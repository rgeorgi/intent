
###########################################################
Igt_id=16639 Url_id=1035 flag=0 cleaned=3 src_leng=4 trans_leng=6
Amwuto way saimha-ci-an-ass-ni ?
Anyone why resign-CI-not-Past-Q ?
Why did no one resign ?

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(SBARQ (WHADVP (WRB Why)) (SQ (VBD did) (NP (DT no) (NN one)) (VP (VB resign))) (. ?))

(SBARQ+resign (WHADVP+Why (WRB Why))
              (SQ+resign (VBD did)
                         (NP+one (DT no)
                                 (NN one))
                         (VP+resign (VB resign)))
              (. ?))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Why did no one resign ?
1 5 # Why resign
2 5 # did resign
3 4 # no one
4 5 # one resign
5 -1 # resign *TOP*
6 5 # ? resign


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Amwuto way saimha-ci-an-ass-ni ?
Anyone why resign-CI-not-Past-Q ?

1 1 # Amwuto Anyone
2 2 # way why
3 3 # saimha-ci-an-ass-ni resign-CI-not-Past-Q
 3.1 3.1 # saimha resign
 3.2 3.2 # -ci -CI
 3.3 3.3 # -an -not
 3.4 3.4 # -ass -Past
 3.5 3.5 # -ni -Q
4 4 # ? ?

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Anyone why resign-CI-not-Past-Q ?
Why did no one resign ?

1 4 # Anyone NULL x
2 1 # why Why
3 5,3 # resign-CI-not-Past-Q resign
 3.1 5 # resign resign
 3.2 0 # -CI NULL
 3.3 3 # -not NULL x
 3.4 0 # -Past NULL 
 3.5 0 # -Q NULL
4 6 # ? ?


######## Q5: gloss and translation alignment is correct? Answer: n
#dj did = -Past ??


############################# Q6: src DS
Amwuto way saimha-ci-an-ass-ni ?
Anyone why resign-CI-not-Past-Q ?
Why did no one resign ?

1 3 # Amwuto saimha-ci-an-ass-ni
2 3 # way saimha-ci-an-ass-ni
3 -1 # saimha-ci-an-ass-ni *TOP*
4 3 # ? saimha-ci-an-ass-ni


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8508 Url_id=1072 flag=0 cleaned=3 src_leng=5 trans_leng=5
mek-ki-nun John-i sakwa-lul mek-ess-ta .
eat-KI-TOP John-NOM apple-ACC eat-PAST-DECL .
John ate the apple .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD ate) (NP (DT the) (NN apple))) (. .))

(S+ate (NP+John (NNP John))
       (VP+ate (VBD ate)
               (NP+apple (DT the)
                         (NN apple)))
       (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John ate the apple .
1 2 # John ate
2 -1 # ate *TOP*
3 4 # the apple
4 2 # apple ate
5 2 # . ate


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
mek-ki-nun John-i sakwa-lul mek-ess-ta .
eat-KI-TOP John-NOM apple-ACC eat-PAST-DECL .

1 1 # mek-ki-nun eat-KI-TOP
 1.1 1.1 # mek eat
 1.2 1.2 # -ki -KI
 1.3 1.3 # -nun -TOP
2 2 # John-i John-NOM
 2.1 2.1 # John John
 2.2 2.2 # -i -NOM
3 3 # sakwa-lul apple-ACC
 3.1 3.1 # sakwa apple
 3.2 3.2 # -lul -ACC
4 4 # mek-ess-ta eat-PAST-DECL
 4.1 4.1 # mek eat
 4.2 4.2 # -ess -PAST
 4.3 4.3 # -ta -DECL
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
eat-KI-TOP John-NOM apple-ACC eat-PAST-DECL .
John ate the apple .

1 2 # eat-KI-TOP ate
 1.1 2 # eat ate
 1.2 0 # -KI NULL
 1.3 0 # -TOP NULL
2 1 # John-NOM John
 2.1 1 # John John
 2.2 0 # -NOM NULL
3 4 # apple-ACC apple
 3.1 4 # apple apple
 3.2 0 # -ACC NULL
4 2 # eat-PAST-DECL ate
 4.1 2 # eat ate
 4.2 0 # -PAST NULL
 4.3 0 # -DECL NULL
5 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
mek-ki-nun John-i sakwa-lul mek-ess-ta .
eat-KI-TOP John-NOM apple-ACC eat-PAST-DECL .
John ate the apple .

1 4 # mek-ki-nun mek-ess-ta
2 4 # John-i mek-ki-nun,mek-ess-ta x
3 4 # sakwa-lul mek-ki-nun,mek-ess-ta x
4 -1 # mek-ess-ta *TOP*
5 4 # . mek-ki-nun,mek-ess-ta x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8509 Url_id=1072 flag=0 cleaned=4 src_leng=6 trans_leng=10
cil-i coh-ki-nun ha-ciman nemu pissa-nteyo .
quality-NOM good-KI-CT do-but too expensive-POLITE .
The quality is good but it 's too expensive .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (S (NP (DT The) (NN quality)) (VP (VBZ is) (ADJP (JJ good)))) (CC but) (S (NP (PRP it)) (VP (VBZ 's) (ADJP (RB too) (JJ expensive)))) (. .))

(S+expensive (S+good (NP+quality (DT The)
                                 (NN quality))
                     (VP+good (VBZ is)
                              (ADJP-PRD+good (JJ good))))
             (CC but)
             (S+expensive (NP+it (PRP it))
                          (VP+expensive (VBZ 's)
                                        (ADJP-PRD+expensive (RB too)
                                                            (JJ expensive))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The quality is good but it 's too expensive .
1 2 # The quality
2 4 # quality good
3 4 # is good
4 9 # good expensive
5 9 # but expensive
6 9 # it expensive
7 9 # 's expensive
8 9 # too expensive
9 -1 # expensive *TOP*
10 9 # . expensive


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
cil-i coh-ki-nun ha-ciman nemu pissa-nteyo .
quality-NOM good-KI-CT do-but too expensive-POLITE .

1 1 # cil-i quality-NOM
 1.1 1.1 # cil quality
 1.2 1.2 # -i -NOM
2 2 # coh-ki-nun good-KI-CT
 2.1 2.1 # coh good
 2.2 2.2 # -ki -KI
 2.3 2.3 # -nun -CT
3 3 # ha-ciman do-but
 3.1 3.1 # ha do
 3.2 3.2 # -ciman -but
4 4 # nemu too
5 5 # pissa-nteyo expensive-POLITE
 5.1 5.1 # pissa expensive
 5.2 5.2 # -nteyo -POLITE
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
quality-NOM good-KI-CT do-but too expensive-POLITE .
The quality is good but it 's too expensive .

1 2 # quality-NOM quality
 1.1 2 # quality quality
 1.2 0 # -NOM NULL
2 4 # good-KI-CT good
 2.1 4 # good good
 2.2 0 # -KI NULL
 2.3 0 # -CT NULL
3 5 # do-but but
 3.1 0 # do NULL
 3.2 5 # -but but
4 8 # too too
5 9 # expensive-POLITE expensive
 5.1 9 # expensive expensive
 5.2 0 # -POLITE NULL
6 10 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
cil-i coh-ki-nun ha-ciman nemu pissa-nteyo .
quality-NOM good-KI-CT do-but too expensive-POLITE .
The quality is good but it 's too expensive .

1 2 # cil-i coh-ki-nun
2 5 # coh-ki-nun pissa-nteyo
3 5 # ha-ciman pissa-nteyo
4 5 # nemu pissa-nteyo
5 -1 # pissa-nteyo *TOP*
6 5 # . pissa-nteyo


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=15703 Url_id=1078 flag=0 cleaned=3 src_leng=6 trans_leng=7
Na-nun Mary-eykey ppalli o-la-ko myenglyengha-yess-ta .
I-Top Mary-to quickly come-la-Comp order-Past-Dec .
I ordered Mary to come quickly .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD ordered) (NP (NNP Mary)) (S (VP (TO to) (VP (VB come) (ADVP (RB quickly)))))) (. .))

(S+ordered (NP+I (PRP I))
           (VP+ordered (VBD ordered)
                       (NP+Mary (NNP Mary))
                       (S+come (VP+come (TO to)
                                        (VP+come (VB come)
                                                 (ADVP+quickly (RB quickly))))))
           (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
I ordered Mary to come quickly .
1 2 # I ordered
2 -1 # ordered *TOP*
3 2 # Mary ordered
4 5 # to come
5 2 # come ordered
6 5 # quickly come
7 2 # . ordered


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Na-nun Mary-eykey ppalli o-la-ko myenglyengha-yess-ta .
I-Top Mary-to quickly come-la-Comp order-Past-Dec .

1 1 # Na-nun I-Top
 1.1 1.1 # Na I
 1.2 1.2 # -nun -Top
2 2 # Mary-eykey Mary-to
 2.1 2.1 # Mary Mary
 2.2 2.2 # -eykey -to
3 3 # ppalli quickly
4 4 # o-la-ko come-la-Comp
 4.1 4.1 # o come
 4.2 4.2 # -la -la
 4.3 4.3 # -ko -Comp
5 5 # myenglyengha-yess-ta order-Past-Dec
 5.1 5.1 # myenglyengha order
 5.2 5.2 # -yess -Past
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Top Mary-to quickly come-la-Comp order-Past-Dec .
I ordered Mary to come quickly .

1 1 # I-Top I
 1.1 1 # I I
 1.2 0 # -Top NULL
2 3 # Mary-to Mary,to x
 2.1 3 # Mary Mary
 2.2 0 # -to to x
3 6 # quickly quickly
4 5 # come-la-Comp come
 4.1 5 # come come
 4.2 0 # -la NULL
 4.3 0 # -Comp NULL
5 2 # order-Past-Dec ordered
 5.1 2 # order ordered
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Na-nun Mary-eykey ppalli o-la-ko myenglyengha-yess-ta .
I-Top Mary-to quickly come-la-Comp order-Past-Dec .
I ordered Mary to come quickly .

1 5 # Na-nun myenglyengha-yess-ta
2 5 # Mary-eykey myenglyengha-yess-ta
3 4 # ppalli o-la-ko
4 5 # o-la-ko myenglyengha-yess-ta
5 -1 # myenglyengha-yess-ta *TOP*
6 5 # . myenglyengha-yess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=15707 Url_id=1078 flag=0 cleaned=3 src_leng=6 trans_leng=7
Na-nun Mary-eykey ppalli o-la-ko myenglyengha-yess-ta .
I-Top Mary-to quickly come-la-Comp order-Past-Dec .
I ordered Mary to come quickly .

######## Q1: IGT is clean? Answer: n
#dj duplicate of 15703


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD ordered) (NP (NNP Mary)) (S (VP (TO to) (VP (VB come) (ADVP (RB quickly)))))) (. .))

(S+ordered (NP+I (PRP I))
           (VP+ordered (VBD ordered)
                       (NP+Mary (NNP Mary))
                       (S+come (VP+come (TO to)
                                        (VP+come (VB come)
                                                 (ADVP+quickly (RB quickly))))))
           (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
I ordered Mary to come quickly .
1 2 # I ordered
2 -1 # ordered *TOP*
3 2 # Mary ordered
4 5 # to come
5 2 # come ordered
6 5 # quickly come
7 2 # . ordered


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Na-nun Mary-eykey ppalli o-la-ko myenglyengha-yess-ta .
I-Top Mary-to quickly come-la-Comp order-Past-Dec .

1 1 # Na-nun I-Top
 1.1 1.1 # Na I
 1.2 1.2 # -nun -Top
2 2 # Mary-eykey Mary-to
 2.1 2.1 # Mary Mary
 2.2 2.2 # -eykey -to
3 3 # ppalli quickly
4 4 # o-la-ko come-la-Comp
 4.1 4.1 # o come
 4.2 4.2 # -la -la
 4.3 4.3 # -ko -Comp
5 5 # myenglyengha-yess-ta order-Past-Dec
 5.1 5.1 # myenglyengha order
 5.2 5.2 # -yess -Past
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
I-Top Mary-to quickly come-la-Comp order-Past-Dec .
I ordered Mary to come quickly .

1 1 # I-Top I
 1.1 1 # I I
 1.2 0 # -Top NULL
2 3 # Mary-to Mary,to x
 2.1 3 # Mary Mary
 2.2 0 # -to to x
3 6 # quickly quickly
4 5 # come-la-Comp come
 4.1 5 # come come
 4.2 0 # -la NULL
 4.3 0 # -Comp NULL
5 2 # order-Past-Dec ordered
 5.1 2 # order ordered
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Na-nun Mary-eykey ppalli o-la-ko myenglyengha-yess-ta .
I-Top Mary-to quickly come-la-Comp order-Past-Dec .
I ordered Mary to come quickly .

1 5 # Na-nun myenglyengha-yess-ta
2 5 # Mary-eykey myenglyengha-yess-ta
3 4 # ppalli o-la-ko
4 5 # o-la-ko myenglyengha-yess-ta
5 -1 # myenglyengha-yess-ta *TOP*
6 5 # . myenglyengha-yess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=17691 Url_id=1258 flag=0 cleaned=3 src_leng=4 trans_leng=5
Ne-nun nwuku-lul sarangha-ni ?
You-Top who-Acc love-Q ?
Who do you love ?

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(SBARQ (WHNP (WP Who)) (SQ (VBP do) (NP (PRP you)) (VP (VB love))) (. ?))

(SBARQ+love (WHNP+Who (WP Who))
            (SQ+love (VBP do)
                     (NP+you (PRP you))
                     (VP+love (VB love)))
            (. ?))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Who do you love ?
1 4 # Who love
2 4 # do love
3 4 # you love
4 -1 # love *TOP*
5 4 # ? love


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Ne-nun nwuku-lul sarangha-ni ?
You-Top who-Acc love-Q ?

1 1 # Ne-nun You-Top
 1.1 1.1 # Ne You
 1.2 1.2 # -nun -Top
2 2 # nwuku-lul who-Acc
 2.1 2.1 # nwuku who
 2.2 2.2 # -lul -Acc
3 3 # sarangha-ni love-Q
 3.1 3.1 # sarangha love
 3.2 3.2 # -ni -Q
4 4 # ? ?

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
You-Top who-Acc love-Q ?
Who do you love ?

1 3 # You-Top you
 1.1 3 # You you
 1.2 0 # -Top NULL
2 1 # who-Acc Who
 2.1 1 # who Who
 2.2 0 # -Acc NULL
3 4 # love-Q love
 3.1 4 # love love
 3.2 0 # -Q NULL
4 5 # ? ?


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Ne-nun nwuku-lul sarangha-ni ?
You-Top who-Acc love-Q ?
Who do you love ?

1 3 # Ne-nun sarangha-ni
2 3 # nwuku-lul sarangha-ni
3 -1 # sarangha-ni *TOP*
4 3 # ? sarangha-ni


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=21084 Url_id=1495 flag=0 cleaned=3 src_leng=8 trans_leng=11
chayk pily-e ka-n- kes nayil kac-ko o-kyess-upni-ta .
book borrow go-PAST KES tomorrow bring-ing come-FUT-POL-DEC .
I will bring back the book that I borrowed tomorrow .

######## Q1: IGT is clean? Answer: y
#dj once again, I think this has a typo in the first line.
#dj the future morpheme is -keyss- not -kyess-


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (MD will) (VP (VB bring) (ADVP (RB back)) (NP (NP (DT the) (NN book)) (SBAR (WHNP (WDT that)) (S (NP (PRP I)) (VP (VBD borrowed) (NP (NN tomorrow)))))))) (. .))

(S+bring (NP+I (PRP I))
         (VP+bring (MD will)
                   (VP+bring (VB bring)
                             (ADVP+back (RB back))
                             (NP+book (NP+book (DT the)
                                               (NN book))
                                      (SBAR+borrowed (WHNP+that (WDT that))
                                                     (S+borrowed (NP+I (PRP I))
                                                                 (VP+borrowed (VBD borrowed)
                                                                              (NP+tomorrow (NN tomorrow))))))))
         (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
I will bring back the book that I borrowed tomorrow .
1 3 # I bring
2 3 # will bring
3 -1 # bring *TOP*
4 3 # back bring
5 6 # the book
6 3 # book bring
7 9 # that borrowed
8 9 # I borrowed
9 6 # borrowed book
10 3 # tomorrow borrowed x
11 3 # . bring


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
chayk pily-e ka-n- kes nayil kac-ko o-kyess-upni-ta .
book borrow go-PAST KES tomorrow bring-ing come-FUT-POL-DEC .

1 1 # chayk book
2 2 # pily-e borrow
 2.1 0 # pily NULL
 2.2 0 # -e NULL
3 3 # ka-n- go-PAST
 3.1 3.1 # ka go
 3.2 3.2 # -n -PAST
4 4 # kes KES
5 5 # nayil tomorrow
6 6 # kac-ko bring-ing
 6.1 6.1 # kac bring
 6.2 6.2 # -ko -ing
7 7 # o-kyess-upni-ta come-FUT-POL-DEC
 7.1 7.1 # o come
 7.2 7.2 # -kyess -FUT
 7.3 7.3 # -upni -POL
 7.4 7.4 # -ta -DEC
8 8 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
book borrow go-PAST KES tomorrow bring-ing come-FUT-POL-DEC .
I will bring back the book that I borrowed tomorrow .

1 6 # book book
2 9 # borrow borrowed
3 0 # go-PAST NULL
 3.1 0 # go NULL
 3.2 0 # -PAST NULL
4 0 # KES NULL
5 10 # tomorrow tomorrow
6 3 # bring-ing bring
 6.1 3 # bring bring
 6.2 0 # -ing NULL
7 4,2 # come-FUT-POL-DEC NULL x
 7.1 4 # come NULL x
 7.2 2 # -FUT NULL x
 7.3 0 # -POL NULL
 7.4 0 # -DEC NULL
8 11 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
chayk pily-e ka-n- kes nayil kac-ko o-kyess-upni-ta .
book borrow go-PAST KES tomorrow bring-ing come-FUT-POL-DEC .
I will bring back the book that I borrowed tomorrow .

1 6 # chayk kac-ko
2 3 # pily-e chayk
3 4 # ka-n- kac-ko x
4 1 # kes kac-ko
5 6 # nayil pily-e x
6 7 # kac-ko *TOP* x
7 -1 # o-kyess-upni-ta kac-ko x
8 7 # . kac-ko x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=21114 Url_id=1495 flag=0 cleaned=3 src_leng=3 trans_leng=7
Yong-guk-ulo ttona-ss-ul-ke-eyo .
England-to left-IRR-KES-BE .
He must have left for England .

######## Q1: IGT is clean? Answer: n
#dj We have Yongguk (England) broken into was looks like two morphs
#dj Similarly, -ss- is -PAST- and -ul- is -POTENTIAL- mapping to -IRR-


############################## Q2: English parse tree 
(S (NP (PRP He)) (VP (MD must) (VP (VB have) (VP (VBN left) (PP (IN for) (NP (NNP England)))))) (. .))

(S+left (NP+He (PRP He))
        (VP+left (MD must)
                 (VP+left (VB have)
                          (VP+left (VBN left)
                                   (PP+for (IN for)
                                           (NP+England (NNP England))))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
He must have left for England .
1 4 # He left
2 4 # must left
3 4 # have left
4 -1 # left *TOP*
5 4 # for left
6 5 # England for
7 4 # . left


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Yong-guk-ulo ttona-ss-ul-ke-eyo .
England-to left-IRR-KES-BE .

1 1 # Yong-guk-ulo England-to
 1.1 1.1a # Yong NULL x
 1.2 1.1b # -guk NULL x
 1.3 1.2 # -ulo NULL x
2 2 # ttona-ss-ul-ke-eyo left-IRR-KES-BE
 2.1 2.1 # ttona NULL x
 2.2 0 # -ss NULL x # PAST tense marker
 2.3 0 # -ul NULL x # POTENTIAL aspect marker
 2.4 2.3 # -ke NULL x
 2.5 2.4 # -eyo NULL x
3 3 # . .

######## Q4: src and gloss alignment is correct? Answer: n



######################### Q5: gloss and translation alignment
England-to left-IRR-KES-BE .
He must have left for England .

1 6,5 # England-to England x
 1.1 6 # England England
 1.2 5 # -to NULL x
2 4 # left-IRR-KES-BE left
 2.1 4 # left left
 2.2 0 # -IRR NULL
 2.3 0 # -KES NULL
 2.4 0 # -BE NULL
3 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Yong-guk-ulo ttona-ss-ul-ke-eyo .
England-to left-IRR-KES-BE .
He must have left for England .

1 2 # Yong-guk-ulo ttona-ss-ul-ke-eyo
2 -1 # ttona-ss-ul-ke-eyo *TOP*
3 2 # . ttona-ss-ul-ke-eyo


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=21119 Url_id=1495 flag=0 cleaned=0 src_leng=4 trans_leng=7
na ­uy sal-te-n kohyang
I ­Gen live-Ret-N hometown
the hometown where I used to live

######## Q1: IGT is clean? Answer: y
#dj When I compare this to the results I get on the web, 
#dj there is some extra stuff. The web seems to show "na uy"


############################## Q2: English parse tree 
(NP (NP (DT the) (NN hometown)) (SBAR (WHADVP (WRB where)) (S (NP (PRP I)) (VP (VBD used) (S (VP (TO to) (VP (VB live))))))))

(NP+hometown (NP+hometown (DT the)
                          (NN hometown))
             (SBAR+used (WHADVP+where (WRB where))
                        (S+used (NP+I (PRP I))
                                (VP+used (VBD used)
                                         (S+live (VP+live (TO to)
                                                          (VP+live (VB live))))))))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
the hometown where I used to live
1 2 # the hometown
2 -1 # hometown *TOP*
3 7 # where used x
4 7 # I used x
5 7 # used hometown x
6 7 # to live
7 2 # live used x


########  Q3: English DS is correct? Answer: n
#dj Here I'm considering the construction "used to" as aspect,
#dj so the main verb in the subord clause is "live"
#dj If we consider "used" as the primary verb, then this is correct.


#######################  Q4: src and gloss alignment
na ­uy sal-te-n kohyang
I ­Gen live-Ret-N hometown

1 1 # na I
2 2 # ­uy ­Gen
3 3 # sal-te-n live-Ret-N
 3.1 3.1 # sal live
 3.2 3.2 # -te -Ret
 3.3 3.3 # -n -N
4 4 # kohyang hometown

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I ­Gen live-Ret-N hometown
the hometown where I used to live

1 4 # I I
2 0 # ­Gen NULL
3 7 # live-Ret-N live
 3.1 7 # live live
 3.2 0 # -Ret NULL
 3.3 0 # -N NULL
4 2 # hometown hometown


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
na ­uy sal-te-n kohyang
I ­Gen live-Ret-N hometown
the hometown where I used to live

1 3 # na kohyang x
2 1 # ­uy kohyang x
3 4 # sal-te-n kohyang
4 -1 # kohyang *TOP*


####### Q6: src DS is correct? Answer: n
#dj I could have said that the IGT is incorrect, not only because of the 
#dj "­uy", but also because this "-uy" would typically be marked as a 
#dj posposition, like -TOP or -ACC.




###########################################################
Igt_id=21127 Url_id=1495 flag=0 cleaned=0 src_leng=4 trans_leng=5
Chelswu-ka ecey pro manna-ass-te-n-salam
Chelswu-Nom yesterday meet-Past-Ret-N person
the person Chelswu met yesterday

######## Q1: IGT is clean? Answer: n
#dj We have "pro" trace as well as different morph joining.


############################## Q2: English parse tree 
(S (NP (DT the) (NN person) (NN Chelswu)) (VP (VBD met) (NP (NN yesterday))))

(S+met (NP+Chelswu (DT the)
                   (NN person)
                   (NN Chelswu))
       (VP+met (VBD met)
               (NP+yesterday (NN yesterday))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
the person Chelswu met yesterday
1 3 # the Chelswu
2 3 # person Chelswu
3 4 # Chelswu met
4 -1 # met *TOP*
5 4 # yesterday met


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Chelswu-ka ecey pro manna-ass-te-n-salam
Chelswu-Nom yesterday meet-Past-Ret-N person

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # ecey yesterday
3 3 # pro meet-Past-Ret-N
4 4 # manna-ass-te-n-salam person
 4.1 0 # manna NULL
 4.2 0 # -ass NULL
 4.3 0 # -te NULL
 4.4 0 # -n NULL
 4.5 0 # -salam NULL

######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Chelswu-Nom yesterday meet-Past-Ret-N person
the person Chelswu met yesterday

1 3 # Chelswu-Nom Chelswu
 1.1 3 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 5 # yesterday yesterday
3 4 # meet-Past-Ret-N met
 3.1 4 # meet met
 3.2 0 # -Past NULL
 3.3 0 # -Ret NULL
 3.4 0 # -N NULL
4 2 # person person


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Chelswu-ka ecey pro manna-ass-te-n-salam
Chelswu-Nom yesterday meet-Past-Ret-N person
the person Chelswu met yesterday

1 3 # Chelswu-ka pro
2 3 # ecey pro
3 -1 # pro *TOP*
4 1 # manna-ass-te-n-salam Chelswu-ka


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=2240 Url_id=1733 flag=0 cleaned=3 src_leng=7 trans_leng=9
ilpon-eyse o-n salam-un cinccalo ku haksayng-i-ta .
Japan-from come-MOD person-TOP actually that student-COP-DECL .
The person from Japan is actually that student .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NP (DT The) (NN person)) (PP (IN from) (NP (NNP Japan)))) (VP (VBZ is) (ADVP (RB actually)) (NP (DT that) (NN student))) (. .))

(S+is (NP+person (NP+person (DT The)
                            (NN person))
                 (PP+from (IN from)
                          (NP+Japan (NNP Japan))))
      (VP+is (VBZ is)
             (ADVP+actually (RB actually))
             (NP+student (DT that)
                         (NN student)))
      (. .))


###### Q2: English parse tree is correct? Answer: n (I think)
#dj This is predicate nominative. Weren't we marking these as
#dj we did the predicate adjectives? so the head of the sentence
#dj is "student" not "is"? I don't remember. cf 8509



###############################  Q3: English DS 
The person from Japan is actually that student .
1 2 # The person
2 8 # person is x
3 2 # from person
4 3 # Japan from
5 8 # is *TOP* x
6 5 # actually is
7 8 # that student 
8 -1 # student is x
9 8 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
ilpon-eyse o-n salam-un cinccalo ku haksayng-i-ta .
Japan-from come-MOD person-TOP actually that student-COP-DECL .

1 1 # ilpon-eyse Japan-from
 1.1 1.1 # ilpon Japan
 1.2 1.2 # -eyse -from
2 2 # o-n come-MOD
 2.1 2.1 # o come
 2.2 2.2 # -n -MOD
3 3 # salam-un person-TOP
 3.1 3.1 # salam person
 3.2 3.2 # -un -TOP
4 4 # cinccalo actually
5 5 # ku that
6 6 # haksayng-i-ta student-COP-DECL
 6.1 6.1 # haksayng student
 6.2 6.2 # -i -COP
 6.3 6.3 # -ta -DECL
7 7 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Japan-from come-MOD person-TOP actually that student-COP-DECL .
The person from Japan is actually that student .

1 3,4 # Japan-from from,Japan
 1.1 4 # Japan Japan
 1.2 3 # -from from
2 0 # come-MOD NULL
 2.1 0 # come NULL
 2.2 0 # -MOD NULL
3 2 # person-TOP person
 3.1 2 # person person
 3.2 0 # -TOP NULL
4 6 # actually actually
5 7 # that that
6 8 # student-COP-DECL student
 6.1 8 # student student
 6.2 0 # -COP NULL
 6.3 0 # -DECL NULL
7 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
ilpon-eyse o-n salam-un cinccalo ku haksayng-i-ta .
Japan-from come-MOD person-TOP actually that student-COP-DECL .
The person from Japan is actually that student .

1 1 # ilpon-eyse salam-un x
2 3 # o-n haksayng-i-ta x
3 6 # salam-un haksayng-i-ta
4 6 # cinccalo haksayng-i-ta
5 6 # ku haksayng-i-ta
6 -1 # haksayng-i-ta NULL x
7 6 # . haksayng-i-ta 


####### Q6: src DS is correct? Answer: n
#dj This is a difficult case. Literally the sentence is "The person who
#dj came from Japan is actually that student." So, the deictic verb 
#dj "come" is left dangling.




###########################################################
Igt_id=2241 Url_id=1733 flag=0 cleaned=3 src_leng=7 trans_leng=9
ku haysayng-un cinccalo ilpon-eyse o-n salam-i-ta .
that student-TOP actually Japan-from come-MOD person-COP-DECL .
That student is actually a person from Japan .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT That) (NN student)) (VP (VBZ is) (ADVP (RB actually)) (NP (NP (DT a) (NN person)) (PP (IN from) (NP (NNP Japan))))) (. .))

(S+is (NP+student (DT That)
                  (NN student))
      (VP+is (VBZ is)
             (ADVP+actually (RB actually))
             (NP+person (NP+person (DT a)
                                   (NN person))
                        (PP+from (IN from)
                                 (NP+Japan (NNP Japan)))))
      (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
That student is actually a person from Japan .
1 2 # That student
2 6 # student is x
3 6 # is *TOP* x
4 6 # actually is x
5 6 # a person
6 -1 # person is x
7 6 # from person
8 7 # Japan from
9 6 # . is x


########  Q3: English DS is correct? Answer: n
#dj Copula and headedness, again. cf 2240



#######################  Q4: src and gloss alignment
ku haysayng-un cinccalo ilpon-eyse o-n salam-i-ta .
that student-TOP actually Japan-from come-MOD person-COP-DECL .

1 1 # ku that
2 2 # haysayng-un student-TOP
 2.1 2.1 # haysayng student
 2.2 2.2 # -un -TOP
3 3 # cinccalo actually
4 4 # ilpon-eyse Japan-from
 4.1 4.1 # ilpon Japan
 4.2 4.2 # -eyse -from
5 5 # o-n come-MOD
 5.1 5.1 # o come
 5.2 5.2 # -n -MOD
6 6 # salam-i-ta person-COP-DECL
 6.1 6.1 # salam person
 6.2 6.2 # -i -COP
 6.3 6.3 # -ta -DECL
7 7 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
that student-TOP actually Japan-from come-MOD person-COP-DECL .
That student is actually a person from Japan .

1 1 # that That
2 2 # student-TOP student
 2.1 2 # student student
 2.2 0 # -TOP NULL
3 4 # actually actually
4 7,8 # Japan-from from,Japan
 4.1 8 # Japan Japan
 4.2 7 # -from from
5 0 # come-MOD NULL
 5.1 0 # come NULL
 5.2 0 # -MOD NULL
6 6 # person-COP-DECL person
 6.1 6 # person person
 6.2 0 # -COP NULL
 6.3 0 # -DECL NULL
7 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
ku haysayng-un cinccalo ilpon-eyse o-n salam-i-ta .
that student-TOP actually Japan-from come-MOD person-COP-DECL .
That student is actually a person from Japan .

1 2 # ku haysayng-un
2 6 # haysayng-un salam-i-ta
3 6 # cinccalo salam-i-ta
4 5 # ilpon-eyse salam-i-ta x
5 6 # o-n salam-i-ta
6 -1 # salam-i-ta NULL x
7 6 # . salam-i-ta


####### Q6: src DS is correct? Answer: n
#dj Deictic "come", cf 2240.




###########################################################
Igt_id=22003 Url_id=1739 flag=0 cleaned=3 src_leng=7 trans_leng=9
Chelswu-nun kakkak-uy ai-ka swukcey-lul ha-tolok seltukha-ess-ta .
Chelswu-TOP each-GEN child-NOM homework-ACC do-COMP persuaded .
Chelswu persuaded each child to do the homework .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBD persuaded) (NP (DT each) (NN child)) (S (VP (TO to) (VP (VB do) (NP (DT the) (NN homework)))))) (. .))

(S+persuaded (NP+Chelswu (NNP Chelswu))
             (VP+persuaded (VBD persuaded)
                           (NP+child (DT each)
                                     (NN child))
                           (S+do (VP+do (TO to)
                                        (VP+do (VB do)
                                               (NP+homework (DT the)
                                                            (NN homework))))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu persuaded each child to do the homework .
1 2 # Chelswu persuaded
2 -1 # persuaded *TOP*
3 4 # each child
4 2 # child persuaded
5 6 # to do
6 2 # do persuaded
7 8 # the homework
8 6 # homework do
9 2 # . persuaded


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-nun kakkak-uy ai-ka swukcey-lul ha-tolok seltukha-ess-ta .
Chelswu-TOP each-GEN child-NOM homework-ACC do-COMP persuaded .

1 1 # Chelswu-nun Chelswu-TOP
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -nun -TOP
2 2 # kakkak-uy each-GEN
 2.1 2.1 # kakkak each
 2.2 2.2 # -uy -GEN
3 3 # ai-ka child-NOM
 3.1 3.1 # ai child
 3.2 3.2 # -ka -NOM
4 4 # swukcey-lul homework-ACC
 4.1 4.1 # swukcey homework
 4.2 4.2 # -lul -ACC
5 5 # ha-tolok do-COMP
 5.1 5.1 # ha do
 5.2 5.2 # -tolok -COMP
6 6 # seltukha-ess-ta persuaded
 6.1 0 # seltukha NULL
 6.2 0 # -ess NULL
 6.3 0 # -ta NULL
7 7 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-TOP each-GEN child-NOM homework-ACC do-COMP persuaded .
Chelswu persuaded each child to do the homework .

1 1 # Chelswu-TOP Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -TOP NULL
2 3 # each-GEN each
 2.1 3 # each each
 2.2 0 # -GEN NULL
3 4 # child-NOM child
 3.1 4 # child child
 3.2 0 # -NOM NULL
4 8 # homework-ACC homework
 4.1 8 # homework homework
 4.2 0 # -ACC NULL
5 6 # do-COMP do
 5.1 6 # do do
 5.2 0 # -COMP NULL
6 2 # persuaded persuaded
7 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chelswu-nun kakkak-uy ai-ka swukcey-lul ha-tolok seltukha-ess-ta .
Chelswu-TOP each-GEN child-NOM homework-ACC do-COMP persuaded .
Chelswu persuaded each child to do the homework .

1 6 # Chelswu-nun seltukha-ess-ta
2 3 # kakkak-uy ai-ka
3 6 # ai-ka seltukha-ess-ta
4 5 # swukcey-lul ha-tolok
5 6 # ha-tolok seltukha-ess-ta
6 -1 # seltukha-ess-ta *TOP*
7 6 # . seltukha-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=22265 Url_id=1775 flag=0 cleaned=4 src_leng=6 trans_leng=8
John-un kunye-ka wu-n-un kes-ul tallayessta .
John-top she-nom cry-rel-imprf kes-acc comforted .
John comforted her when she was crying .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBN comforted) (NP (PRP her)) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (VP (VBG crying)))))) (. .))

(S+comforted (NP+John (NNP John))
             (VP+comforted (VBN comforted)
                           (NP+her (PRP her))
                           (SBAR+crying (WHADVP+when (WRB when))
                                        (S+crying (NP+she (PRP she))
                                                  (VP+crying (VBD was)
                                                             (VP+crying (VBG crying))))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John comforted her when she was crying .
1 2 # John comforted
2 -1 # comforted *TOP*
3 2 # her comforted
4 7 # when crying
5 7 # she crying
6 7 # was crying
7 2 # crying comforted
8 2 # . comforted


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un kunye-ka wu-n-un kes-ul tallayessta .
John-top she-nom cry-rel-imprf kes-acc comforted .

1 1 # John-un John-top
 1.1 1.1 # John John
 1.2 1.2 # -un -top
2 2 # kunye-ka she-nom
 2.1 2.1 # kunye she
 2.2 2.2 # -ka -nom
3 3 # wu-n-un cry-rel-imprf
 3.1 3.1 # wu cry
 3.2 3.2 # -n -rel
 3.3 3.3 # -un -imprf
4 4 # kes-ul kes-acc
 4.1 4.1 # kes kes
 4.2 4.2 # -ul -acc
5 5 # tallayessta comforted
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-top she-nom cry-rel-imprf kes-acc comforted .
John comforted her when she was crying .

1 1 # John-top John
 1.1 1 # John John
 1.2 0 # -top NULL
2 5 # she-nom she
 2.1 5 # she she
 2.2 0 # -nom NULL
3 7 # cry-rel-imprf crying
 3.1 7 # cry crying
 3.2 0 # -rel NULL
 3.3 0 # -imprf NULL
4 0 # kes-acc NULL
 4.1 0 # kes NULL
 4.2 0 # -acc NULL
5 2 # comforted comforted
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-un kunye-ka wu-n-un kes-ul tallayessta .
John-top she-nom cry-rel-imprf kes-acc comforted .
John comforted her when she was crying .

1 5 # John-un tallayessta
2 5 # kunye-ka wu-n-un x
3 4 # wu-n-un tallayessta x
4 5 # kes-ul tallayessta
5 -1 # tallayessta *TOP*
6 5 # . tallayessta


####### Q6: src DS is correct? Answer: n
#dj The point of the IGT, I believe, is showing the use of KES
#dj as a complementizer. So, we have a problem, the complementizer
#dj in our scheme would be associated with the subordinate verb,
#dj but here it is also marked as the object of the main verb.
#dj One could translate KES as "object" or "thing", also there is
#dj an odd active/passive thing going on in this sentence. then this
#dj sentence has the literal translation, As for John, the woman was
#dj comforted as a crying one.





###########################################################
Igt_id=22266 Url_id=1775 flag=0 cleaned=5 src_leng=6 trans_leng=8
John-un Sue-ka wu-n-un kes-ul tallayessta .
John-top Sue-nom cry-imprf-rel kes-acc comforted .
John comforted Sue when she was crying .

######## Q1: IGT is clean? Answer: n
#dj This is virtually identical to 22265, simply replacing "the woman"
#dj with "Sue". It has the same complementizer and active/passive issues
#dj as 22265.


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBN comforted) (S (VP (VB Sue) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (VP (VBG crying)))))))) (. .))

(S+comforted (NP+John (NNP John))
             (VP+comforted (VBN comforted)
                           (S+Sue (VP+Sue (VB Sue)
                                          (SBAR+crying (WHADVP+when (WRB when))
                                                       (S+crying (NP+she (PRP she))
                                                                 (VP+crying (VBD was)
                                                                            (VP+crying (VBG crying))))))))
             (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
John comforted Sue when she was crying .
1 2 # John comforted
2 -1 # comforted *TOP*
3 2 # Sue comforted
4 7 # when crying
5 7 # she crying
6 7 # was crying
7 3 # crying Sue
8 2 # . comforted


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
John-un Sue-ka wu-n-un kes-ul tallayessta .
John-top Sue-nom cry-imprf-rel kes-acc comforted .

1 1 # John-un John-top
 1.1 1.1 # John John
 1.2 1.2 # -un -top
2 2 # Sue-ka Sue-nom
 2.1 2.1 # Sue Sue
 2.2 2.2 # -ka -nom
3 3 # wu-n-un cry-imprf-rel
 3.1 3.1 # wu cry
 3.2 3.2 # -n -imprf
 3.3 3.3 # -un -rel
4 4 # kes-ul kes-acc
 4.1 4.1 # kes kes
 4.2 4.2 # -ul -acc
5 5 # tallayessta comforted
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
John-top Sue-nom cry-imprf-rel kes-acc comforted .
John comforted Sue when she was crying .

1 1 # John-top John
 1.1 1 # John John
 1.2 0 # -top NULL
2 3 # Sue-nom Sue
 2.1 3 # Sue Sue
 2.2 0 # -nom NULL
3 7 # cry-imprf-rel crying
 3.1 7 # cry crying
 3.2 0 # -imprf NULL
 3.3 0 # -rel NULL
4 0 # kes-acc NULL
 4.1 0 # kes NULL
 4.2 0 # -acc NULL
5 2 # comforted comforted
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
John-un Sue-ka wu-n-un kes-ul tallayessta .
John-top Sue-nom cry-imprf-rel kes-acc comforted .
John comforted Sue when she was crying .

1 5 # John-un tallayessta
2 5 # Sue-ka tallayessta
3 2 # wu-n-un Sue-ka
4 5 # kes-ul tallayessta
5 -1 # tallayessta *TOP*
6 5 # . tallayessta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=2164 Url_id=220 flag=0 cleaned=3 src_leng=5 trans_leng=9
John-i sakwa-lul sey-kay-ssik nanu-ess-ta .
John-nom apple-acc three-cl-ssik divide-pst-decl .
John divided the apples into groups of three .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD divided) (NP (DT the) (NNS apples)) (PP (IN into) (NP (NP (NNS groups)) (PP (IN of) (NP (CD three)))))) (. .))

(S+divided (NP+John (NNP John))
           (VP+divided (VBD divided)
                       (NP+apples (DT the)
                                  (NNS apples))
                       (PP+into (IN into)
                                (NP+groups (NP+groups (NNS groups))
                                           (PP+of (IN of)
                                                  (NP+three (CD three))))))
           (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John divided the apples into groups of three .
1 2 # John divided
2 -1 # divided *TOP*
3 4 # the apples
4 2 # apples divided
5 2 # into divided
6 5 # groups into
7 6 # of groups
8 7 # three of
9 2 # . divided


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-i sakwa-lul sey-kay-ssik nanu-ess-ta .
John-nom apple-acc three-cl-ssik divide-pst-decl .

1 1 # John-i John-nom
 1.1 1.1 # John John
 1.2 1.2 # -i -nom
2 2 # sakwa-lul apple-acc
 2.1 2.1 # sakwa apple
 2.2 2.2 # -lul -acc
3 3 # sey-kay-ssik three-cl-ssik
 3.1 3.1 # sey three
 3.2 3.2 # -kay -cl
 3.3 3.3 # -ssik -ssik
4 4 # nanu-ess-ta divide-pst-decl
 4.1 4.1 # nanu divide
 4.2 4.2 # -ess -pst
 4.3 4.3 # -ta -decl
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-nom apple-acc three-cl-ssik divide-pst-decl .
John divided the apples into groups of three .

1 1 # John-nom John
 1.1 1 # John John
 1.2 0 # -nom NULL
2 4 # apple-acc apples
 2.1 4 # apple apples
 2.2 0 # -acc NULL
3 8 # three-cl-ssik three
 3.1 8 # three three
 3.2 0 # -cl NULL
 3.3 0 # -ssik NULL
4 2 # divide-pst-decl NULL x
 4.1 2 # divide NULL
 4.2 2 # -pst NULL
 4.3 0 # -decl NULL
5 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj stemming would catch this, perhaps


############################# Q6: src DS
John-i sakwa-lul sey-kay-ssik nanu-ess-ta .
John-nom apple-acc three-cl-ssik divide-pst-decl .
John divided the apples into groups of three .

1 4 # John-i nanu-ess-ta
2 4 # sakwa-lul nanu-ess-ta
3 4 # sey-kay-ssik nanu-ess-ta
4 -1 # nanu-ess-ta NULL x
5 4 # . nanu-ess-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=7759 Url_id=220 flag=0 cleaned=3 src_leng=9 trans_leng=7
salam twu myeng-i kapang sey kay ssik-ul wunpanha-ess-ta .
man two cl-nom suitcase three cl ssik-acc carry-pst-dec .
Two men carried three ssik suitcases .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (CD Two) (NNS men)) (VP (VBD carried) (NP (CD three) (NNP ssik) (NNS suitcases))) (. .))

(S+carried (NP+men (CD Two)
                   (NNS men))
           (VP+carried (VBD carried)
                       (NP+suitcases (CD three)
                                     (NNP ssik)
                                     (NNS suitcases)))
           (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Two men carried three ssik suitcases .
1 2 # Two men
2 3 # men carried
3 -1 # carried *TOP*
4 6 # three suitcases
5 6 # ssik suitcases
6 3 # suitcases carried
7 3 # . carried


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
salam twu myeng-i kapang sey kay ssik-ul wunpanha-ess-ta .
man two cl-nom suitcase three cl ssik-acc carry-pst-dec .

1 1 # salam man
2 2 # twu two
3 3 # myeng-i cl-nom
 3.1 3.1 # myeng cl
 3.2 3.2 # -i -nom
4 4 # kapang suitcase
5 5 # sey three
6 6 # kay cl
7 7 # ssik-ul ssik-acc
 7.1 7.1 # ssik ssik
 7.2 7.2 # -ul -acc
8 8 # wunpanha-ess-ta carry-pst-dec
 8.1 8.1 # wunpanha carry
 8.2 8.2 # -ess -pst
 8.3 8.3 # -ta -dec
9 9 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
man two cl-nom suitcase three cl ssik-acc carry-pst-dec .
Two men carried three ssik suitcases .

1 2 # man men
2 1 # two Two
3 0 # cl-nom NULL
 3.1 0 # cl NULL
 3.2 0 # -nom NULL
4 6 # suitcase NULL x
5 4 # three three
6 0 # cl NULL
7 5 # ssik-acc ssik
 7.1 5 # ssik ssik
 7.2 0 # -acc NULL
8 3 # carry-pst-dec carried
 8.1 3 # carry carried
 8.2 0 # -pst NULL
 8.3 0 # -dec NULL
9 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
salam twu myeng-i kapang sey kay ssik-ul wunpanha-ess-ta .
man two cl-nom suitcase three cl ssik-acc carry-pst-dec .
Two men carried three ssik suitcases .

1 8 # salam wunpanha-ess-ta
2 2 # twu salam x
3 1 # myeng-i wunpanha-ess-ta x
4 8 # kapang wunpanha-ess-ta
5 4 # sey wunpanha-ess-ta x
6 4 # kay wunpanha-ess-ta x
7 4 # ssik-ul wunpanha-ess-ta x
8 -1 # wunpanha-ess-ta *TOP*
9 8 # . wunpanha-ess-ta


####### Q6: src DS is correct? Answer: n
#dj Another somewhat problematic case. The nouns are not marked
#dj for sentencial role, the numbers are. However, I have set this
#dj with the nouns as heads of those NPs, based on the sense, rather
#dj than on the overt grammar of the Korean.





###########################################################
Igt_id=13034 Url_id=225 flag=0 cleaned=1 src_leng=6 trans_leng=9
John-uy chayk-ul ilk- um-i nolawu-n sasil-i-ta
John-GEN book-ACC read-NOMINAL-NOM surprise-V.PRENOM fact-be- PRES-DECL
John 's reading the book is a surprising thing

######## Q1: IGT is clean? Answer: n
#dj the morphemic breaks are not consistent between the 1st and 2nd lines


############################## Q2: English parse tree 
(NP (NP (NNP John) (POS 's)) (NN reading) (SBAR (S (NP (DT the) (NN book)) (VP (VBZ is) (NP (DT a) (JJ surprising) (NN thing))))))

(NP+reading (NP+'s (NNP John)
                   (POS 's))
            (NN reading)
            (SBAR+thing (S+thing (NP+book (DT the)
                                          (NN book))
                                 (VP+thing (VBZ is)
                                           (NP-PRD+thing (DT a)
                                                         (JJ surprising)
                                                         (NN thing))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
John 's reading the book is a surprising thing
1 2 # John 's
2 3 # 's reading
3 -1 # reading *TOP*
4 5 # the book
5 9 # book thing
6 9 # is thing
7 9 # a thing
8 9 # surprising thing
9 3 # thing reading


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
John-uy chayk-ul ilk- um-i nolawu-n sasil-i-ta
John-GEN book-ACC read-NOMINAL-NOM surprise-V.PRENOM fact-be- PRES-DECL

1 1 # John-uy John-GEN
 1.1 1.1 # John John
 1.2 1.2 # -uy -GEN
2 2 # chayk-ul book-ACC
 2.1 2.1 # chayk book
 2.2 2.2 # -ul -ACC
3 3 # ilk- read-NOMINAL-NOM
4 4 # um-i surprise-V.PRENOM
 4.1 4.1 # um surprise
 4.2 4.2 # -i -V.PRENOM
5 5 # nolawu-n fact-be-
 5.1 5.1 # nolawu fact
 5.2 5.2 # -n -be
6 6 # sasil-i-ta PRES-DECL
 6.1 0 # sasil NULL
 6.2 0 # -i NULL
 6.3 0 # -ta NULL

######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
John-GEN book-ACC read-NOMINAL-NOM surprise-V.PRENOM fact-be- PRES-DECL
John 's reading the book is a surprising thing

1 1 # John-GEN John
 1.1 1 # John John
 1.2 0 # -GEN NULL
2 5 # book-ACC book
 2.1 5 # book book
 2.2 0 # -ACC NULL
3 3 # read-NOMINAL-NOM NULL x
 3.1 3 # read NULL x
 3.2 0 # -NOMINAL NULL
 3.3 0 # -NOM NULL
4 0 # surprise-V.PRENOM NULL
 4.1 0 # surprise NULL
 4.2 0 # -V.PRENOM NULL
5 0 # fact-be- NULL
 5.1 0 # fact NULL
 5.2 0 # -be NULL
6 0 # PRES-DECL NULL
 6.1 0 # PRES NULL
 6.2 0 # -DECL NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
John-uy chayk-ul ilk- um-i nolawu-n sasil-i-ta
John-GEN book-ACC read-NOMINAL-NOM surprise-V.PRENOM fact-be- PRES-DECL
John 's reading the book is a surprising thing

1 6 # John-uy sasil-i-ta
2 6 # chayk-ul sasil-i-ta
3 6 # ilk- sasil-i-ta
4 6 # um-i sasil-i-ta
5 6 # nolawu-n sasil-i-ta
6 -2 # sasil-i-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=24976 Url_id=2365 flag=0 cleaned=3 src_leng=4 trans_leng=7
John-i ttangkhong-ul sa-mek-ess-ta .
Nom peanuts-Acc buy-eat-Past-Decl .
John bought peanuts and ate them .

######## Q1: IGT is clean? Answer: y
#dj The 2nd line does not repeat the name John, marking it only as nom.
#dj The Korean DS turns out OK because everything depends on the compound 
#dj verb, but ...


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VP (VBD bought) (NP (NNS peanuts))) (CC and) (VP (VBD ate) (NP (PRP them)))) (. .))

(S+ate (NP+John (NNP John))
       (VP+ate (VP+bought (VBD bought)
                          (NP+peanuts (NNS peanuts)))
               (CC and)
               (VP+ate (VBD ate)
                       (NP+them (PRP them))))
       (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John bought peanuts and ate them .
1 5 # John ate
2 5 # bought ate
3 2 # peanuts bought
4 5 # and ate
5 -1 # ate *TOP*
6 5 # them ate
7 5 # . ate


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-i ttangkhong-ul sa-mek-ess-ta .
Nom peanuts-Acc buy-eat-Past-Decl .

1 1 # John-i Nom
 1.1 0 # John NULL
 1.2 0 # -i NULL
2 2 # ttangkhong-ul peanuts-Acc
 2.1 2.1 # ttangkhong peanuts
 2.2 2.2 # -ul -Acc
3 3 # sa-mek-ess-ta buy-eat-Past-Decl
 3.1 3.1 # sa buy
 3.2 3.2 # -mek -eat
 3.3 3.3 # -ess -Past
 3.4 3.4 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Nom peanuts-Acc buy-eat-Past-Decl .
John bought peanuts and ate them .

1 1 # Nom NULL x
2 3 # peanuts-Acc peanuts
 2.1 3 # peanuts peanuts
 2.2 0 # -Acc NULL
3 2,5 # buy-eat-Past-Decl bought,ate
 3.1 2 # buy bought
 3.2 5 # -eat ate
 3.3 0 # -Past NULL
 3.4 0 # -Decl NULL
4 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: x 


############################# Q6: src DS
John-i ttangkhong-ul sa-mek-ess-ta .
Nom peanuts-Acc buy-eat-Past-Decl .
John bought peanuts and ate them .

1 3 # John-i sa-mek-ess-ta
2 3 # ttangkhong-ul sa-mek-ess-ta
3 -1 # sa-mek-ess-ta *TOP*
4 3 # . sa-mek-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=28756 Url_id=2706 flag=0 cleaned=4 src_leng=4 trans_leng=6
John-uy Mary-wa-uy tayhwa .
John-Gen Mary-with-Gen talk .
John 's talk with Mary .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBZ 's) (NP (NP (NN talk)) (PP (IN with) (NP (NNP Mary))))) (. .))

(S+talk (NP+John (NNP John))
        (VP+talk (VBZ 's)
                 (NP-PRD+talk (NP+talk (NN talk))
                              (PP+with (IN with)
                                       (NP+Mary (NNP Mary)))))
        (. .))


###### Q2: English parse tree is correct? Answer: n
#dj this is an NP fragment, but it's parsed as an S


###############################  Q3: English DS 
John 's talk with Mary .
1 2 # John talk x
2 3 # 's talk
3 -1 # talk *TOP*
4 3 # with talk
5 4 # Mary with
6 3 # . talk


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
John-uy Mary-wa-uy tayhwa .
John-Gen Mary-with-Gen talk .

1 1 # John-uy John-Gen
 1.1 1.1 # John John
 1.2 1.2 # -uy -Gen
2 2 # Mary-wa-uy Mary-with-Gen
 2.1 2.1 # Mary Mary
 2.2 2.2 # -wa -with
 2.3 2.3 # -uy -Gen
3 3 # tayhwa talk
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Gen Mary-with-Gen talk .
John 's talk with Mary .

1 1,2 # John-Gen John
 1.1 1 # John John
 1.2 2 # -Gen NULL x
2 4,5 # Mary-with-Gen with,Mary
 2.1 5 # Mary Mary
 2.2 4 # -with with
 2.3 0 # -Gen NULL
3 3 # talk talk
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-uy Mary-wa-uy tayhwa .
John-Gen Mary-with-Gen talk .
John 's talk with Mary .

1 3 # John-uy tayhwa
2 3 # Mary-wa-uy tayhwa
3 -1 # tayhwa *TOP*
4 3 # . tayhwa


####### Q6: src DS is correct? Answer: y
#dj head-final, it makes it so easy...




###########################################################
Igt_id=28757 Url_id=2706 flag=0 cleaned=1 src_leng=3 trans_leng=5
John-uy yenge-uy kongpu
John-Gen English-Gen study
John 's study of English

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(NP (NP (NP (NNP John) (POS 's)) (NN study)) (PP (IN of) (NP (NNP English))))

(NP+study (NP+study (NP+'s (NNP John)
                           (POS 's))
                    (NN study))
          (PP+of (IN of)
                 (NP+English (NNP English))))


###### Q2: English parse tree is correct? Answer: n
#dj "John's" depends on "study of English"



###############################  Q3: English DS 
John 's study of English
1 2 # John 's
2 3 # 's study
3 -1 # study *TOP*
4 3 # of study
5 4 # English of


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-uy yenge-uy kongpu
John-Gen English-Gen study

1 1 # John-uy John-Gen
 1.1 1.1 # John John
 1.2 1.2 # -uy -Gen
2 2 # yenge-uy English-Gen
 2.1 2.1 # yenge English
 2.2 2.2 # -uy -Gen
3 3 # kongpu study

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Gen English-Gen study
John 's study of English

1 1,2 # John-Gen John x
 1.1 1 # John John
 1.2 2 # -Gen NULL
2 5,4 # English-Gen English x
 2.1 5 # English English
 2.2 4 # -Gen NULL
3 3 # study study


######## Q5: gloss and translation alignment is correct? Answer: n
#dj do we want to relate 's with GEN or of with GEN? Seems to make sense?


############################# Q6: src DS
John-uy yenge-uy kongpu
John-Gen English-Gen study
John 's study of English

1 3 # John-uy kongpu
2 3 # yenge-uy kongpu
3 -1 # kongpu *TOP*


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=7777 Url_id=273 flag=0 cleaned=3 src_leng=6 trans_leng=6
Waynamyen ku-ka na-ekey kulehkey malha-ess-e .
Because he-NOM I-DAT so say-PAST-DCL .
Because he told me so .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (RB Because) (NP (PRP he)) (VP (VBD told) (NP (PRP me)) (ADVP (RB so))) (. .))

(S+told (RB Because)
        (NP+he (PRP he))
        (VP+told (VBD told)
                 (NP+me (PRP me))
                 (ADVP+so (RB so)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Because he told me so .
1 3 # Because told
2 3 # he told
3 -1 # told *TOP*
4 3 # me told
5 3 # so told
6 3 # . told


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Waynamyen ku-ka na-ekey kulehkey malha-ess-e .
Because he-NOM I-DAT so say-PAST-DCL .

1 1 # Waynamyen Because
2 2 # ku-ka he-NOM
 2.1 2.1 # ku he
 2.2 2.2 # -ka -NOM
3 3 # na-ekey I-DAT
 3.1 3.1 # na I
 3.2 3.2 # -ekey -DAT
4 4 # kulehkey so
5 5 # malha-ess-e say-PAST-DCL
 5.1 5.1 # malha say
 5.2 5.2 # -ess -PAST
 5.3 5.3 # -e -DCL
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Because he-NOM I-DAT so say-PAST-DCL .
Because he told me so .

1 1 # Because Because
2 2 # he-NOM he
 2.1 2 # he he
 2.2 0 # -NOM NULL
3 4 # I-DAT NULL x
 3.1 4 # I NULL x
 3.2 0 # -DAT NULL
4 5 # so so
5 3 # say-PAST-DCL NULL x
 5.1 3 # say NULL x
 5.2 3 # -PAST NULL x
 5.3 0 # -DCL NULL
6 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj mapping issue "say" / "tell"


############################# Q6: src DS
Waynamyen ku-ka na-ekey kulehkey malha-ess-e .
Because he-NOM I-DAT so say-PAST-DCL .
Because he told me so .

1 5 # Waynamyen malha-ess-e
2 5 # ku-ka malha-ess-e
3 5 # na-ekey malha-ess-e
4 5 # kulehkey malha-ess-e
5 -1 # malha-ess-e NULL x
6 5 # . malha-ess-e


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=17927 Url_id=386 flag=0 cleaned=3 src_leng=4 trans_leng=6
tungpwul-i pang-ul palk-hi-n-ta .
lamp-Nom room-Acc bright-Cau-Pre-Dec .
The lamp lights the room .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN lamp)) (VP (NNS lights) (NP (DT the) (NN room))) (. .))

(S+room (NP+lamp (DT The)
                 (NN lamp))
        (VP+room (NNS lights)
                 (NP+room (DT the)
                          (NN room)))
        (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
The lamp lights the room .
1 2 # The lamp
2 3 # lamp room x
3 -1 # lights room x
4 5 # the room
5 3 # room *TOP* x
6 5 # . room


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
tungpwul-i pang-ul palk-hi-n-ta .
lamp-Nom room-Acc bright-Cau-Pre-Dec .

1 1 # tungpwul-i lamp-Nom
 1.1 1.1 # tungpwul lamp
 1.2 1.2 # -i -Nom
2 2 # pang-ul room-Acc
 2.1 2.1 # pang room
 2.2 2.2 # -ul -Acc
3 3 # palk-hi-n-ta bright-Cau-Pre-Dec
 3.1 3.1 # palk bright
 3.2 3.2 # -hi -Cau
 3.3 3.3 # -n -Pre
 3.4 3.4 # -ta -Dec
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
lamp-Nom room-Acc bright-Cau-Pre-Dec .
The lamp lights the room .

1 2 # lamp-Nom lamp
 1.1 2 # lamp lamp
 1.2 0 # -Nom NULL
2 5 # room-Acc room
 2.1 5 # room room
 2.2 0 # -Acc NULL
3 3 # bright-Cau-Pre-Dec NULL x
 3.1 3 # bright NULL x
 3.2 3 # -Cau NULL x
 3.3 0 # -Pre NULL
 3.4 0 # -Dec NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: ?
#dj What to do here? "causes to be bright" "lights"? semantically 
#dj there's a mapping. syntactically, I'm not sure. Syntactically
#dj in Korean, this is a causitive construction.


############################# Q6: src DS
tungpwul-i pang-ul palk-hi-n-ta .
lamp-Nom room-Acc bright-Cau-Pre-Dec .
The lamp lights the room .

1 3 # tungpwul-i pang-ul x
2 3 # pang-ul *TOP* x
3 -1 # palk-hi-n-ta pang-ul x
4 3 # . pang-ul x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=17928 Url_id=386 flag=0 cleaned=3 src_leng=4 trans_leng=5
Swuni-ka wuyu-lul kkulh-i-n-ta .
Swuni-Nom milk-Acc boil-Cau-Pre-Dec .
Suni boils the milk .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Suni)) (VP (VBZ boils) (NP (DT the) (NN milk))) (. .))

(S+boils (NP+Suni (NNP Suni))
         (VP+boils (VBZ boils)
                   (NP+milk (DT the)
                            (NN milk)))
         (. .))


###### Q2: English parse tree is correct? Answer: y
#dj This is one of those causitive constructions again.



###############################  Q3: English DS 
Suni boils the milk .
1 2 # Suni boils
2 -1 # boils *TOP*
3 4 # the milk
4 2 # milk boils
5 2 # . boils


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Swuni-ka wuyu-lul kkulh-i-n-ta .
Swuni-Nom milk-Acc boil-Cau-Pre-Dec .

1 1 # Swuni-ka Swuni-Nom
 1.1 1.1 # Swuni Swuni
 1.2 1.2 # -ka -Nom
2 2 # wuyu-lul milk-Acc
 2.1 2.1 # wuyu milk
 2.2 2.2 # -lul -Acc
3 3 # kkulh-i-n-ta boil-Cau-Pre-Dec
 3.1 3.1 # kkulh boil
 3.2 3.2 # -i -Cau
 3.3 3.3 # -n -Pre
 3.4 3.4 # -ta -Dec
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Swuni-Nom milk-Acc boil-Cau-Pre-Dec .
Suni boils the milk .

1 1 # Swuni-Nom NULL x
 1.1 1 # Swuni NULL x
#dj Transcription issue, English vs Yale...
 1.2 0 # -Nom NULL
2 4 # milk-Acc milk
 2.1 4 # milk milk
 2.2 0 # -Acc NULL
3 2 # boil-Cau-Pre-Dec boils
 3.1 2 # boil boils
 3.2 0 # -Cau NULL
 3.3 0 # -Pre NULL
 3.4 0 # -Dec NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Swuni-ka wuyu-lul kkulh-i-n-ta .
Swuni-Nom milk-Acc boil-Cau-Pre-Dec .
Suni boils the milk .

1 3 # Swuni-ka kkulh-i-n-ta
2 3 # wuyu-lul kkulh-i-n-ta
3 -1 # kkulh-i-n-ta *TOP*
4 3 # . kkulh-i-n-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=17929 Url_id=386 flag=0 cleaned=3 src_leng=6 trans_leng=6
na-nun ku pwun-i ttena-key hay-ss-ta .
I-Top that one-Nom leave-Com do-Past-Dec .
I made that one leave .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD made) (S (NP (DT that) (NN one)) (VP (VB leave)))) (. .))

(S+made (NP+I (PRP I))
        (VP+made (VBD made)
                 (S+leave (NP+one (DT that)
                                  (NN one))
                          (VP+leave (VB leave))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
I made that one leave .
1 2 # I made
2 -1 # made *TOP*
3 4 # that one
4 5 # one leave
5 2 # leave made
6 2 # . made


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
na-nun ku pwun-i ttena-key hay-ss-ta .
I-Top that one-Nom leave-Com do-Past-Dec .

1 1 # na-nun I-Top
 1.1 1.1 # na I
 1.2 1.2 # -nun -Top
2 2 # ku that
3 3 # pwun-i one-Nom
 3.1 3.1 # pwun one
 3.2 3.2 # -i -Nom
4 4 # ttena-key leave-Com
 4.1 4.1 # ttena leave
 4.2 4.2 # -key -Com
5 5 # hay-ss-ta do-Past-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Past
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Top that one-Nom leave-Com do-Past-Dec .
I made that one leave .

1 1 # I-Top I
 1.1 1 # I I
 1.2 0 # -Top NULL
2 3 # that that
3 4 # one-Nom one
 3.1 4 # one one
 3.2 0 # -Nom NULL
4 5 # leave-Com leave
 4.1 5 # leave leave
 4.2 0 # -Com NULL
5 2 # do-Past-Dec NULL x
 5.1 2 # do NULL x
 5.2 0 # -Past NULL 
 5.3 0 # -Dec NULL
6 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj There is a very common "make" "do" alternation in many languages.
#dj do we want to build that into our processing.


############################# Q6: src DS
na-nun ku pwun-i ttena-key hay-ss-ta .
I-Top that one-Nom leave-Com do-Past-Dec .
I made that one leave .

1 5 # na-nun hay-ss-ta
2 3 # ku pwun-i
3 4 # pwun-i ttena-key
4 5 # ttena-key hay-ss-ta
5 -1 # hay-ss-ta NULL x
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: n
#dj I've been marking these as incorrect when the head
#dj isn't recognized as the head. Somehow NULL and *TOP*
#dj don't seem to be the same....





###########################################################
Igt_id=17930 Url_id=386 flag=0 cleaned=3 src_leng=6 trans_leng=9
nay-ka sikmo-ka achim-pwuthe ilha-key hay-ss-ta .
I-Nom maid-Nom morning-from work-Com do-Past-Dec .
I made the maid [work starting this morning] .

######## Q1: IGT is clean? Answer: y
#dj We have the spurious brackets in the third line that may
#dj interfere with alignment later...


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD made) (S (NP (DT the) (NN maid)) (VP (VB [work) (S (VP (VBG starting) (NP (DT this) (NN morning]))))))) (. .))

(S+made (NP+I (PRP I))
        (VP+made (VBD made)
                 (S+[work (NP+maid (DT the)
                                   (NN maid))
                          (VP+[work (VB [work)
                                    (S+starting (VP+starting (VBG starting)
                                                             (NP+morning] (DT this)
                                                                          (NN morning])))))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
I made the maid [work starting this morning] .
1 2 # I made
2 -1 # made *TOP*
3 4 # the maid
4 5 # maid [work
5 2 # [work made
6 5 # starting [work
7 8 # this morning]
8 6 # morning] starting
9 2 # . made


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
nay-ka sikmo-ka achim-pwuthe ilha-key hay-ss-ta .
I-Nom maid-Nom morning-from work-Com do-Past-Dec .

1 1 # nay-ka I-Nom
 1.1 1.1 # nay I
 1.2 1.2 # -ka -Nom
2 2 # sikmo-ka maid-Nom
 2.1 2.1 # sikmo maid
 2.2 2.2 # -ka -Nom
3 3 # achim-pwuthe morning-from
 3.1 3.1 # achim morning
 3.2 3.2 # -pwuthe -from
4 4 # ilha-key work-Com
 4.1 4.1 # ilha work
 4.2 4.2 # -key -Com
5 5 # hay-ss-ta do-Past-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Past
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Nom maid-Nom morning-from work-Com do-Past-Dec .
I made the maid [work starting this morning] .

1 1 # I-Nom I
 1.1 1 # I I
 1.2 0 # -Nom NULL
2 4 # maid-Nom maid
 2.1 4 # maid maid
 2.2 0 # -Nom NULL
3 8,6 # morning-from NULL x
 3.1 8 # morning NULL x
 3.2 6 # -from NULL x
4 0 # work-Com NULL
 4.1 5 # work NULL x
 4.2 0 # -Com NULL
5 2 # do-Past-Dec NULL
 5.1 2 # do NULL x
 5.2 0 # -Past NULL 
 5.3 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj once again, "make" "do" alternation, also the [ does mess us up.


############################# Q6: src DS
nay-ka sikmo-ka achim-pwuthe ilha-key hay-ss-ta .
I-Nom maid-Nom morning-from work-Com do-Past-Dec .
I made the maid [work starting this morning] .

1 5 # nay-ka hay-ss-ta
2 4 # sikmo-ka hay-ss-ta x
3 4 # achim-pwuthe hay-ss-ta x
4 5 # ilha-key hay-ss-ta
5 -1 # hay-ss-ta NULL x
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=17931 Url_id=386 flag=0 cleaned=3 src_leng=6 trans_leng=8
sensayngnim-i na-lul chayk-ul ilk-key hay-ss-ta .
professor-Nom me-Acc book-Ac read-Com do-Past-Dec .
The professor had me read the book .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN professor)) (VP (VBD had) (S (NP (PRP me)) (VP (VB read) (NP (DT the) (NN book))))) (. .))

(S+had (NP+professor (DT The)
                     (NN professor))
       (VP+had (VBD had)
               (S+read (NP+me (PRP me))
                       (VP+read (VB read)
                                (NP+book (DT the)
                                         (NN book)))))
       (. .))


###### Q2: English parse tree is correct? Answer: y
#dj once again, it depends on how we want to handle causitive verbs



###############################  Q3: English DS 
The professor had me read the book .
1 2 # The professor
2 3 # professor had
3 -1 # had *TOP*
4 5 # me read
5 3 # read had
6 7 # the book
7 5 # book read
8 3 # . had


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
sensayngnim-i na-lul chayk-ul ilk-key hay-ss-ta .
professor-Nom me-Acc book-Ac read-Com do-Past-Dec .

1 1 # sensayngnim-i professor-Nom
 1.1 1.1 # sensayngnim professor
 1.2 1.2 # -i -Nom
2 2 # na-lul me-Acc
 2.1 2.1 # na me
 2.2 2.2 # -lul -Acc
3 3 # chayk-ul book-Ac
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Ac
4 4 # ilk-key read-Com
 4.1 4.1 # ilk read
 4.2 4.2 # -key -Com
5 5 # hay-ss-ta do-Past-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Past
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
professor-Nom me-Acc book-Ac read-Com do-Past-Dec .
The professor had me read the book .

1 2 # professor-Nom professor
 1.1 2 # professor professor
 1.2 0 # -Nom NULL
2 4 # me-Acc me
 2.1 4 # me me
 2.2 0 # -Acc NULL
3 7 # book-Ac book
 3.1 7 # book book
 3.2 0 # -Ac NULL
4 5 # read-Com read
 4.1 5 # read read
 4.2 0 # -Com NULL
5 3 # do-Past-Dec NULL x
 5.1 3 # do NULL x
 5.2 0 # -Past NULL 
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj again, this is the "do" "make" alternation issue


############################# Q6: src DS
sensayngnim-i na-lul chayk-ul ilk-key hay-ss-ta .
professor-Nom me-Acc book-Ac read-Com do-Past-Dec .
The professor had me read the book .

1 5 # sensayngnim-i hay-ss-ta
2 4 # na-lul ilk-key
3 4 # chayk-ul ilk-key
4 5 # ilk-key hay-ss-ta
5 -1 # hay-ss-ta NULL x
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=20940 Url_id=386 flag=0 cleaned=0 src_leng=4 trans_leng=8
emeni-ka atul-ekey cacangka-lul pule-e-cwu-ess-ta
mother-Nom son-Dat lullaby-Acc sing-PF-give-Past-Dec
The mother sang a lullaby for the son

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN mother)) (VP (VBD sang) (NP (NP (DT a) (NN lullaby)) (PP (IN for) (NP (DT the) (NN son))))))

(S+sang (NP+mother (DT The)
                   (NN mother))
        (VP+sang (VBD sang)
                 (NP+lullaby (NP+lullaby (DT a)
                                         (NN lullaby))
                             (PP+for (IN for)
                                     (NP+son (DT the)
                                             (NN son))))))


###### Q2: English parse tree is correct? Answer: n
#dj PP attachment



###############################  Q3: English DS 
The mother sang a lullaby for the son
1 2 # The mother
2 3 # mother sang
3 -1 # sang *TOP*
4 5 # a lullaby
5 3 # lullaby sang
6 5 3 for lullaby x
7 8 # the son
8 6 # son for


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
emeni-ka atul-ekey cacangka-lul pule-e-cwu-ess-ta
mother-Nom son-Dat lullaby-Acc sing-PF-give-Past-Dec

1 1 # emeni-ka mother-Nom
 1.1 1.1 # emeni mother
 1.2 1.2 # -ka -Nom
2 2 # atul-ekey son-Dat
 2.1 2.1 # atul son
 2.2 2.2 # -ekey -Dat
3 3 # cacangka-lul lullaby-Acc
 3.1 3.1 # cacangka lullaby
 3.2 3.2 # -lul -Acc
4 4 # pule-e-cwu-ess-ta sing-PF-give-Past-Dec
 4.1 4.1 # pule sing
 4.2 4.2 # -e -PF
 4.3 4.3 # -cwu -give
 4.4 4.4 # -ess -Past
 4.5 4.5 # -ta -Dec

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
mother-Nom son-Dat lullaby-Acc sing-PF-give-Past-Dec
The mother sang a lullaby for the son

1 2 # mother-Nom mother
 1.1 2 # mother mother
 1.2 0 # -Nom NULL
2 8,6 # son-Dat son
 2.1 8 # son son
 2.2 6 # -Dat NULL
3 5 # lullaby-Acc lullaby
 3.1 5 # lullaby lullaby
 3.2 0 # -Acc NULL
4 3 # sing-PF-give-Past-Dec sang
 4.1 3 # sing sang
 4.2 0 # -PF NULL
 4.3 0 # -give NULL
 4.4 0 # -Past NULL 
 4.5 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: y
#dj synthetic verbs ... sang = sing + PAST?


############################# Q6: src DS
emeni-ka atul-ekey cacangka-lul pule-e-cwu-ess-ta
mother-Nom son-Dat lullaby-Acc sing-PF-give-Past-Dec
The mother sang a lullaby for the son

1 4 # emeni-ka pule-e-cwu-ess-ta
2 4 # atul-ekey pule-e-cwu-ess-ta
3 4 # cacangka-lul pule-e-cwu-ess-ta
4 -1 # pule-e-cwu-ess-ta *TOP*


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=6456 Url_id=386 flag=0 cleaned=1 src_leng=4 trans_leng=5
Chelswu-ka say os-ul ip-ess-ta
Chelswu-Nom new clothes-Acc wear-Past-Dec
Chelswu wore the new clothes

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBD wore) (NP (DT the) (JJ new) (NNS clothes))))

(S+wore (NP+Chelswu (NNP Chelswu))
        (VP+wore (VBD wore)
                 (NP+clothes (DT the)
                             (JJ new)
                             (NNS clothes))))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu wore the new clothes
1 2 # Chelswu wore
2 -1 # wore *TOP*
3 5 # the clothes
4 5 # new clothes
5 2 # clothes wore


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-ka say os-ul ip-ess-ta
Chelswu-Nom new clothes-Acc wear-Past-Dec

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # say new
3 3 # os-ul clothes-Acc
 3.1 3.1 # os clothes
 3.2 3.2 # -ul -Acc
4 4 # ip-ess-ta wear-Past-Dec
 4.1 4.1 # ip wear
 4.2 4.2 # -ess -Past
 4.3 4.3 # -ta -Dec

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom new clothes-Acc wear-Past-Dec
Chelswu wore the new clothes

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 4 # new new
3 5 # clothes-Acc clothes
 3.1 5 # clothes clothes
 3.2 0 # -Acc NULL
4 2 # wear-Past-Dec wore
 4.1 2 # wear wore
 4.2 0 # -Past NULL 
 4.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: y
#dj morphology? wore = wear + PAST?


############################# Q6: src DS
Chelswu-ka say os-ul ip-ess-ta
Chelswu-Nom new clothes-Acc wear-Past-Dec
Chelswu wore the new clothes

1 4 # Chelswu-ka ip-ess-ta
2 3 # say os-ul
3 4 # os-ul ip-ess-ta
4 -1 # ip-ess-ta *TOP*


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=6457 Url_id=386 flag=0 cleaned=1 src_leng=6 trans_leng=7
nay-ka Chelswu-ka say os-ul ip-key ha-ess-ta
I-Nom Chelswu-Nom new clothes-Acc wear-Com do-Past-Dec
I made Chelswu wear the new clothes

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD made) (S (NP (NNS Chelswu)) (VP (VB wear) (NP (DT the) (JJ new) (NNS clothes))))))

(S+made (NP+I (PRP I))
        (VP+made (VBD made)
                 (S+wear (NP+Chelswu (NNS Chelswu))
                         (VP+wear (VB wear)
                                  (NP+clothes (DT the)
                                              (JJ new)
                                              (NNS clothes))))))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
I made Chelswu wear the new clothes
1 2 # I made
2 -1 # made *TOP*
3 4 # Chelswu wear
4 2 # wear made
5 7 # the clothes
6 7 # new clothes
7 4 # clothes wear


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
nay-ka Chelswu-ka say os-ul ip-key ha-ess-ta
I-Nom Chelswu-Nom new clothes-Acc wear-Com do-Past-Dec

1 1 # nay-ka I-Nom
 1.1 1.1 # nay I
 1.2 1.2 # -ka -Nom
2 2 # Chelswu-ka Chelswu-Nom
 2.1 2.1 # Chelswu Chelswu
 2.2 2.2 # -ka -Nom
3 3 # say new
4 4 # os-ul clothes-Acc
 4.1 4.1 # os clothes
 4.2 4.2 # -ul -Acc
5 5 # ip-key wear-Com
 5.1 5.1 # ip wear
 5.2 5.2 # -key -Com
6 6 # ha-ess-ta do-Past-Dec
 6.1 6.1 # ha do
 6.2 6.2 # -ess -Past
 6.3 6.3 # -ta -Dec

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Nom Chelswu-Nom new clothes-Acc wear-Com do-Past-Dec
I made Chelswu wear the new clothes

1 1 # I-Nom I
 1.1 1 # I I
 1.2 0 # -Nom NULL
2 3 # Chelswu-Nom Chelswu
 2.1 3 # Chelswu Chelswu
 2.2 0 # -Nom NULL
3 6 # new new
4 7 # clothes-Acc clothes
 4.1 7 # clothes clothes
 4.2 0 # -Acc NULL
5 4 # wear-Com wear
 5.1 4 # wear wear
 5.2 0 # -Com NULL
6 2 # do-Past-Dec NULL x
 6.1 2 # do NULL x
 6.2 0 # -Past NULL 
 6.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
nay-ka Chelswu-ka say os-ul ip-key ha-ess-ta
I-Nom Chelswu-Nom new clothes-Acc wear-Com do-Past-Dec
I made Chelswu wear the new clothes

1 6 # nay-ka ha-ess-ta
2 5 # Chelswu-ka ip-key
3 4 # say os-ul
4 5 # os-ul ip-key
5 6 # ip-key ha-ess-ta
6 -1 # ha-ess-ta NULL x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8194 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Na-nun kimchi-lul mos mek-ci anh-ass-ta .
I-Top kimchi-Acc Neg-cannot eat-Cmp NegAux-Pst-Dec .
I was not unable to eat kimchi .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD was) (RB not) (ADJP (JJ unable) (S (VP (TO to) (VP (VB eat) (NP (NNP kimchi))))))) (. .))

(S+was (NP+I (PRP I))
       (VP+was (VBD was)
               (RB not)
               (ADJP+unable (JJ unable)
                            (S+eat (VP+eat (TO to)
                                           (VP+eat (VB eat)
                                                   (NP+kimchi (NNP kimchi)))))))
       (. .))


###### Q2: English parse tree is correct? Answer: n
#dj predicate adjective



###############################  Q3: English DS 
I was not unable to eat kimchi .
1 2 # I was
2 4 # was *TOP* x
3 4 # not was x
4 -1 # unable was x
5 6 # to eat
6 4 # eat unable
7 6 # kimchi eat
8 4 # . was x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
Na-nun kimchi-lul mos mek-ci anh-ass-ta .
I-Top kimchi-Acc Neg-cannot eat-Cmp NegAux-Pst-Dec .

1 1 # Na-nun I-Top
 1.1 1.1 # Na I
 1.2 1.2 # -nun -Top
2 2 # kimchi-lul kimchi-Acc
 2.1 2.1 # kimchi kimchi
 2.2 2.2 # -lul -Acc
3 3 # mos Neg-cannot
4 4 # mek-ci eat-Cmp
 4.1 4.1 # mek eat
 4.2 4.2 # -ci -Cmp
5 5 # anh-ass-ta NegAux-Pst-Dec
 5.1 5.1 # anh NegAux
 5.2 5.2 # -ass -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Top kimchi-Acc Neg-cannot eat-Cmp NegAux-Pst-Dec .
I was not unable to eat kimchi .

1 1 # I-Top I
 1.1 1 # I I
 1.2 0 # -Top NULL
2 7 # kimchi-Acc kimchi
 2.1 7 # kimchi kimchi
 2.2 0 # -Acc NULL
3 4 # Neg-cannot NULL x
 3.1 0 # Neg NULL
 3.2 4 # -cannot NULL x
4 6 # eat-Cmp eat
 4.1 6 # eat eat
 4.2 0 # -Cmp NULL
5 2,3 # NegAux-Pst-Dec NULL x
 5.1 3 # NegAux NULL x
 5.2 2 # -Pst NULL x
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj This one could be handled a couple of different ways


############################# Q6: src DS
Na-nun kimchi-lul mos mek-ci anh-ass-ta .
I-Top kimchi-Acc Neg-cannot eat-Cmp NegAux-Pst-Dec .
I was not unable to eat kimchi .

1 5 # Na-nun anh-ass-ta
2 4 # kimchi-lul mek-ci
3 4 # mos anh-ass-ta x
4 5 # mek-ci anh-ass-ta 
5 -1 # anh-ass-ta NULL x
6 5 # . anh-ass-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8196 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=7
Apeci-kkeyse atul-eykey ton-ul cwu-si-ess-ta .
father-HNom son-Dat money-Acc give-Hon-Pst-Dec .
The father gave the son money .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN father)) (VP (VBD gave) (NP (DT the) (NN son)) (NP (NN money))) (. .))

(S+gave (NP+father (DT The)
                   (NN father))
        (VP+gave (VBD gave)
                 (NP+son (DT the)
                         (NN son))
                 (NP+money (NN money)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The father gave the son money .
1 2 # The father
2 3 # father gave
3 -1 # gave *TOP*
4 5 # the son
5 3 # son gave
6 3 # money gave
7 3 # . gave


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Apeci-kkeyse atul-eykey ton-ul cwu-si-ess-ta .
father-HNom son-Dat money-Acc give-Hon-Pst-Dec .

1 1 # Apeci-kkeyse father-HNom
 1.1 1.1 # Apeci father
 1.2 1.2 # -kkeyse -HNom
2 2 # atul-eykey son-Dat
 2.1 2.1 # atul son
 2.2 2.2 # -eykey -Dat
3 3 # ton-ul money-Acc
 3.1 3.1 # ton money
 3.2 3.2 # -ul -Acc
4 4 # cwu-si-ess-ta give-Hon-Pst-Dec
 4.1 4.1 # cwu give
 4.2 4.2 # -si -Hon
 4.3 4.3 # -ess -Pst
 4.4 4.4 # -ta -Dec
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
father-HNom son-Dat money-Acc give-Hon-Pst-Dec .
The father gave the son money .

1 2 # father-HNom father
 1.1 2 # father father
 1.2 0 # -HNom NULL
2 5 # son-Dat son
 2.1 5 # son son
 2.2 0 # -Dat NULL
3 6 # money-Acc money
 3.1 6 # money money
 3.2 0 # -Acc NULL
4 3 # give-Hon-Pst-Dec gave
 4.1 3 # give gave
 4.2 0 # -Hon NULL
 4.3 0 # -Pst NULL
 4.4 0 # -Dec NULL
5 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Apeci-kkeyse atul-eykey ton-ul cwu-si-ess-ta .
father-HNom son-Dat money-Acc give-Hon-Pst-Dec .
The father gave the son money .

1 4 # Apeci-kkeyse cwu-si-ess-ta
2 4 # atul-eykey cwu-si-ess-ta
3 4 # ton-ul cwu-si-ess-ta
4 -1 # cwu-si-ess-ta *TOP*
5 4 # . cwu-si-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8197 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=7
Atul-eykey apeci-kkeyse ton-ul cwu-si-ess-ta .
son-Dat father-HNom money-Acc give-Hon-Pst-Dec .
The father gave the son money .

######## Q1: IGT is clean? Answer: y
#dj I don't know how you want to handle this, there are several
#dj IGT that have virtually the same translation. We just see
#dj differences in the word-order in Korean, primarily for emphasis.
#dj 8196, 8197, 8198, 8199


############################## Q2: English parse tree 
(S (NP (DT The) (NN father)) (VP (VBD gave) (NP (DT the) (NN son)) (NP (NN money))) (. .))

(S+gave (NP+father (DT The)
                   (NN father))
        (VP+gave (VBD gave)
                 (NP+son (DT the)
                         (NN son))
                 (NP+money (NN money)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The father gave the son money .
1 2 # The father
2 3 # father gave
3 -1 # gave *TOP*
4 5 # the son
5 3 # son gave
6 3 # money gave
7 3 # . gave


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Atul-eykey apeci-kkeyse ton-ul cwu-si-ess-ta .
son-Dat father-HNom money-Acc give-Hon-Pst-Dec .

1 1 # Atul-eykey son-Dat
 1.1 1.1 # Atul son
 1.2 1.2 # -eykey -Dat
2 2 # apeci-kkeyse father-HNom
 2.1 2.1 # apeci father
 2.2 2.2 # -kkeyse -HNom
3 3 # ton-ul money-Acc
 3.1 3.1 # ton money
 3.2 3.2 # -ul -Acc
4 4 # cwu-si-ess-ta give-Hon-Pst-Dec
 4.1 4.1 # cwu give
 4.2 4.2 # -si -Hon
 4.3 4.3 # -ess -Pst
 4.4 4.4 # -ta -Dec
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
son-Dat father-HNom money-Acc give-Hon-Pst-Dec .
The father gave the son money .

1 5 # son-Dat son
 1.1 5 # son son
 1.2 0 # -Dat NULL
2 2 # father-HNom father
 2.1 2 # father father
 2.2 0 # -HNom NULL
3 6 # money-Acc money
 3.1 6 # money money
 3.2 0 # -Acc NULL
4 3 # give-Hon-Pst-Dec gave
 4.1 3 # give gave
 4.2 0 # -Hon NULL
 4.3 0 # -Pst NULL
 4.4 0 # -Dec NULL
5 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Atul-eykey apeci-kkeyse ton-ul cwu-si-ess-ta .
son-Dat father-HNom money-Acc give-Hon-Pst-Dec .
The father gave the son money .

1 4 # Atul-eykey cwu-si-ess-ta
2 4 # apeci-kkeyse cwu-si-ess-ta
3 4 # ton-ul cwu-si-ess-ta
4 -1 # cwu-si-ess-ta *TOP*
5 4 # . cwu-si-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8199 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=7
Apeci-kkeyse ton-ul atul-eykey cwu-si-ess-ta .
father-HNom money-Acc son-Dat give-Hon-Pst-Dec .
The father gave the son money .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN father)) (VP (VBD gave) (NP (DT the) (NN son)) (NP (NN money))) (. .))

(S+gave (NP+father (DT The)
                   (NN father))
        (VP+gave (VBD gave)
                 (NP+son (DT the)
                         (NN son))
                 (NP+money (NN money)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The father gave the son money .
1 2 # The father
2 3 # father gave
3 -1 # gave *TOP*
4 5 # the son
5 3 # son gave
6 3 # money gave
7 3 # . gave


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Apeci-kkeyse ton-ul atul-eykey cwu-si-ess-ta .
father-HNom money-Acc son-Dat give-Hon-Pst-Dec .

1 1 # Apeci-kkeyse father-HNom
 1.1 1.1 # Apeci father
 1.2 1.2 # -kkeyse -HNom
2 2 # ton-ul money-Acc
 2.1 2.1 # ton money
 2.2 2.2 # -ul -Acc
3 3 # atul-eykey son-Dat
 3.1 3.1 # atul son
 3.2 3.2 # -eykey -Dat
4 4 # cwu-si-ess-ta give-Hon-Pst-Dec
 4.1 4.1 # cwu give
 4.2 4.2 # -si -Hon
 4.3 4.3 # -ess -Pst
 4.4 4.4 # -ta -Dec
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
father-HNom money-Acc son-Dat give-Hon-Pst-Dec .
The father gave the son money .

1 2 # father-HNom father
 1.1 2 # father father
 1.2 0 # -HNom NULL
2 6 # money-Acc money
 2.1 6 # money money
 2.2 0 # -Acc NULL
3 5 # son-Dat son
 3.1 5 # son son
 3.2 0 # -Dat NULL
4 3 # give-Hon-Pst-Dec gave
 4.1 3 # give gave
 4.2 0 # -Hon NULL
 4.3 0 # -Pst NULL
 4.4 0 # -Dec NULL
5 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Apeci-kkeyse ton-ul atul-eykey cwu-si-ess-ta .
father-HNom money-Acc son-Dat give-Hon-Pst-Dec .
The father gave the son money .

1 4 # Apeci-kkeyse cwu-si-ess-ta
2 4 # ton-ul cwu-si-ess-ta
3 4 # atul-eykey cwu-si-ess-ta
4 -1 # cwu-si-ess-ta *TOP*
5 4 # . cwu-si-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8200 Url_id=397 flag=0 cleaned=4 src_leng=6 trans_leng=7
Chelswu-ka ku chayk-ul ilk-ki-nun hay-ss-ta .
Chelswu-Nom that book-Acc read-Cmp-Top do-Pst-Dec .
Read the book , Chelswu did .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (PP (VBN Read) (NP (DT the) (NN book))) (, ,) (NP (NNP Chelswu)) (VP (VBD did)) (. .))

(S+did (PP+Read (VBN Read)
                (NP+book (DT the)
                         (NN book)))
       (, ,)
       (NP+Chelswu (NNP Chelswu))
       (VP+did (VBD did))
       (. .))


###### Q2: English parse tree is correct? Answer: y
#dj I'm marking this as correct, even though read the book is a VP
#dj not a PP, but the head is correct and its relation to the rest
#dj of the sentence is also correct.



###############################  Q3: English DS 
Read the book , Chelswu did .
1 6 # Read did
2 3 # the book
3 1 # book Read
4 6 # , did
5 6 # Chelswu did
6 -1 # did *TOP*
7 6 # . did


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-ka ku chayk-ul ilk-ki-nun hay-ss-ta .
Chelswu-Nom that book-Acc read-Cmp-Top do-Pst-Dec .

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # ku that
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-ki-nun read-Cmp-Top
 4.1 4.1 # ilk read
 4.2 4.2 # -ki -Cmp
 4.3 4.3 # -nun -Top
5 5 # hay-ss-ta do-Pst-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom that book-Acc read-Cmp-Top do-Pst-Dec .
Read the book , Chelswu did .

1 5 # Chelswu-Nom Chelswu
 1.1 5 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 2 # that NULL x
3 3 # book-Acc book
 3.1 3 # book book
 3.2 0 # -Acc NULL
4 1 # read-Cmp-Top Read
 4.1 1 # read Read
 4.2 0 # -Cmp NULL
 4.3 0 # -Top NULL
5 6 # do-Pst-Dec did
 5.1 6 # do did
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Chelswu-ka ku chayk-ul ilk-ki-nun hay-ss-ta .
Chelswu-Nom that book-Acc read-Cmp-Top do-Pst-Dec .
Read the book , Chelswu did .

1 5 # Chelswu-ka hay-ss-ta
2 3 # ku hay-ss-ta x
3 4 # chayk-ul ilk-ki-nun
4 5 # ilk-ki-nun hay-ss-ta
5 -1 # hay-ss-ta *TOP*
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8202 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=5
Kong-ul Cwuni-ka cayppalli cap-a .
ball-Acc Cwuni-Nom quick catch-Pres .
Balls he catches quick .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNS Balls)) (NP (PRP he)) (VP (VBZ catches) (ADJP (JJ quick))) (. .))

(S+catches (NP+Balls (NNS Balls))
           (NP+he (PRP he))
           (VP+catches (VBZ catches)
                       (ADJP+quick (JJ quick)))
           (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Balls he catches quick .
1 3 # Balls catches
2 3 # he catches
3 -1 # catches *TOP*
4 3 # quick catches
5 3 # . catches


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Kong-ul Cwuni-ka cayppalli cap-a .
ball-Acc Cwuni-Nom quick catch-Pres .

1 1 # Kong-ul ball-Acc
 1.1 1.1 # Kong ball
 1.2 1.2 # -ul -Acc
2 2 # Cwuni-ka Cwuni-Nom
 2.1 2.1 # Cwuni Cwuni
 2.2 2.2 # -ka -Nom
3 3 # cayppalli quick
4 4 # cap-a catch-Pres
 4.1 4.1 # cap catch
 4.2 4.2 # -a -Pres
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
ball-Acc Cwuni-Nom quick catch-Pres .
Balls he catches quick .

1 1 # ball-Acc Balls
 1.1 1 # ball Balls
 1.2 0 # -Acc NULL
2 2 # Cwuni-Nom NULL x
 2.1 2 # Cwuni NULL x
 2.2 0 # -Nom NULL
3 4 # quick quick
4 3 # catch-Pres catches
 4.1 3 # catch catches
 4.2 0 # -Pres NULL
5 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj The translation uses a pronoun rather than the name.
#dj Alternately, one could say the alignment is correct, but the
#dj disparity in the two lines accounts for the mismatch...


############################# Q6: src DS
Kong-ul Cwuni-ka cayppalli cap-a .
ball-Acc Cwuni-Nom quick catch-Pres .
Balls he catches quick .

1 4 # Kong-ul cap-a
2 4 # Cwuni-ka cap-a
3 4 # cayppalli cap-a
4 -1 # cap-a *TOP*
5 4 # . cap-a


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8203 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=9
Komo-ka kocong.sachon-ul kakkum cay-wu-ess-ta .
aunt-Nom cousin-Acc sometimes put.to.sleep-Pst-Dec .
My aunt put my cousin to sleep sometimes .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP$ My) (NN aunt)) (VP (VBD put) (S (NP (PRP$ my) (NN cousin)) (VP (TO to) (VP (VB sleep) (ADVP (RB sometimes)))))) (. .))

(S+put (NP+aunt (PRP$ My)
                (NN aunt))
       (VP+put (VBD put)
               (S+sleep (NP+cousin (PRP$ my)
                                   (NN cousin))
                        (VP+sleep (TO to)
                                  (VP+sleep (VB sleep)
                                            (ADVP+sometimes (RB sometimes))))))
       (. .))


###### Q2: English parse tree is correct? Answer: n
#dj I consider "to sleep" a PP, as in "put to death" or 
#dj "put to pasture"



###############################  Q3: English DS 
My aunt put my cousin to sleep sometimes .
1 2 # My aunt
2 3 # aunt put
3 -1 # put *TOP*
4 5 # my cousin
5 3 # cousin sleep
6 3 # to sleep
7 6 # sleep put
8 3 # sometimes sleep
9 3 # . put


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
Komo-ka kocong.sachon-ul kakkum cay-wu-ess-ta .
aunt-Nom cousin-Acc sometimes put.to.sleep-Pst-Dec .

1 1 # Komo-ka aunt-Nom
 1.1 1.1 # Komo aunt
 1.2 1.2 # -ka -Nom
2 2 # kocong.sachon-ul cousin-Acc
 2.1 2.1 # kocong.sachon cousin
 2.2 2.2 # -ul -Acc
3 3 # kakkum sometimes
4 4 # cay-wu-ess-ta put.to.sleep-Pst-Dec
 4.1 4.1 # cay NULL x
 4.2 4.1 # -wu NULL x
 4.3 4.2 # -ess NULL x
 4.4 4.3 # -ta NULL x
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: n
#dj I'm not sure why they broke the caywu into two pieces
#dj it's a single morpheme; I guess it "reads" better this
#dj way, but ...



######################### Q5: gloss and translation alignment
aunt-Nom cousin-Acc sometimes put.to.sleep-Pst-Dec .
My aunt put my cousin to sleep sometimes .

1 2 # aunt-Nom aunt
 1.1 2 # aunt aunt
 1.2 0 # -Nom NULL
2 5 # cousin-Acc cousin
 2.1 5 # cousin cousin
 2.2 0 # -Acc NULL
3 8 # sometimes sometimes
4 3,6,7 # put.to.sleep-Pst-Dec put,to,sleep
 4.1 3,6,7 # put.to.sleep put,to,sleep
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Komo-ka kocong.sachon-ul kakkum cay-wu-ess-ta .
aunt-Nom cousin-Acc sometimes put.to.sleep-Pst-Dec .
My aunt put my cousin to sleep sometimes .

1 4 # Komo-ka cay-wu-ess-ta
2 4 # kocong.sachon-ul cay-wu-ess-ta
3 4 # kakkum cay-wu-ess-ta
4 -1 # cay-wu-ess-ta *TOP*
5 4 # . cay-wu-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8205 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=9
Kocong.sachon-ul komo-nun kakkum ka-lilako kitay.ha-n-ta .
cousin-Acc aunt-Top sometimes go-Cmp expect-Pres-Dec .
My aunt expects my cousin to go sometimes .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP$ My) (NN aunt)) (VP (VBZ expects) (S (NP (PRP$ my) (NN cousin)) (VP (TO to) (VP (VB go) (ADVP (RB sometimes)))))) (. .))

(S+expects (NP+aunt (PRP$ My)
                    (NN aunt))
           (VP+expects (VBZ expects)
                       (S+go (NP+cousin (PRP$ my)
                                        (NN cousin))
                             (VP+go (TO to)
                                    (VP+go (VB go)
                                           (ADVP+sometimes (RB sometimes))))))
           (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
My aunt expects my cousin to go sometimes .
1 2 # My aunt
2 3 # aunt expects
3 -1 # expects *TOP*
4 5 # my cousin
5 7 # cousin go
6 7 # to go
7 3 # go expects
8 7 # sometimes go
9 3 # . expects


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Kocong.sachon-ul komo-nun kakkum ka-lilako kitay.ha-n-ta .
cousin-Acc aunt-Top sometimes go-Cmp expect-Pres-Dec .

1 1 # Kocong.sachon-ul cousin-Acc
 1.1 1.1 # Kocong.sachon cousin
 1.2 1.2 # -ul -Acc
2 2 # komo-nun aunt-Top
 2.1 2.1 # komo aunt
 2.2 2.2 # -nun -Top
3 3 # kakkum sometimes
4 4 # ka-lilako go-Cmp
 4.1 4.1 # ka go
 4.2 4.2 # -lilako -Cmp
5 5 # kitay.ha-n-ta expect-Pres-Dec
 5.1 5.1 # kitay.ha expect
 5.2 5.2 # -n -Pres
 5.3 5.3 # -ta -Dec
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
cousin-Acc aunt-Top sometimes go-Cmp expect-Pres-Dec .
My aunt expects my cousin to go sometimes .

1 5 # cousin-Acc cousin
 1.1 5 # cousin cousin
 1.2 0 # -Acc NULL
2 2 # aunt-Top aunt
 2.1 2 # aunt aunt
 2.2 0 # -Top NULL
3 8 # sometimes sometimes
4 7 # go-Cmp go
 4.1 7 # go go
 4.2 0 # -Cmp NULL
5 3 # expect-Pres-Dec expects
 5.1 3 # expect expects
 5.2 0 # -Pres NULL
 5.3 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Kocong.sachon-ul komo-nun kakkum ka-lilako kitay.ha-n-ta .
cousin-Acc aunt-Top sometimes go-Cmp expect-Pres-Dec .
My aunt expects my cousin to go sometimes .

1 4 # Kocong.sachon-ul ka-lilako
2 5 # komo-nun kitay.ha-n-ta
3 4 # kakkum ka-lilako
4 5 # ka-lilako kitay.ha-n-ta
5 -1 # kitay.ha-n-ta *TOP*
6 5 # . kitay.ha-n-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8439 Url_id=492 flag=0 cleaned=3 src_leng=5 trans_leng=7
John-i Mary-lul son-ul ttayli-ess-ta .
John-NOM Mary-ACC hand-ACC hit-PST-IND .
John hit Mary on the hand .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD hit) (NP (NNP Mary)) (PP (IN on) (NP (DT the) (NN hand)))) (. .))

(S+hit (NP+John (NNP John))
       (VP+hit (VBD hit)
               (NP+Mary (NNP Mary))
               (PP+on (IN on)
                      (NP+hand (DT the)
                               (NN hand))))
       (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John hit Mary on the hand .
1 2 # John hit
2 -1 # hit *TOP*
3 2 # Mary hit
4 2 # on hit
5 6 # the hand
6 4 # hand on
7 2 # . hit


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-i Mary-lul son-ul ttayli-ess-ta .
John-NOM Mary-ACC hand-ACC hit-PST-IND .

1 1 # John-i John-NOM
 1.1 1.1 # John John
 1.2 1.2 # -i -NOM
2 2 # Mary-lul Mary-ACC
 2.1 2.1 # Mary Mary
 2.2 2.2 # -lul -ACC
3 3 # son-ul hand-ACC
 3.1 3.1 # son hand
 3.2 3.2 # -ul -ACC
4 4 # ttayli-ess-ta hit-PST-IND
 4.1 4.1 # ttayli hit
 4.2 4.2 # -ess -PST
 4.3 4.3 # -ta -IND
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-NOM Mary-ACC hand-ACC hit-PST-IND .
John hit Mary on the hand .

1 1 # John-NOM John
 1.1 1 # John John
 1.2 0 # -NOM NULL
2 3 # Mary-ACC Mary
 2.1 3 # Mary Mary
 2.2 0 # -ACC NULL
3 6 # hand-ACC hand
 3.1 6 # hand hand
 3.2 0 # -ACC NULL
4 2 # hit-PST-IND hit
 4.1 2 # hit hit
 4.2 0 # -PST NULL
 4.3 0 # -IND NULL
5 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-i Mary-lul son-ul ttayli-ess-ta .
John-NOM Mary-ACC hand-ACC hit-PST-IND .
John hit Mary on the hand .

1 4 # John-i ttayli-ess-ta
2 4 # Mary-lul ttayli-ess-ta
3 4 # son-ul ttayli-ess-ta
4 -1 # ttayli-ess-ta *TOP*
5 4 # . ttayli-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8441 Url_id=564 flag=0 cleaned=0 src_leng=6 trans_leng=7
Na-nun tennis-lul ecey han sikan-tongan-ul chi-ess-
I-TOP tennis-ACC yesterday one hour-for-ACC played
Yesterday I played tennis for one hour

######## Q1: IGT is clean? Answer: n,y #dj I'll do it anyway
#dj the verb is truncated. I don't think this is a "licensed" form


############################## Q2: English parse tree 
(NP (NP (NN Yesterday)) (SBAR (S (NP (PRP I)) (VP (VBD played) (NP (NP (NN tennis)) (PP (IN for) (NP (CD one) (NN hour))))))))

(NP+Yesterday (NP+Yesterday (NN Yesterday))
              (SBAR+played (S+played (NP+I (PRP I))
                                     (VP+played (VBD played)
                                                (NP+tennis (NP+tennis (NN tennis))
                                                           (PP+for (IN for)
                                                                   (NP+hour (CD one)
                                                                            (NN hour))))))))


###### Q2: English parse tree is correct? Answer: n
#dj yesterday is actually a displaced piece of the VP.



###############################  Q3: English DS 
Yesterday I played tennis for one hour
1 3 # Yesterday *TOP* x
2 3 # I played
3 -1 # played Yesterday x
4 3 # tennis played
5 3 # for tennis
6 7 # one hour
7 5 # hour for


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
Na-nun tennis-lul ecey han sikan-tongan-ul chi-ess-
I-TOP tennis-ACC yesterday one hour-for-ACC played

1 1 # Na-nun I-TOP
 1.1 1.1 # Na I
 1.2 1.2 # -nun -TOP
2 2 # tennis-lul tennis-ACC
 2.1 2.1 # tennis tennis
 2.2 2.2 # -lul -ACC
3 3 # ecey yesterday
4 4 # han one
5 5 # sikan-tongan-ul hour-for-ACC
 5.1 5.1 # sikan hour
 5.2 5.2 # -tongan -for
 5.3 5.3 # -ul -ACC
6 6 # chi-ess- played
 6.1 0 # chi NULL
 6.2 0 # -ess NULL

######## Q4: src and gloss alignment is correct? Answer: y
#dj 6 matches 6 ... that's as much as we can do ...



######################### Q5: gloss and translation alignment
I-TOP tennis-ACC yesterday one hour-for-ACC played
Yesterday I played tennis for one hour

1 2 # I-TOP I
 1.1 2 # I I
 1.2 0 # -TOP NULL
2 4 # tennis-ACC tennis
 2.1 4 # tennis tennis
 2.2 0 # -ACC NULL
3 1 # yesterday Yesterday
4 6 # one one
5 5,7 # hour-for-ACC for,hour
 5.1 7 # hour hour
 5.2 5 # -for for
 5.3 0 # -ACC NULL
6 3 # played played


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Na-nun tennis-lul ecey han sikan-tongan-ul chi-ess-
I-TOP tennis-ACC yesterday one hour-for-ACC played
Yesterday I played tennis for one hour

1 6 # Na-nun chi-ess-
2 6 # tennis-lul chi-ess-
3 6 # ecey *TOP* x
4 5 # han sikan-tongan-ul
5 6 # sikan-tongan-ul tennis-lul x
6 -1 # chi-ess- ecey x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8444 Url_id=564 flag=0 cleaned=0 src_leng=4 trans_leng=6
John-un Seoul yek-ey-lul tochak-ha-ess-ta
John-TOP Seoul Station-to-ACC arrival-do-PST-DECL
John arrived at the Seoul Station

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD arrived) (PP (IN at) (NP (DT the) (NNP Seoul) (NN Station)))))

(S+arrived (NP+John (NNP John))
           (VP+arrived (VBD arrived)
                       (PP+at (IN at)
                              (NP+Station (DT the)
                                          (NNP Seoul)
                                          (NN Station)))))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John arrived at the Seoul Station
1 2 # John arrived
2 -1 # arrived *TOP*
3 2 # at arrived
4 6 # the Station
5 6 # Seoul Station
6 3 # Station at


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un Seoul yek-ey-lul tochak-ha-ess-ta
John-TOP Seoul Station-to-ACC arrival-do-PST-DECL

1 1 # John-un John-TOP
 1.1 1.1 # John John
 1.2 1.2 # -un -TOP
2 2 # Seoul Seoul
3 3 # yek-ey-lul Station-to-ACC
 3.1 3.1 # yek Station
 3.2 3.2 # -ey -to
 3.3 3.3 # -lul -ACC
4 4 # tochak-ha-ess-ta arrival-do-PST-DECL
 4.1 4.1 # tochak arrival
 4.2 4.2 # -ha -do
 4.3 4.3 # -ess -PST
 4.4 4.4 # -ta -DECL

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-TOP Seoul Station-to-ACC arrival-do-PST-DECL
John arrived at the Seoul Station

1 1 # John-TOP John
 1.1 1 # John John
 1.2 0 # -TOP NULL
2 5 # Seoul Seoul
3 6,3 # Station-to-ACC Station x
 3.1 6 # Station Station
 3.2 3 # -to NULL x
 3.3 0 # -ACC NULL
4 2 # arrival-do-PST-DECL NULL x
 4.1 2 # arrival NULL x
 4.2 0 # -do NULL
 4.3 0 # -PST NULL
 4.4 0 # -DECL NULL


######## Q5: gloss and translation alignment is correct? Answer: n
#dj what to do about typical prepositions?


############################# Q6: src DS
John-un Seoul yek-ey-lul tochak-ha-ess-ta
John-TOP Seoul Station-to-ACC arrival-do-PST-DECL
John arrived at the Seoul Station

1 4 # John-un tochak-ha-ess-ta
2 3 # Seoul yek-ey-lul
3 4 # yek-ey-lul tochak-ha-ess-ta
4 -1 # tochak-ha-ess-ta NULL x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8445 Url_id=564 flag=0 cleaned=0 src_leng=7 trans_leng=12
na-nun ecey i kos-ul sip meyta-mankum-ul pha-
I-TOP yesterday this spot-ACC ten meter-extent-ACC dig.out-P
Yesterday I dug out this spot to the extent of ten meters

######## Q1: IGT is clean? Answer: y
#dj like 8441, this one has pieces of the verb missing. Like 8441,
#dj I'm doing it. I figure it's easier to throw it out later.


############################## Q2: English parse tree 
(S (NP (NN Yesterday)) (NP (PRP I)) (VP (VBD dug) (PRT (RP out)) (NP (DT this) (NN spot)) (PP (TO to) (NP (NP (DT the) (NN extent)) (PP (IN of) (NP (CD ten) (NNS meters)))))))

(S+dug (NP+Yesterday (NN Yesterday))
       (NP+I (PRP I))
       (VP+dug (VBD dug)
               (PRT+out (RP out))
               (NP+spot (DT this)
                        (NN spot))
               (PP+to (TO to)
                      (NP+extent (NP+extent (DT the)
                                            (NN extent))
                                 (PP+of (IN of)
                                        (NP+meters (CD ten)
                                                   (NNS meters)))))))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Yesterday I dug out this spot to the extent of ten meters
1 3 # Yesterday dug
2 3 # I dug
3 -1 # dug *TOP*
4 3 # out dug
5 6 # this spot
6 3 # spot dug
7 3 # to dug
8 9 # the extent
9 7 # extent to
10 9 # of extent
11 12 # ten meters
12 10 # meters of


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
na-nun ecey i kos-ul sip meyta-mankum-ul pha-
I-TOP yesterday this spot-ACC ten meter-extent-ACC dig.out-P

1 1 # na-nun I-TOP
 1.1 1.1 # na I
 1.2 1.2 # -nun -TOP
2 2 # ecey yesterday
3 3 # i this
4 4 # kos-ul spot-ACC
 4.1 4.1 # kos spot
 4.2 4.2 # -ul -ACC
5 5 # sip ten
6 6 # meyta-mankum-ul meter-extent-ACC
 6.1 6.1 # meyta meter
 6.2 6.2 # -mankum -extent
 6.3 6.3 # -ul -ACC
7 7 # pha- dig.out-P

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-TOP yesterday this spot-ACC ten meter-extent-ACC dig.out-P
Yesterday I dug out this spot to the extent of ten meters

1 2 # I-TOP I
 1.1 2 # I I
 1.2 0 # -TOP NULL
2 1 # yesterday Yesterday
3 5 # this this
4 6 # spot-ACC spot
 4.1 6 # spot spot
 4.2 0 # -ACC NULL
5 11 # ten ten
6 12,9 # meter-extent-ACC meters,extent
 6.1 12 # meter meters
 6.2 9 # -extent extent
 6.3 0 # -ACC NULL
7 3,4 # dig.out-P dug,out
 7.1 3,4 # dig.out dug,out
 7.2 0 # -P NULL


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
na-nun ecey i kos-ul sip meyta-mankum-ul pha-
I-TOP yesterday this spot-ACC ten meter-extent-ACC dig.out-P
Yesterday I dug out this spot to the extent of ten meters

1 7 # na-nun pha-
2 7 # ecey pha-
3 4 # i kos-ul
4 7 # kos-ul pha-
5 6 # sip meyta-mankum-ul
6 7 # meyta-mankum-ul pha-
7 -1 # pha- *TOP*


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8452 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=6
salyengpwu-ka database-lul yuciha-n-ta .
headquarter-Nom database-Acc maintain-Pres-Decl .
The headquarter maintains the database .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (JJ headquarter)) (VP (VBZ maintains) (NP (DT the) (NN database))) (. .))

(S+maintains (NP+headquarter (DT The)
                             (JJ headquarter))
             (VP+maintains (VBZ maintains)
                           (NP+database (DT the)
                                        (NN database)))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The headquarter maintains the database .
1 2 # The headquarter
2 3 # headquarter maintains
3 -1 # maintains *TOP*
4 5 # the database
5 3 # database maintains
6 3 # . maintains


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
salyengpwu-ka database-lul yuciha-n-ta .
headquarter-Nom database-Acc maintain-Pres-Decl .

1 1 # salyengpwu-ka headquarter-Nom
 1.1 1.1 # salyengpwu headquarter
 1.2 1.2 # -ka -Nom
2 2 # database-lul database-Acc
 2.1 2.1 # database database
 2.2 2.2 # -lul -Acc
3 3 # yuciha-n-ta maintain-Pres-Decl
 3.1 3.1 # yuciha maintain
 3.2 3.2 # -n -Pres
 3.3 3.3 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
headquarter-Nom database-Acc maintain-Pres-Decl .
The headquarter maintains the database .

1 2 # headquarter-Nom headquarter
 1.1 2 # headquarter headquarter
 1.2 0 # -Nom NULL
2 5 # database-Acc database
 2.1 5 # database database
 2.2 0 # -Acc NULL
3 3 # maintain-Pres-Decl maintains
 3.1 3 # maintain maintains
 3.2 0 # -Pres NULL
 3.3 0 # -Decl NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y
#dj do we want to map the 3sg.pres "-s" to PRES?


############################# Q6: src DS
salyengpwu-ka database-lul yuciha-n-ta .
headquarter-Nom database-Acc maintain-Pres-Decl .
The headquarter maintains the database .

1 3 # salyengpwu-ka yuciha-n-ta
2 3 # database-lul yuciha-n-ta
3 -1 # yuciha-n-ta *TOP*
4 3 # . yuciha-n-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8453 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
cihwikwan-i cengpohwaltong-ul cisiha-n-ta .
commander-Nom intelligence-activity-Acc order-Pres-Decl .
The commander orders intelligence-activity .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN commander)) (VP (NNS orders) (NP (JJ intelligence-activity))) (. .))

(S+intelligence-activity (NP+commander (DT The)
                                       (NN commander))
                         (VP+intelligence-activity (NNS orders)
                                                   (NP+intelligence-activity (JJ intelligence-activity)))
                         (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
The commander orders intelligence-activity .
1 2 # The commander
2 3 # commander intelligence-activity x
3 -1 # orders intelligence-activity x
4 3 # intelligence-activity *TOP* x
5 3 # . intelligence-activity x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
cihwikwan-i cengpohwaltong-ul cisiha-n-ta .
commander-Nom intelligence-activity-Acc order-Pres-Decl .

1 1 # cihwikwan-i commander-Nom
 1.1 1.1 # cihwikwan commander
 1.2 1.2 # -i -Nom
2 2 # cengpohwaltong-ul intelligence-activity-Acc
 2.1 2.1,2.2 # cengpohwaltong NULL x
 2.2 0 # -ul NULL
3 3 # cisiha-n-ta order-Pres-Decl
 3.1 3.1 # cisiha order
 3.2 3.2 # -n -Pres
 3.3 3.3 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: n
#dj the unnecessary hyphen in "intelligence-activity" is messing
#dj things up.



######################### Q5: gloss and translation alignment
commander-Nom intelligence-activity-Acc order-Pres-Decl .
The commander orders intelligence-activity .

1 2 # commander-Nom commander
 1.1 2 # commander commander
 1.2 0 # -Nom NULL
2 3 # intelligence-activity-Acc NULL x
 2.1 3.1 # intelligence NULL x
 2.2 3.2 # -activity NULL x
 2.3 0 # -Acc NULL
3 3 # order-Pres-Decl orders
 3.1 3 # order orders
 3.2 0 # -Pres NULL
 3.3 0 # -Decl NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
cihwikwan-i cengpohwaltong-ul cisiha-n-ta .
commander-Nom intelligence-activity-Acc order-Pres-Decl .
The commander orders intelligence-activity .

1 3 # cihwikwan-i cisiha-n-ta
2 3 # cengpohwaltong-ul cisiha-n-ta
3 -1 # cisiha-n-ta NULL x
4 3 # . cisiha-n-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8454 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=8
satan-i cenpang-ulo itongha-n-ta .
unit-Nom frontline-to move-Pres-Decl .
The unit is moving to the frontline .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN unit)) (VP (VBZ is) (VP (VBG moving) (PP (TO to) (NP (DT the) (NN frontline))))) (. .))

(S+moving (NP+unit (DT The)
                   (NN unit))
          (VP+moving (VBZ is)
                     (VP+moving (VBG moving)
                                (PP+to (TO to)
                                       (NP+frontline (DT the)
                                                     (NN frontline)))))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The unit is moving to the frontline .
1 2 # The unit
2 4 # unit moving
3 4 # is moving
4 -1 # moving *TOP*
5 4 # to moving
6 7 # the frontline
7 5 # frontline to
8 4 # . moving


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
satan-i cenpang-ulo itongha-n-ta .
unit-Nom frontline-to move-Pres-Decl .

1 1 # satan-i unit-Nom
 1.1 1.1 # satan unit
 1.2 1.2 # -i -Nom
2 2 # cenpang-ulo frontline-to
 2.1 2.1 # cenpang frontline
 2.2 2.2 # -ulo -to
3 3 # itongha-n-ta move-Pres-Decl
 3.1 3.1 # itongha move
 3.2 3.2 # -n -Pres
 3.3 3.3 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
unit-Nom frontline-to move-Pres-Decl .
The unit is moving to the frontline .

1 2 # unit-Nom unit
 1.1 2 # unit unit
 1.2 0 # -Nom NULL
2 5,7 # frontline-to to,frontline
 2.1 7 # frontline frontline
 2.2 5 # -to to
3 4 # move-Pres-Decl NULL x
 3.1 0 # move NULL
 3.2 0 # -Pres NULL
 3.3 0 # -Decl NULL
4 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n
#dj giza++ ??


############################# Q6: src DS
satan-i cenpang-ulo itongha-n-ta .
unit-Nom frontline-to move-Pres-Decl .
The unit is moving to the frontline .

1 3 # satan-i itongha-n-ta
2 3 # cenpang-ulo itongha-n-ta
3 -1 # itongha-n-ta NULL x
4 3 # . itongha-n-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8455 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=6
cengpo-ka yele chwulche-lopwute yulaytoy-n-ta .
intelligence-Nom many source-from originate-Pres-Decl .
Intelligence originates from many sources .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Intelligence)) (VP (VBZ originates) (PP (IN from) (NP (JJ many) (NNS sources)))) (. .))

(S+originates (NP+Intelligence (NNP Intelligence))
              (VP+originates (VBZ originates)
                             (PP+from (IN from)
                                      (NP+sources (JJ many)
                                                  (NNS sources))))
              (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Intelligence originates from many sources .
1 2 # Intelligence originates
2 -1 # originates *TOP*
3 2 # from originates
4 5 # many sources
5 3 # sources from
6 2 # . originates


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
cengpo-ka yele chwulche-lopwute yulaytoy-n-ta .
intelligence-Nom many source-from originate-Pres-Decl .

1 1 # cengpo-ka intelligence-Nom
 1.1 1.1 # cengpo intelligence
 1.2 1.2 # -ka -Nom
2 2 # yele many
3 3 # chwulche-lopwute source-from
 3.1 3.1 # chwulche source
 3.2 3.2 # -lopwute -from
4 4 # yulaytoy-n-ta originate-Pres-Decl
 4.1 4.1 # yulaytoy originate
 4.2 4.2 # -n -Pres
 4.3 4.3 # -ta -Decl
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
intelligence-Nom many source-from originate-Pres-Decl .
Intelligence originates from many sources .

1 1 # intelligence-Nom Intelligence
 1.1 1 # intelligence Intelligence
 1.2 0 # -Nom NULL
2 4 # many many
3 3,5 # source-from from,sources
 3.1 5 # source sources
 3.2 3 # -from from
4 2 # originate-Pres-Decl originates
 4.1 2 # originate originates
 4.2 0 # -Pres NULL
 4.3 0 # -Decl NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
cengpo-ka yele chwulche-lopwute yulaytoy-n-ta .
intelligence-Nom many source-from originate-Pres-Decl .
Intelligence originates from many sources .

1 4 # cengpo-ka yulaytoy-n-ta
2 3 # yele chwulche-lopwute
3 4 # chwulche-lopwute yulaytoy-n-ta
4 -1 # yulaytoy-n-ta *TOP*
5 4 # . yulaytoy-n-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8456 Url_id=572 flag=0 cleaned=3 src_leng=6 trans_leng=7
9 satan-i salyengpwu-eykey pokose-lul ponay-ss-ta .
9 unit-Nom headquarter-to report-Acc send-Past-Decl .
9th unit sent headquarters the report .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (JJ 9th) (NN unit)) (VP (VBD sent) (NP (NN headquarters)) (NP (DT the) (NN report))) (. .))

(S+sent (NP+unit (JJ 9th)
                 (NN unit))
        (VP+sent (VBD sent)
                 (NP+headquarters (NN headquarters))
                 (NP+report (DT the)
                            (NN report)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
9th unit sent headquarters the report .
1 2 # 9th unit
2 3 # unit sent
3 -1 # sent *TOP*
4 3 # headquarters sent
5 6 # the report
6 3 # report sent
7 3 # . sent


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
9 satan-i salyengpwu-eykey pokose-lul ponay-ss-ta .
9 unit-Nom headquarter-to report-Acc send-Past-Decl .

1 1 # 9 9
2 2 # satan-i unit-Nom
 2.1 2.1 # satan unit
 2.2 2.2 # -i -Nom
3 3 # salyengpwu-eykey headquarter-to
 3.1 3.1 # salyengpwu headquarter
 3.2 3.2 # -eykey -to
4 4 # pokose-lul report-Acc
 4.1 4.1 # pokose report
 4.2 4.2 # -lul -Acc
5 5 # ponay-ss-ta send-Past-Decl
 5.1 5.1 # ponay send
 5.2 5.2 # -ss -Past
 5.3 5.3 # -ta -Decl
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
9 unit-Nom headquarter-to report-Acc send-Past-Decl .
9th unit sent headquarters the report .

1 1 # 9 NULL x
2 2 # unit-Nom unit
 2.1 2 # unit unit
 2.2 0 # -Nom NULL
3 4 # headquarter-to NULL x
 3.1 4 # headquarter NULL x
 3.2 0 # -to NULL
4 6 # report-Acc report
 4.1 6 # report report
 4.2 0 # -Acc NULL
5 3 # send-Past-Decl sent
 5.1 3 # send sent
 5.2 0 # -Past NULL
 5.3 0 # -Decl NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
9 satan-i salyengpwu-eykey pokose-lul ponay-ss-ta .
9 unit-Nom headquarter-to report-Acc send-Past-Decl .
9th unit sent headquarters the report .

1 2 # 9 ponay-ss-ta x
2 5 # satan-i ponay-ss-ta
3 5 # salyengpwu-eykey ponay-ss-ta
4 5 # pokose-lul ponay-ss-ta
5 -1 # ponay-ss-ta *TOP*
6 5 # . ponay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8457 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
chelswu-ka uysa-ka toy-ess-ta .
chelswu-Nom doctor-Nom become-Past-Decl .
Chelswu became a doctor .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBD became) (NP (DT a) (NN doctor))) (. .))

(S+became (NP+Chelswu (NNP Chelswu))
          (VP+became (VBD became)
                     (NP+doctor (DT a)
                                (NN doctor)))
          (. .))


###### Q2: English parse tree is correct? Answer: y
#dj In many ways, this is like a copula; it denotes an equivalence
#dj between the subject and predicate noun. Do we want to handle this
#dj as a copula, or as a verb?


###############################  Q3: English DS 
Chelswu became a doctor .
1 2 # Chelswu became
2 -1 # became *TOP*
3 4 # a doctor
4 2 # doctor became
5 2 # . became


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
chelswu-ka uysa-ka toy-ess-ta .
chelswu-Nom doctor-Nom become-Past-Decl .

1 1 # chelswu-ka chelswu-Nom
 1.1 1.1 # chelswu chelswu
 1.2 1.2 # -ka -Nom
2 2 # uysa-ka doctor-Nom
 2.1 2.1 # uysa doctor
 2.2 2.2 # -ka -Nom
3 3 # toy-ess-ta become-Past-Decl
 3.1 3.1 # toy become
 3.2 3.2 # -ess -Past
 3.3 3.3 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
chelswu-Nom doctor-Nom become-Past-Decl .
Chelswu became a doctor .

1 1 # chelswu-Nom Chelswu
 1.1 1 # chelswu Chelswu
 1.2 0 # -Nom NULL
2 4 # doctor-Nom doctor
 2.1 4 # doctor doctor
 2.2 0 # -Nom NULL
3 2 # become-Past-Decl became
 3.1 2 # become became
 3.2 0 # -Past NULL
 3.3 0 # -Decl NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
chelswu-ka uysa-ka toy-ess-ta .
chelswu-Nom doctor-Nom become-Past-Decl .
Chelswu became a doctor .

1 3 # chelswu-ka toy-ess-ta
2 3 # uysa-ka toy-ess-ta
3 -1 # toy-ess-ta *TOP*
4 3 # . toy-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8458 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
chelswu-ka cha-ka iss-ta .
chelswu-Nom car-Nom have-Decl .
Chelswu has a car .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBZ has) (NP (DT a) (NN car))) (. .))

(S+has (NP+Chelswu (NNP Chelswu))
       (VP+has (VBZ has)
               (NP+car (DT a)
                       (NN car)))
       (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu has a car .
1 2 # Chelswu has
2 -1 # has *TOP*
3 4 # a car
4 2 # car has
5 2 # . has


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
chelswu-ka cha-ka iss-ta .
chelswu-Nom car-Nom have-Decl .

1 1 # chelswu-ka chelswu-Nom
 1.1 1.1 # chelswu chelswu
 1.2 1.2 # -ka -Nom
2 2 # cha-ka car-Nom
 2.1 2.1 # cha car
 2.2 2.2 # -ka -Nom
3 3 # iss-ta have-Decl
 3.1 3.1 # iss have
 3.2 3.2 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
chelswu-Nom car-Nom have-Decl .
Chelswu has a car .

1 1 # chelswu-Nom Chelswu
 1.1 1 # chelswu Chelswu
 1.2 0 # -Nom NULL
2 4 # car-Nom car
 2.1 4 # car car
 2.2 0 # -Nom NULL
3 2 # have-Decl NULL x
 3.1 2 # have NULL x
 3.2 0 # -Decl NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
chelswu-ka cha-ka iss-ta .
chelswu-Nom car-Nom have-Decl .
Chelswu has a car .

1 3 # chelswu-ka iss-ta
2 3 # cha-ka iss-ta
3 -1 # iss-ta NULL x
4 3 # . iss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8459 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
chelswu-nun uysa i-ta .
chelswu-Top doctor Cop-Decl .
Chelswu is a doctor .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(SINV (ADVP (RB Chelswu)) (VP (VBZ is)) (NP (DT a) (NN doctor)) (. .))

(SINV+is (ADVP+Chelswu (RB Chelswu))
         (VP+is (VBZ is))
         (NP+doctor (DT a)
                    (NN doctor))
         (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
Chelswu is a doctor .
1 4 # Chelswu is x
2 4 # is *TOP* x
3 4 # a doctor 
4 -1 # doctor is x
5 4 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
chelswu-nun uysa i-ta .
chelswu-Top doctor Cop-Decl .

1 1 # chelswu-nun chelswu-Top
 1.1 1.1 # chelswu chelswu
 1.2 1.2 # -nun -Top
2 2 # uysa doctor
3 3 # i-ta Cop-Decl
 3.1 3.1 # i Cop
 3.2 3.2 # -ta -Decl
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
chelswu-Top doctor Cop-Decl .
Chelswu is a doctor .

1 1 # chelswu-Top Chelswu
 1.1 1 # chelswu Chelswu
 1.2 0 # -Top NULL
2 4 # doctor doctor
3 2 # Cop-Decl NULL x
 3.1 2 # Cop NULL x
 3.2 0 # -Decl NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
chelswu-nun uysa i-ta .
chelswu-Top doctor Cop-Decl .
Chelswu is a doctor .

1 2 # chelswu-nun i-ta x
2 -1 # uysa i-ta x
3 2 # i-ta NULL x
4 2 # . i-ta x


####### Q6: src DS is correct? Answer: n
#dj It is interesting to note that typical Korean orthography
#dj does not separate the copula from the predicate noun. So,
#dj this construction would remain head-final.





###########################################################
Igt_id=8534 Url_id=591 flag=0 cleaned=4 src_leng=4 trans_leng=10
Enehak-i chwuycik-i elyepta .
linguistics-NOM employment-NOM difficult .
As for linguistics , getting a job is difficult .

######## Q1: IGT is clean? Answer: y
#dj Though I think a more responsible translation would be:
#dj Getting a job in linguistics is difficult.


############################## Q2: English parse tree 
(S (PP (IN As) (PP (IN for) (NP (NNS linguistics)))) (, ,) (S (VP (VBG getting) (NP (DT a) (NN job)))) (VP (VBZ is) (ADJP (JJ difficult))) (. .))

(S+difficult (PP+As (IN As)
                    (PP+for (IN for)
                            (NP+linguistics (NNS linguistics))))
             (, ,)
             (S+getting (VP+getting (VBG getting)
                                    (NP+job (DT a)
                                            (NN job))))
             (VP+difficult (VBZ is)
                           (ADJP-PRD+difficult (JJ difficult)))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
As for linguistics , getting a job is difficult .
1 9 # As difficult
2 1 # for As
3 2 # linguistics for
4 9 # , difficult
5 9 # getting difficult
6 7 # a job
7 5 # job getting
8 9 # is difficult
9 -1 # difficult *TOP*
10 9 # . difficult


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Enehak-i chwuycik-i elyepta .
linguistics-NOM employment-NOM difficult .

1 1 # Enehak-i linguistics-NOM
 1.1 1.1 # Enehak linguistics
 1.2 1.2 # -i -NOM
2 2 # chwuycik-i employment-NOM
 2.1 2.1 # chwuycik employment
 2.2 2.2 # -i -NOM
3 3 # elyepta difficult
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y
#dj technically, chwuycik is "getting a job" / "finding
#dj employment"



######################### Q5: gloss and translation alignment
linguistics-NOM employment-NOM difficult .
As for linguistics , getting a job is difficult .

1 3 # linguistics-NOM linguistics
 1.1 3 # linguistics linguistics
 1.2 0 # -NOM NULL
2 7 # employment-NOM NULL x
 2.1 7 # employment NULL x
 2.2 0 # -NOM NULL
3 9 # difficult difficult
4 10 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Enehak-i chwuycik-i elyepta .
linguistics-NOM employment-NOM difficult .
As for linguistics , getting a job is difficult .

1 3 # Enehak-i elyepta
2 3 # chwuycik-i elyepta
3 -1 # elyepta *TOP*
4 3 # . elyepta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8535 Url_id=591 flag=0 cleaned=3 src_leng=5 trans_leng=8
Sopangswu-eykey-ka kyewul palam-i mwusepta .
fireman-DAT-NOM winter wind-NOM fear .
Firemen are afraid of the winter wind .

######## Q1: IGT is clean? Answer: y
#dj Literally, "for firemen, the winter wind is fearsome"


############################## Q2: English parse tree 
(S (NP (NNS Firemen)) (VP (VBP are) (ADJP (JJ afraid) (PP (IN of) (NP (DT the) (NN winter) (NN wind))))) (. .))

(S+afraid (NP+Firemen (NNS Firemen))
          (VP+afraid (VBP are)
                     (ADJP-PRD+afraid (JJ afraid)
                                      (PP+of (IN of)
                                             (NP+wind (DT the)
                                                      (NN winter)
                                                      (NN wind)))))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Firemen are afraid of the winter wind .
1 3 # Firemen afraid
2 3 # are afraid
3 -1 # afraid *TOP*
4 3 # of afraid
5 7 # the wind
6 7 # winter wind
7 4 # wind of
8 3 # . afraid


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Sopangswu-eykey-ka kyewul palam-i mwusepta .
fireman-DAT-NOM winter wind-NOM fear .

1 1 # Sopangswu-eykey-ka fireman-DAT-NOM
 1.1 1.1 # Sopangswu fireman
 1.2 1.2 # -eykey -DAT
 1.3 1.3 # -ka -NOM
2 2 # kyewul winter
3 3 # palam-i wind-NOM
 3.1 3.1 # palam wind
 3.2 3.2 # -i -NOM
4 4 # mwusepta fear
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
fireman-DAT-NOM winter wind-NOM fear .
Firemen are afraid of the winter wind .

1 1 # fireman-DAT-NOM NULL x
 1.1 1 # fireman NULL x
 1.2 0 # -DAT NULL
 1.3 0 # -NOM NULL
2 6 # winter winter
3 7 # wind-NOM wind
 3.1 7 # wind wind
 3.2 0 # -NOM NULL
4 3 # fear NULL x
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Sopangswu-eykey-ka kyewul palam-i mwusepta .
fireman-DAT-NOM winter wind-NOM fear .
Firemen are afraid of the winter wind .

1 4 # Sopangswu-eykey-ka mwusepta
2 3 # kyewul palam-i
3 4 # palam-i mwusepta
4 -1 # mwusepta NULL x
5 4 # . mwusepta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8538 Url_id=591 flag=0 cleaned=3 src_leng=7 trans_leng=11
Tol-i entek alay-lo twu pen-i kw .
stone-NOM hill bottom-to 2 times-NOM rolled .
It happened twice that a stone rolled down the hill .

######## Q1: IGT is clean? Answer: y
#dj actually, the verb in the Korean is truncated, but it looks
#dj like it should be processable.


############################## Q2: English parse tree 
(S (NP (PRP It)) (VP (VBD happened) (ADVP (RB twice)) (SBAR (IN that) (S (NP (DT a) (NN stone)) (VP (VBD rolled) (PRT (RP down)) (NP (DT the) (NN hill)))))) (. .))

(S+happened (NP+It (PRP It))
            (VP+happened (VBD happened)
                         (ADVP+twice (RB twice))
                         (SBAR+rolled (IN that)
                                      (S+rolled (NP+stone (DT a)
                                                          (NN stone))
                                                (VP+rolled (VBD rolled)
                                                           (PRT+down (RP down))
                                                           (NP+hill (DT the)
                                                                    (NN hill))))))
            (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
It happened twice that a stone rolled down the hill .
1 2 # It happened
2 -1 # happened *TOP*
3 2 # twice happened
4 7 # that rolled
5 6 # a stone
6 7 # stone rolled
7 2 # rolled happened
8 7 # down rolled
9 10 # the hill
10 8 # hill rolled x
11 2 # . happened


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
Tol-i entek alay-lo twu pen-i kw .
stone-NOM hill bottom-to 2 times-NOM rolled .

1 1 # Tol-i stone-NOM
 1.1 1.1 # Tol stone
 1.2 1.2 # -i -NOM
2 2 # entek hill
3 3 # alay-lo bottom-to
 3.1 3.1 # alay bottom
 3.2 3.2 # -lo -to
4 4 # twu 2
5 5 # pen-i times-NOM
 5.1 5.1 # pen times
 5.2 5.2 # -i -NOM
6 6 # kw rolled
7 7 # . .

######## Q4: src and gloss alignment is correct? Answer: y
#dj as far as it goes ...



######################### Q5: gloss and translation alignment
stone-NOM hill bottom-to 2 times-NOM rolled .
It happened twice that a stone rolled down the hill .

1 6 # stone-NOM stone
 1.1 6 # stone stone
 1.2 0 # -NOM NULL
2 10 # hill hill
3 8 # bottom-to NULL x
 3.1 8 # bottom NULL x
 3.2 0 # -to NULL
4 3 # 2 NULL x
5 3 # times-NOM NULL x
 5.1 3 # times NULL x
 5.2 0 # -NOM NULL
6 7 # rolled rolled
7 11 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Tol-i entek alay-lo twu pen-i kw .
stone-NOM hill bottom-to 2 times-NOM rolled .
It happened twice that a stone rolled down the hill .

1 6 # Tol-i kw
2 3 # entek kw x
3 6 # alay-lo kw
4 5 # twu kw x
5 6 # pen-i kw
6 -1 # kw NULL x
7 6 # . kw


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8540 Url_id=628 flag=0 cleaned=4 src_leng=4 trans_leng=6
cereal-ul mek-ess-ta Mary-ka .
cereal-ACC eat-PST-DEC Mary-NOM .
She ate cereal , Mary .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP She)) (VP (VBD ate) (NP (NP (NN cereal)) (, ,) (NP (NNP Mary)))) (. .))

(S+ate (NP+She (PRP She))
       (VP+ate (VBD ate)
               (NP+Mary (NP+cereal (NN cereal))
                        (, ,)
                        (NP+Mary (NNP Mary))))
       (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
She ate cereal , Mary .
1 2 # She ate
2 -1 # ate *TOP*
3 2 # cereal Mary x
4 2 # , Mary x
5 2 # Mary ate
6 2 # . ate


########  Q3: English DS is correct? Answer: n
#dj I'm not sure what to say about this DS. Mary sort of
#dj depends on "she". It sort of sounds like "the one who
#dj ate cereal is Mary" or "Mary's the one who ate cereal"
#dj so I have "Mary" depend on the clause.



#######################  Q4: src and gloss alignment
cereal-ul mek-ess-ta Mary-ka .
cereal-ACC eat-PST-DEC Mary-NOM .

1 1 # cereal-ul cereal-ACC
 1.1 1.1 # cereal cereal
 1.2 1.2 # -ul -ACC
2 2 # mek-ess-ta eat-PST-DEC
 2.1 2.1 # mek eat
 2.2 2.2 # -ess -PST
 2.3 2.3 # -ta -DEC
3 3 # Mary-ka Mary-NOM
 3.1 3.1 # Mary Mary
 3.2 3.2 # -ka -NOM
4 4 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
cereal-ACC eat-PST-DEC Mary-NOM .
She ate cereal , Mary .

1 3 # cereal-ACC cereal
 1.1 3 # cereal cereal
 1.2 0 # -ACC NULL
2 2 # eat-PST-DEC ate
 2.1 2 # eat ate
 2.2 0 # -PST NULL
 2.3 0 # -DEC NULL
3 5 # Mary-NOM Mary
 3.1 5 # Mary Mary
 3.2 0 # -NOM NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
cereal-ul mek-ess-ta Mary-ka .
cereal-ACC eat-PST-DEC Mary-NOM .
She ate cereal , Mary .

1 2 # cereal-ul Mary-ka x
2 -1 # mek-ess-ta *TOP*
3 2 # Mary-ka mek-ess-ta
4 2 # . mek-ess-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8545 Url_id=820 flag=0 cleaned=3 src_leng=5 trans_leng=7
Chelswu-Ka namwunip-ul ssel-E chiw-ess-ta .
Chelswu-Nom leaves-Acc sweep-E clean-Past-Decl .
Chelswu has swept up the leaves .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBZ has) (VP (VBN swept) (PRT (RP up)) (NP (DT the) (NNS leaves)))) (. .))

(S+swept (NP+Chelswu (NNP Chelswu))
         (VP+swept (VBZ has)
                   (VP+swept (VBN swept)
                             (PRT+up (RP up))
                             (NP+leaves (DT the)
                                        (NNS leaves))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu has swept up the leaves .
1 3 # Chelswu swept
2 3 # has swept
3 -1 # swept *TOP*
4 3 # up swept
5 6 # the leaves
6 3 # leaves swept
7 3 # . swept


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-Ka namwunip-ul ssel-E chiw-ess-ta .
Chelswu-Nom leaves-Acc sweep-E clean-Past-Decl .

1 1 # Chelswu-Ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -Ka -Nom
2 2 # namwunip-ul leaves-Acc
 2.1 2.1 # namwunip leaves
 2.2 2.2 # -ul -Acc
3 3 # ssel-E sweep-E
 3.1 3.1 # ssel sweep
 3.2 3.2 # -E -E
4 4 # chiw-ess-ta clean-Past-Decl
 4.1 4.1 # chiw clean
 4.2 4.2 # -ess -Past
 4.3 4.3 # -ta -Decl
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom leaves-Acc sweep-E clean-Past-Decl .
Chelswu has swept up the leaves .

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 6 # leaves-Acc leaves
 2.1 6 # leaves leaves
 2.2 0 # -Acc NULL
3 3 # sweep-E swept
 3.1 3 # sweep swept
 3.2 0 # -E NULL
4 0 # clean-Past-Decl NULL
 4.1 0 # clean NULL
 4.2 0 # -Past NULL
 4.3 0 # -Decl NULL
5 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y
#dj do we say "sweeping cleaned" is the same as "swept up"? If so,
#dj does the "up" align with "clean"?


############################# Q6: src DS
Chelswu-Ka namwunip-ul ssel-E chiw-ess-ta .
Chelswu-Nom leaves-Acc sweep-E clean-Past-Decl .
Chelswu has swept up the leaves .

1 4 # Chelswu-Ka ssel-E x
2 4 # namwunip-ul ssel-E x
3 4 # ssel-E *TOP* x
4 -1 # chiw-ess-ta ssel-E x
5 4 # . ssel-E x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8568 Url_id=829 flag=0 cleaned=3 src_leng=5 trans_leng=8
nay-ka Minho-ul chencay-la-ko sayngkakhanta .
I-nom Minho-acc genius-cop-comp think .
I think Minho to be a genius .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBP think) (ADJP (JJ Minho) (S (VP (TO to) (VP (VB be) (NP (DT a) (NN genius))))))) (. .))

(S+think (NP+I (PRP I))
         (VP+think (VBP think)
                   (ADJP+Minho (JJ Minho)
                               (S+genius (VP+genius (TO to)
                                                    (VP+genius (VB be)
                                                               (NP-PRD+genius (DT a)
                                                                              (NN genius)))))))
         (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
I think Minho to be a genius .
1 2 # I think
2 -1 # think *TOP*
3 7 # Minho think x
4 b # to genius x
5 7 # be genius 
6 7 # a genius
7 2 # genius Minho x
8 2 # . think


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
nay-ka Minho-ul chencay-la-ko sayngkakhanta .
I-nom Minho-acc genius-cop-comp think .

1 1 # nay-ka I-nom
 1.1 1.1 # nay I
 1.2 1.2 # -ka -nom
2 2 # Minho-ul Minho-acc
 2.1 2.1 # Minho Minho
 2.2 2.2 # -ul -acc
3 3 # chencay-la-ko genius-cop-comp
 3.1 3.1 # chencay genius
 3.2 3.2 # -la -cop
 3.3 3.3 # -ko -comp
4 4 # sayngkakhanta think
5 5 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-nom Minho-acc genius-cop-comp think .
I think Minho to be a genius .

1 1 # I-nom I
 1.1 1 # I I
 1.2 0 # -nom NULL
2 3 # Minho-acc Minho
 2.1 3 # Minho Minho
 2.2 0 # -acc NULL
3 7 # genius-cop-comp genius
 3.1 7 # genius genius
 3.2 0 # -cop NULL
 3.3 0 # -comp NULL
4 2 # think think
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
nay-ka Minho-ul chencay-la-ko sayngkakhanta .
I-nom Minho-acc genius-cop-comp think .
I think Minho to be a genius .

1 4 # nay-ka sayngkakhanta
2 3 # Minho-ul sayngkakhanta x
3 4 # chencay-la-ko Minho-ul x
4 -1 # sayngkakhanta *TOP*
5 4 # . sayngkakhanta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8575 Url_id=829 flag=0 cleaned=3 src_leng=6 trans_leng=6
siptay-tul-i taypwupwun Michael Jackson-ul coahanta .
teenager-pl-nom most Michael Jackson-acc like .
Most teenagers like Michael Jackson .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (JJS Most) (NNS teenagers)) (VP (VBP like) (NP (NNP Michael) (NNP Jackson))) (. .))

(S+like (NP+teenagers (JJS Most)
                      (NNS teenagers))
        (VP+like (VBP like)
                 (NP+Jackson (NNP Michael)
                             (NNP Jackson)))
        (. .))


###### Q2: English parse tree is correct? Answer: y
#dj "first name" depends on "last name"? "last name" depends on "first
#dj name"? What about "Henry VIII" "U. S." "Mary Queen of Scots"??



###############################  Q3: English DS 
Most teenagers like Michael Jackson .
1 2 # Most teenagers
2 3 # teenagers like
3 -1 # like *TOP*
4 5 # Michael Jackson
5 3 # Jackson like
6 3 # . like


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
siptay-tul-i taypwupwun Michael Jackson-ul coahanta .
teenager-pl-nom most Michael Jackson-acc like .

1 1 # siptay-tul-i teenager-pl-nom
 1.1 1.1 # siptay teenager
 1.2 1.2 # -tul -pl
 1.3 1.3 # -i -nom
2 2 # taypwupwun most
3 3 # Michael Michael
4 4 # Jackson-ul Jackson-acc
 4.1 4.1 # Jackson Jackson
 4.2 4.2 # -ul -acc
5 5 # coahanta like
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
teenager-pl-nom most Michael Jackson-acc like .
Most teenagers like Michael Jackson .

1 2 # teenager-pl-nom teenagers
 1.1 2 # teenager teenagers
 1.2 0 # -pl NULL
 1.3 0 # -nom NULL
2 1 # most Most
3 4 # Michael Michael
4 5 # Jackson-acc Jackson
 4.1 5 # Jackson Jackson
 4.2 0 # -acc NULL
5 3 # like like
6 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
siptay-tul-i taypwupwun Michael Jackson-ul coahanta .
teenager-pl-nom most Michael Jackson-acc like .
Most teenagers like Michael Jackson .

1 5 # siptay-tul-i coahanta
2 5 # taypwupwun siptay-tul-i x
3 4 # Michael Jackson-ul
4 5 # Jackson-ul coahanta
5 -1 # coahanta *TOP*
6 5 # . coahanta


####### Q6: src DS is correct? Answer: n
#dj The Korean is "Teenages, for the most part, like M J"





###########################################################
Igt_id=8582 Url_id=829 flag=0 cleaned=3 src_leng=9 trans_leng=13
Minho-ka pro lotte hotel-eyse yumyeng violinist-lul poassta-ko calanghayssta .
Minho-nom lotte hotel-loc famous violist-acc saw-comp said proudly .
Minho said proudly that he saw a famous violinist at Hotel Lotte .

######## Q1: IGT is clean? Answer: n
#dj alignment problems "pro" and "said proudly" / "boasted"


############################## Q2: English parse tree 
(S (NP (NNP Minho)) (VP (VBD said) (ADVP (RB proudly)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD saw) (NP (NP (DT a) (JJ famous) (NN violinist)) (PP (IN at) (NP (NNP Hotel) (NNP Lotte)))))))) (. .))

(S+said (NP+Minho (NNP Minho))
        (VP+said (VBD said)
                 (ADVP+proudly (RB proudly))
                 (SBAR+saw (IN that)
                           (S+saw (NP+he (PRP he))
                                  (VP+saw (VBD saw)
                                          (NP+violinist (NP+violinist (DT a)
                                                                      (JJ famous)
                                                                      (NN violinist))
                                                        (PP+at (IN at)
                                                               (NP+Lotte (NNP Hotel)
                                                                         (NNP Lotte))))))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Minho said proudly that he saw a famous violinist at Hotel Lotte .
1 2 # Minho said
2 -1 # said *TOP*
3 2 # proudly said
4 6 # that saw
5 6 # he saw
6 2 # saw said
7 9 # a violinist
8 9 # famous violinist
9 6 # violinist saw
10 9 # at violinist
11 12 # Hotel Lotte
12 10 # Lotte at
13 2 # . said


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Minho-ka pro lotte hotel-eyse yumyeng violinist-lul poassta-ko calanghayssta .
Minho-nom lotte hotel-loc famous violist-acc saw-comp said proudly .

1 1 # Minho-ka Minho-nom
 1.1 1.1 # Minho Minho
 1.2 1.2 # -ka -nom
2 2 # pro lotte
3 3 # lotte hotel-loc
4 4 # hotel-eyse famous
 4.1 0 # hotel NULL
 4.2 0 # -eyse NULL
5 5 # yumyeng violist-acc
6 6 # violinist-lul saw-comp
 6.1 6.1 # violinist saw
 6.2 6.2 # -lul -comp
7 7 # poassta-ko said
 7.1 0 # poassta NULL
 7.2 0 # -ko NULL
8 8 # calanghayssta proudly
9 9 # . .

######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Minho-nom lotte hotel-loc famous violist-acc saw-comp said proudly .
Minho said proudly that he saw a famous violinist at Hotel Lotte .

1 1 # Minho-nom Minho
 1.1 1 # Minho Minho
 1.2 0 # -nom NULL
2 12 # lotte Lotte
3 11 # hotel-loc Hotel
 3.1 11 # hotel Hotel
 3.2 0 # -loc NULL
4 8 # famous famous
5 9 # violist-acc NULL x
 5.1 9 # violist NULL x
 5.2 0 # -acc NULL
6 6 # saw-comp saw
 6.1 6 # saw saw
 6.2 0 # -comp NULL
7 2 # said said
8 3 # proudly proudly
9 13 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Minho-ka pro lotte hotel-eyse yumyeng violinist-lul poassta-ko calanghayssta .
Minho-nom lotte hotel-loc famous violist-acc saw-comp said proudly .
Minho said proudly that he saw a famous violinist at Hotel Lotte .

1 7 # Minho-ka poassta-ko
2 7 # pro poassta-ko
3 2 # lotte pro
4 7 # hotel-eyse poassta-ko
5 7 # yumyeng poassta-ko
6 7 # violinist-lul poassta-ko
7 -1 # poassta-ko *TOP*
8 7 # calanghayssta poassta-ko
9 7 # . poassta-ko


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8589 Url_id=852 flag=0 cleaned=4 src_leng=6 trans_leng=13
Ku ai-tul-i cwul-ul cap-a-tangki-ki-nun tangki-ess-ta .
the child-Plu-Nom string-Acc catch-E-pull-Nml-Top pull-Pst-Dcl .
As for catching and pulling the string , the children pulled it .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (PP (IN As) (PP (IN for) (S (VP (VBG catching) (CC and) (VBG pulling) (NP (DT the) (NN string)))))) (, ,) (NP (DT the) (NNS children)) (VP (VBD pulled) (NP (PRP it))) (. .))

(S+pulled (PP+As (IN As)
                 (PP+for (IN for)
                         (S+pulling (VP+pulling (VBG catching)
                                                (CC and)
                                                (VBG pulling)
                                                (NP+string (DT the)
                                                           (NN string))))))
          (, ,)
          (NP+children (DT the)
                       (NNS children))
          (VP+pulled (VBD pulled)
                     (NP+it (PRP it)))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
As for catching and pulling the string , the children pulled it .
1 11 # As pulled
2 1 # for As
3 5 # catching pulling
4 5 # and pulling
5 2 # pulling for
6 7 # the string
7 5 # string pulling
8 11 # , pulled
9 10 # the children
10 11 # children pulled
11 -1 # pulled *TOP*
12 11 # it pulled
13 11 # . pulled


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Ku ai-tul-i cwul-ul cap-a-tangki-ki-nun tangki-ess-ta .
the child-Plu-Nom string-Acc catch-E-pull-Nml-Top pull-Pst-Dcl .

1 1 # Ku the
2 2 # ai-tul-i child-Plu-Nom
 2.1 2.1 # ai child
 2.2 2.2 # -tul -Plu
 2.3 2.3 # -i -Nom
3 3 # cwul-ul string-Acc
 3.1 3.1 # cwul string
 3.2 3.2 # -ul -Acc
4 4 # cap-a-tangki-ki-nun catch-E-pull-Nml-Top
 4.1 4.1 # cap catch
 4.2 4.2 # -a -E
 4.3 4.3 # -tangki -pull
 4.4 4.4 # -ki -Nml
 4.5 4.5 # -nun -Top
5 5 # tangki-ess-ta pull-Pst-Dcl
 5.1 5.1 # tangki pull
 5.2 5.2 # -ess -Pst
 5.3 5.3 # -ta -Dcl
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
the child-Plu-Nom string-Acc catch-E-pull-Nml-Top pull-Pst-Dcl .
As for catching and pulling the string , the children pulled it .

1 9 # the the x
2 10 # child-Plu-Nom children
 2.1 10 # child children
 2.2 0 # -Plu NULL
 2.3 0 # -Nom NULL
3 7 # string-Acc string
 3.1 7 # string string
 3.2 0 # -Acc NULL
4 3,5 # catch-E-pull-Nml-Top catching x
 4.1 3 # catch catching
 4.2 0 # -E NULL
 4.3 5 # -pull NULL x
 4.4 0 # -Nml NULL
 4.5 0 # -Top NULL
5 11 # pull-Pst-Dcl NULL x
 5.1 11 # pull NULL x
 5.2 0 # -Pst NULL
 5.3 0 # -Dcl NULL
6 13 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Ku ai-tul-i cwul-ul cap-a-tangki-ki-nun tangki-ess-ta .
the child-Plu-Nom string-Acc catch-E-pull-Nml-Top pull-Pst-Dcl .
As for catching and pulling the string , the children pulled it .

1 2 # Ku cwul-ul x
2 5 # ai-tul-i tangki-ess-ta
3 4 # cwul-ul tangki-ess-ta x
4 5 # cap-a-tangki-ki-nun tangki-ess-ta
5 -1 # tangki-ess-ta NULL x
6 5 # . tangki-ess-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8590 Url_id=852 flag=0 cleaned=4 src_leng=6 trans_leng=13
Ku ai-tul-i cwul-ul cap-a-po-ki-nun po-ass-ta .
the child-Plu-Nom string-Acc catch-E-try-Nml-Top try-Pst-Dcl .
As for trying to catch the string , the children tried it .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (PP (IN As) (PP (IN for) (S (VP (VBG trying) (S (VP (TO to) (VP (VB catch) (NP (DT the) (NN string))))))))) (, ,) (NP (DT the) (NNS children)) (VP (VBD tried) (NP (PRP it))) (. .))

(S+tried (PP+As (IN As)
                (PP+for (IN for)
                        (S+trying (VP+trying (VBG trying)
                                             (S+catch (VP+catch (TO to)
                                                                (VP+catch (VB catch)
                                                                          (NP+string (DT the)
                                                                                     (NN string)))))))))
         (, ,)
         (NP+children (DT the)
                      (NNS children))
         (VP+tried (VBD tried)
                   (NP+it (PRP it)))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
As for trying to catch the string , the children tried it .
1 11 # As tried
2 1 # for As
3 2 # trying for
4 5 # to catch
5 3 # catch trying
6 7 # the string
7 5 # string catch
8 11 # , tried
9 10 # the children
10 11 # children tried
11 -1 # tried *TOP*
12 11 # it tried
13 11 # . tried


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Ku ai-tul-i cwul-ul cap-a-po-ki-nun po-ass-ta .
the child-Plu-Nom string-Acc catch-E-try-Nml-Top try-Pst-Dcl .

1 1 # Ku the
2 2 # ai-tul-i child-Plu-Nom
 2.1 2.1 # ai child
 2.2 2.2 # -tul -Plu
 2.3 2.3 # -i -Nom
3 3 # cwul-ul string-Acc
 3.1 3.1 # cwul string
 3.2 3.2 # -ul -Acc
4 4 # cap-a-po-ki-nun catch-E-try-Nml-Top
 4.1 4.1 # cap catch
 4.2 4.2 # -a -E
 4.3 4.3 # -po -try
 4.4 4.4 # -ki -Nml
 4.5 4.5 # -nun -Top
5 5 # po-ass-ta try-Pst-Dcl
 5.1 5.1 # po try
 5.2 5.2 # -ass -Pst
 5.3 5.3 # -ta -Dcl
6 6 # . .

######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
the child-Plu-Nom string-Acc catch-E-try-Nml-Top try-Pst-Dcl .
As for trying to catch the string , the children tried it .

1 9 # the the x
2 10 # child-Plu-Nom children
 2.1 10 # child children
 2.2 0 # -Plu NULL
 2.3 0 # -Nom NULL
3 7 # string-Acc string
 3.1 7 # string string
 3.2 0 # -Acc NULL
4 3,5 # catch-E-try-Nml-Top trying,catch
 4.1 5 # catch catch
 4.2 0 # -E NULL
 4.3 3 # -try trying
 4.4 0 # -Nml NULL
 4.5 0 # -Top NULL
5 11 # try-Pst-Dcl tried
 5.1 11 # try tried
 5.2 0 # -Pst NULL
 5.3 0 # -Dcl NULL
6 13 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Ku ai-tul-i cwul-ul cap-a-po-ki-nun po-ass-ta .
the child-Plu-Nom string-Acc catch-E-try-Nml-Top try-Pst-Dcl .
As for trying to catch the string , the children tried it .

1 2 # Ku cwul-ul x
2 5 # ai-tul-i po-ass-ta
3 4 # cwul-ul cap-a-po-ki-nun
4 5 # cap-a-po-ki-nun po-ass-ta
5 -1 # po-ass-ta *TOP*
6 5 # . po-ass-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8596 Url_id=944 flag=0 cleaned=3 src_leng=6 trans_leng=5
muôs-ûli amuto ti sa-chi anh-ass-ni ?
what-ACCi anyone ti buy-CHI not-do-PAST-Q ?
What did nobody buy ?

######## Q1: IGT is clean? Answer: n
#dj coindex markings


############################## Q2: English parse tree 
(SBARQ (WHNP (WP What)) (SQ (VBD did) (NP (NN nobody)) (VP (VB buy))) (. ?))

(SBARQ+buy (WHNP+What (WP What))
           (SQ+buy (VBD did)
                   (NP+nobody (NN nobody))
                   (VP+buy (VB buy)))
           (. ?))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
What did nobody buy ?
1 4 # What buy
2 4 # did buy
3 4 # nobody buy
4 -1 # buy *TOP*
5 4 # ? buy


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
muôs-ûli amuto ti sa-chi anh-ass-ni ?
what-ACCi anyone ti buy-CHI not-do-PAST-Q ?

1 1 # muôs-ûli what-ACCi
 1.1 1.1 # muôs what
 1.2 1.2 # -ûli -ACCi
2 2 # amuto anyone
3 3 # ti ti
4 4 # sa-chi buy-CHI
 4.1 4.1 # sa buy
 4.2 4.2 # -chi -CHI
5 5 # anh-ass-ni not-do-PAST-Q
 5.1 0 # anh NULL
 5.2 0 # -ass NULL
 5.3 0 # -ni NULL
6 6 # ? ?

######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
what-ACCi anyone ti buy-CHI not-do-PAST-Q ?
What did nobody buy ?

1 1 # what-ACCi What
 1.1 1 # what What
 1.2 0 # -ACCi NULL
2 0 # anyone NULL
3 0 # ti NULL
4 4 # buy-CHI buy
 4.1 4 # buy buy
 4.2 0 # -CHI NULL
5 2 # not-do-PAST-Q did
 5.1 0 # not NULL
 5.2 2 # -do did
 5.3 0 # -PAST NULL
 5.4 0 # -Q NULL
6 5 # ? ?


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
muôs-ûli amuto ti sa-chi anh-ass-ni ?
what-ACCi anyone ti buy-CHI not-do-PAST-Q ?
What did nobody buy ?

1 4 # muôs-ûli sa-chi
2 4 # amuto sa-chi
3 4 # ti sa-chi
4 -1 # sa-chi *TOP*
5 4 # anh-ass-ni sa-chi
6 4 # ? sa-chi


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=6796 Url_id=386 flag=0 cleaned=1 src_leng=3 trans_leng=6
Chelswu-ka atul-ul kell-i-ess-ta
Chelswu-Nom son-Acc walk-Cau-Past-Dec
Chelswu caused his son to walk

######## Q1: IGT is clean? Answer: x
#dj causitive modality vs main verb


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBD caused) (S (NP (PRP$ his) (NN son)) (VP (TO to) (VP (VB walk))))))

(S+caused (NP+Chelswu (NNP Chelswu))
          (VP+caused (VBD caused)
                     (S+walk (NP+son (PRP$ his)
                                     (NN son))
                             (VP+walk (TO to)
                                      (VP+walk (VB walk))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Chelswu caused his son to walk
1 2 # Chelswu caused
2 -1 # caused *TOP*
3 4 # his son
4 6 # son walk
5 6 # to walk
6 2 # walk caused


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Chelswu-ka atul-ul kell-i-ess-ta
Chelswu-Nom son-Acc walk-Cau-Past-Dec

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # atul-ul son-Acc
 2.1 2.1 # atul son
 2.2 2.2 # -ul -Acc
3 3 # kell-i-ess-ta walk-Cau-Past-Dec
 3.1 3.1 # kell walk
 3.2 3.2 # -i -Cau
 3.3 3.3 # -ess -Past
 3.4 3.4 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Chelswu-Nom son-Acc walk-Cau-Past-Dec
Chelswu caused his son to walk

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 4 # son-Acc son
 2.1 4 # son son
 2.2 0 # -Acc NULL
3 6 # walk-Cau-Past-Dec walk
 3.1 6 # walk walk
 3.2 0 # -Cau NULL
 3.3 0 # -Past NULL
 3.4 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Chelswu-ka atul-ul kell-i-ess-ta
Chelswu-Nom son-Acc walk-Cau-Past-Dec
Chelswu caused his son to walk

1 3 # Chelswu-ka kell-i-ess-ta
2 3 # atul-ul kell-i-ess-ta
3 -2 # kell-i-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=6797 Url_id=386 flag=0 cleaned=1 src_leng=3 trans_leng=6
Chelswu-ka atul-ul wul-i-ess-ta
Chelswu-Nom son-Acc walk-Cau-Past-Dec
Chelswu caused his son to cry

######## Q1: IGT is clean? Answer: x
#dj causitive mode vs. main verb


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBD caused) (S (NP (PRP$ his) (NN son)) (VP (TO to) (VP (VB cry))))))

(S+caused (NP+Chelswu (NNP Chelswu))
          (VP+caused (VBD caused)
                     (S+cry (NP+son (PRP$ his)
                                    (NN son))
                            (VP+cry (TO to)
                                    (VP+cry (VB cry))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Chelswu caused his son to cry
1 2 # Chelswu caused
2 -1 # caused *TOP*
3 4 # his son
4 6 # son cry
5 6 # to cry
6 2 # cry caused


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Chelswu-ka atul-ul wul-i-ess-ta
Chelswu-Nom son-Acc walk-Cau-Past-Dec

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # atul-ul son-Acc
 2.1 2.1 # atul son
 2.2 2.2 # -ul -Acc
3 3 # wul-i-ess-ta walk-Cau-Past-Dec
 3.1 3.1 # wul walk
 3.2 3.2 # -i -Cau
 3.3 3.3 # -ess -Past
 3.4 3.4 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Chelswu-Nom son-Acc walk-Cau-Past-Dec
Chelswu caused his son to cry

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 4 # son-Acc son
 2.1 4 # son son
 2.2 0 # -Acc NULL
3 0 # walk-Cau-Past-Dec NULL
 3.1 0 # walk NULL
 3.2 0 # -Cau NULL
 3.3 0 # -Past NULL
 3.4 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Chelswu-ka atul-ul wul-i-ess-ta
Chelswu-Nom son-Acc walk-Cau-Past-Dec
Chelswu caused his son to cry

1 3 # Chelswu-ka wul-i-ess-ta
2 3 # atul-ul wul-i-ess-ta
3 -2 # wul-i-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7850 Url_id=386 flag=0 cleaned=0 src_leng=5 trans_leng=9
emeni-ka ai-eykey ka-key an ha-ess-ta
mother-Nom child-Dat go-Com Neg do-Past-Dec
The mother did not cause the child to go

######## Q1: IGT is clean? Answer: x
#dj "do" vs "cause"


############################## Q2: English parse tree 
(S (NP (DT The) (NN mother)) (VP (VBD did) (RB not) (VP (VB cause) (S (NP (DT the) (NN child)) (VP (TO to) (VP (VB go)))))))

(S+cause (NP+mother (DT The)
                    (NN mother))
         (VP+cause (VBD did)
                   (RB not)
                   (VP+cause (VB cause)
                             (S+go (NP+child (DT the)
                                             (NN child))
                                   (VP+go (TO to)
                                          (VP+go (VB go)))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The mother did not cause the child to go
1 2 # The mother
2 5 # mother cause
3 5 # did cause
4 5 # not cause
5 -1 # cause *TOP*
6 7 # the child
7 9 # child go
8 9 # to go
9 5 # go cause


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
emeni-ka ai-eykey ka-key an ha-ess-ta
mother-Nom child-Dat go-Com Neg do-Past-Dec

1 1 # emeni-ka mother-Nom
 1.1 1.1 # emeni mother
 1.2 1.2 # -ka -Nom
2 2 # ai-eykey child-Dat
 2.1 2.1 # ai child
 2.2 2.2 # -eykey -Dat
3 3 # ka-key go-Com
 3.1 3.1 # ka go
 3.2 3.2 # -key -Com
4 4 # an Neg
5 5 # ha-ess-ta do-Past-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -ess -Past
 5.3 5.3 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-Nom child-Dat go-Com Neg do-Past-Dec
The mother did not cause the child to go

1 2 # mother-Nom mother
 1.1 2 # mother mother
 1.2 0 # -Nom NULL
2 7 # child-Dat child
 2.1 7 # child child
 2.2 0 # -Dat NULL
3 9 # go-Com go
 3.1 9 # go go
 3.2 0 # -Com NULL
4 4 # Neg not
5 3 # do-Past-Dec did
 5.1 3 # do did
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
emeni-ka ai-eykey ka-key an ha-ess-ta
mother-Nom child-Dat go-Com Neg do-Past-Dec
The mother did not cause the child to go

1 5 # emeni-ka ha-ess-ta
2 3 # ai-eykey ka-key
3 5 # ka-key ha-ess-ta
4 5 # an ha-ess-ta
5 -2 # ha-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7857 Url_id=386 flag=0 cleaned=0 src_leng=5 trans_leng=5
emeni-ka na-eykey pap-ul mek-key ha-ess-ta
mother-Nom I-Dat rice-Acc eat-Com do-Past-Dec
Mother made me eat rice

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mother)) (VP (VBD made) (S (NP (PRP me)) (VP (VB eat) (NP (NN rice))))))

(S+made (NP+Mother (NNP Mother))
        (VP+made (VBD made)
                 (S+eat (NP+me (PRP me))
                        (VP+eat (VB eat)
                                (NP+rice (NN rice))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mother made me eat rice
1 2 # Mother made
2 -1 # made *TOP*
3 4 # me eat
4 2 # eat made
5 4 # rice eat


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
emeni-ka na-eykey pap-ul mek-key ha-ess-ta
mother-Nom I-Dat rice-Acc eat-Com do-Past-Dec

1 1 # emeni-ka mother-Nom
 1.1 1.1 # emeni mother
 1.2 1.2 # -ka -Nom
2 2 # na-eykey I-Dat
 2.1 2.1 # na I
 2.2 2.2 # -eykey -Dat
3 3 # pap-ul rice-Acc
 3.1 3.1 # pap rice
 3.2 3.2 # -ul -Acc
4 4 # mek-key eat-Com
 4.1 4.1 # mek eat
 4.2 4.2 # -key -Com
5 5 # ha-ess-ta do-Past-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -ess -Past
 5.3 5.3 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-Nom I-Dat rice-Acc eat-Com do-Past-Dec
Mother made me eat rice

1 1 # mother-Nom Mother
 1.1 1 # mother Mother
 1.2 0 # -Nom NULL
2 0 # I-Dat NULL
 2.1 0 # I NULL
 2.2 0 # -Dat NULL
3 5 # rice-Acc rice
 3.1 5 # rice rice
 3.2 0 # -Acc NULL
4 4 # eat-Com eat
 4.1 4 # eat eat
 4.2 0 # -Com NULL
5 0 # do-Past-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
emeni-ka na-eykey pap-ul mek-key ha-ess-ta
mother-Nom I-Dat rice-Acc eat-Com do-Past-Dec
Mother made me eat rice

1 5 # emeni-ka ha-ess-ta
2 5 # na-eykey ha-ess-ta
3 4 # pap-ul mek-key
4 5 # mek-key ha-ess-ta
5 -2 # ha-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7858 Url_id=386 flag=0 cleaned=1 src_leng=5 trans_leng=6
nay-ka Swunhi-ka pap-ul mek-key ha-ess-ta
I-Nom Swunhi-Nom rice-Acc eat-Com do-Past-Dec
I made Swunhi eat the rice

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (PRP I)) (VP (VBD made) (S (NP (NNP Swunhi)) (VP (VB eat) (NP (DT the) (NN rice))))))

(S+made (NP+I (PRP I))
        (VP+made (VBD made)
                 (S+eat (NP+Swunhi (NNP Swunhi))
                        (VP+eat (VB eat)
                                (NP+rice (DT the)
                                         (NN rice))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
I made Swunhi eat the rice
1 2 # I made
2 -1 # made *TOP*
3 4 # Swunhi eat
4 2 # eat made
5 6 # the rice
6 4 # rice eat


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
nay-ka Swunhi-ka pap-ul mek-key ha-ess-ta
I-Nom Swunhi-Nom rice-Acc eat-Com do-Past-Dec

1 1 # nay-ka I-Nom
 1.1 1.1 # nay I
 1.2 1.2 # -ka -Nom
2 2 # Swunhi-ka Swunhi-Nom
 2.1 2.1 # Swunhi Swunhi
 2.2 2.2 # -ka -Nom
3 3 # pap-ul rice-Acc
 3.1 3.1 # pap rice
 3.2 3.2 # -ul -Acc
4 4 # mek-key eat-Com
 4.1 4.1 # mek eat
 4.2 4.2 # -key -Com
5 5 # ha-ess-ta do-Past-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -ess -Past
 5.3 5.3 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
I-Nom Swunhi-Nom rice-Acc eat-Com do-Past-Dec
I made Swunhi eat the rice

1 1 # I-Nom I
 1.1 1 # I I
 1.2 0 # -Nom NULL
2 3 # Swunhi-Nom Swunhi
 2.1 3 # Swunhi Swunhi
 2.2 0 # -Nom NULL
3 6 # rice-Acc rice
 3.1 6 # rice rice
 3.2 0 # -Acc NULL
4 4 # eat-Com eat
 4.1 4 # eat eat
 4.2 0 # -Com NULL
5 0 # do-Past-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
nay-ka Swunhi-ka pap-ul mek-key ha-ess-ta
I-Nom Swunhi-Nom rice-Acc eat-Com do-Past-Dec
I made Swunhi eat the rice

1 5 # nay-ka ha-ess-ta
2 4 # Swunhi-ka mek-key
3 4 # pap-ul mek-key
4 5 # mek-key ha-ess-ta
5 -2 # ha-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7859 Url_id=386 flag=0 cleaned=2 src_leng=5 trans_leng=6
John-i Sue-ka chayk-ul ilk-key ha-ess-ta
John-Nom Sue-Nom book-Acc read-Com do-Past-Dec
John made Sue read the book

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD made) (S (VP (VB Sue) (VP (VBN read) (NP (DT the) (NN book)))))))

(S+made (NP+John (NNP John))
        (VP+made (VBD made)
                 (S+read (VP+read (VB Sue)
                                  (VP+read (VBN read)
                                           (NP+book (DT the)
                                                    (NN book)))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
John made Sue read the book
1 2 # John made
2 -1 # made *TOP*
3 4 # Sue read
4 2 # read made
5 6 # the book
6 4 # book read


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
John-i Sue-ka chayk-ul ilk-key ha-ess-ta
John-Nom Sue-Nom book-Acc read-Com do-Past-Dec

1 1 # John-i John-Nom
 1.1 1.1 # John John
 1.2 1.2 # -i -Nom
2 2 # Sue-ka Sue-Nom
 2.1 2.1 # Sue Sue
 2.2 2.2 # -ka -Nom
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-key read-Com
 4.1 4.1 # ilk read
 4.2 4.2 # -key -Com
5 5 # ha-ess-ta do-Past-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -ess -Past
 5.3 5.3 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
John-Nom Sue-Nom book-Acc read-Com do-Past-Dec
John made Sue read the book

1 1 # John-Nom John
 1.1 1 # John John
 1.2 0 # -Nom NULL
2 3 # Sue-Nom Sue
 2.1 3 # Sue Sue
 2.2 0 # -Nom NULL
3 6 # book-Acc book
 3.1 6 # book book
 3.2 0 # -Acc NULL
4 4 # read-Com read
 4.1 4 # read read
 4.2 0 # -Com NULL
5 0 # do-Past-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
John-i Sue-ka chayk-ul ilk-key ha-ess-ta
John-Nom Sue-Nom book-Acc read-Com do-Past-Dec
John made Sue read the book

1 5 # John-i ha-ess-ta
2 4 # Sue-ka ilk-key
3 4 # chayk-ul ilk-key
4 5 # ilk-key ha-ess-ta
5 -2 # ha-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7869 Url_id=386 flag=0 cleaned=2 src_leng=5 trans_leng=6
John-i Sue-eykey chayk-ul ilk-key ha-ess-ta
John-Nom Sue-Dat book-Acc read-Com do-Past-Dec
John made Sue read the book

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD made) (S (VP (VB Sue) (VP (VBN read) (NP (DT the) (NN book)))))))

(S+made (NP+John (NNP John))
        (VP+made (VBD made)
                 (S+read (VP+read (VB Sue)
                                  (VP+read (VBN read)
                                           (NP+book (DT the)
                                                    (NN book)))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
John made Sue read the book
1 2 # John made
2 -1 # made *TOP*
3 4 # Sue read
4 2 # read made
5 6 # the book
6 4 # book read


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
John-i Sue-eykey chayk-ul ilk-key ha-ess-ta
John-Nom Sue-Dat book-Acc read-Com do-Past-Dec

1 1 # John-i John-Nom
 1.1 1.1 # John John
 1.2 1.2 # -i -Nom
2 2 # Sue-eykey Sue-Dat
 2.1 2.1 # Sue Sue
 2.2 2.2 # -eykey -Dat
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-key read-Com
 4.1 4.1 # ilk read
 4.2 4.2 # -key -Com
5 5 # ha-ess-ta do-Past-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -ess -Past
 5.3 5.3 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
John-Nom Sue-Dat book-Acc read-Com do-Past-Dec
John made Sue read the book

1 1 # John-Nom John
 1.1 1 # John John
 1.2 0 # -Nom NULL
2 3 # Sue-Dat Sue
 2.1 3 # Sue Sue
 2.2 0 # -Dat NULL
3 6 # book-Acc book
 3.1 6 # book book
 3.2 0 # -Acc NULL
4 4 # read-Com read
 4.1 4 # read read
 4.2 0 # -Com NULL
5 0 # do-Past-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Past NULL
 5.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
John-i Sue-eykey chayk-ul ilk-key ha-ess-ta
John-Nom Sue-Dat book-Acc read-Com do-Past-Dec
John made Sue read the book

1 5 # John-i ha-ess-ta
2 4 # Sue-eykey ilk-key
3 4 # chayk-ul ilk-key
4 5 # ilk-key ha-ess-ta
5 -2 # ha-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7873 Url_id=386 flag=0 cleaned=2 src_leng=6 trans_leng=7
John-un Bill-eykey congi-ul tay-wu -ke ha-ess-ta
John-Top Bill-Dat paper- Acc burn(vi)-Cau-Com do-Past-Dec
John caused Bill to burn the paper

######## Q1: IGT is clean? Answer: x
#dj "cause" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD caused) (NP (NP (NN Bill)) (SBAR (S (VP (TO to) (VP (VB burn) (NP (DT the) (NN paper)))))))))

(S+caused (NP+John (NNP John))
          (VP+caused (VBD caused)
                     (NP+Bill (NP+Bill (NN Bill))
                              (SBAR+burn (S+burn (VP+burn (TO to)
                                                          (VP+burn (VB burn)
                                                                   (NP+paper (DT the)
                                                                             (NN paper)))))))))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
John caused Bill to burn the paper
1 2 # John caused
2 -1 # caused *TOP*
3 2 # Bill caused
4 5 # to burn
5 3 # burn Bill
6 7 # the paper
7 5 # paper burn


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
John-un Bill-eykey congi-ul tay-wu -ke ha-ess-ta
John-Top Bill-Dat paper- Acc burn(vi)-Cau-Com do-Past-Dec

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # Bill-eykey Bill-Dat
 2.1 2.1 # Bill Bill
 2.2 2.2 # -eykey -Dat
3 3 # congi-ul paper-
 3.1 0 # congi NULL
 3.2 0 # -ul NULL
4 4 # tay-wu Acc
 4.1 0 # tay NULL
 4.2 0 # -wu NULL
5 5 # -ke burn(vi)-Cau-Com
 5.1 0 #  NULL
 5.2 0 # -ke NULL
6 6 # ha-ess-ta do-Past-Dec
 6.1 6.1 # ha do
 6.2 6.2 # -ess -Past
 6.3 6.3 # -ta -Dec
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
John-Top Bill-Dat paper- Acc burn(vi)-Cau-Com do-Past-Dec
John caused Bill to burn the paper

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 3 # Bill-Dat Bill
 2.1 3 # Bill Bill
 2.2 0 # -Dat NULL
3 7 # paper- paper
4 0 # Acc NULL
5 0 # burn(vi)-Cau-Com NULL
 5.1 0 # burn(vi) NULL
 5.2 0 # -Cau NULL
 5.3 0 # -Com NULL
6 0 # do-Past-Dec NULL
 6.1 0 # do NULL
 6.2 0 # -Past NULL
 6.3 0 # -Dec NULL


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
John-un Bill-eykey congi-ul tay-wu -ke ha-ess-ta
John-Top Bill-Dat paper- Acc burn(vi)-Cau-Com do-Past-Dec
John caused Bill to burn the paper

1 6 # John-un ha-ess-ta
2 6 # Bill-eykey ha-ess-ta
3 2 # congi-ul Bill-eykey
4 6 # tay-wu ha-ess-ta
5 6 # -ke ha-ess-ta
6 -2 # ha-ess-ta NULL


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7878 Url_id=386 flag=0 cleaned=3 src_leng=6 trans_leng=9
emeni-ka ku ai-eykey sosik-ul al-li-ess-ta .
mother-Nom that child-Dat news-Acc know-Cau-Past-Dec .
The mother informed the child of the news .

######## Q1: IGT is clean? Answer: x
#dj "inform" vs "cause to know"


############################## Q2: English parse tree 
(S (NP (DT The) (NN mother)) (VP (VBD informed) (NP (NP (DT the) (NN child)) (PP (IN of) (NP (DT the) (NN news))))) (. .))

(S+informed (NP+mother (DT The)
                       (NN mother))
            (VP+informed (VBD informed)
                         (NP+child (NP+child (DT the)
                                             (NN child))
                                   (PP+of (IN of)
                                          (NP+news (DT the)
                                                   (NN news)))))
            (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The mother informed the child of the news .
1 2 # The mother
2 3 # mother informed
3 -1 # informed *TOP*
4 5 # the child
5 3 # child informed
6 5 # of child
7 8 # the news
8 6 # news of
9 3 # . informed


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
emeni-ka ku ai-eykey sosik-ul al-li-ess-ta .
mother-Nom that child-Dat news-Acc know-Cau-Past-Dec .

1 1 # emeni-ka mother-Nom
 1.1 1.1 # emeni mother
 1.2 1.2 # -ka -Nom
2 2 # ku that
3 3 # ai-eykey child-Dat
 3.1 3.1 # ai child
 3.2 3.2 # -eykey -Dat
4 4 # sosik-ul news-Acc
 4.1 4.1 # sosik news
 4.2 4.2 # -ul -Acc
5 5 # al-li-ess-ta know-Cau-Past-Dec
 5.1 5.1 # al know
 5.2 5.2 # -li -Cau
 5.3 5.3 # -ess -Past
 5.4 5.4 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-Nom that child-Dat news-Acc know-Cau-Past-Dec .
The mother informed the child of the news .

1 2 # mother-Nom mother
 1.1 2 # mother mother
 1.2 0 # -Nom NULL
2 0 # that NULL
3 5 # child-Dat child
 3.1 5 # child child
 3.2 0 # -Dat NULL
4 8 # news-Acc news
 4.1 8 # news news
 4.2 0 # -Acc NULL
5 0 # know-Cau-Past-Dec NULL
 5.1 0 # know NULL
 5.2 0 # -Cau NULL
 5.3 0 # -Past NULL
 5.4 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
emeni-ka ku ai-eykey sosik-ul al-li-ess-ta .
mother-Nom that child-Dat news-Acc know-Cau-Past-Dec .
The mother informed the child of the news .

1 5 # emeni-ka al-li-ess-ta
2 5 # ku al-li-ess-ta
3 5 # ai-eykey al-li-ess-ta
4 3 # sosik-ul ai-eykey
5 -2 # al-li-ess-ta NULL
6 5 # . al-li-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7879 Url_id=386 flag=0 cleaned=6 src_leng=5 trans_leng=6
John-i Mary-uy meli-lul kam-ki-ess-ta .
John-Nom Mary-Gen hair-Acc wash-Cau-Past-Dec .
John washed Mary 's hair .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD washed) (NP (NP (NNP Mary) (POS 's)) (NN hair))) (. .))

(S+washed (NP+John (NNP John))
          (VP+washed (VBD washed)
                     (NP+hair (NP+'s (NNP Mary)
                                     (POS 's))
                              (NN hair)))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John washed Mary 's hair .
1 2 # John washed
2 -1 # washed *TOP*
3 4 # Mary 's
4 5 # 's hair
5 2 # hair washed
6 2 # . washed


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-i Mary-uy meli-lul kam-ki-ess-ta .
John-Nom Mary-Gen hair-Acc wash-Cau-Past-Dec .

1 1 # John-i John-Nom
 1.1 1.1 # John John
 1.2 1.2 # -i -Nom
2 2 # Mary-uy Mary-Gen
 2.1 2.1 # Mary Mary
 2.2 2.2 # -uy -Gen
3 3 # meli-lul hair-Acc
 3.1 3.1 # meli hair
 3.2 3.2 # -lul -Acc
4 4 # kam-ki-ess-ta wash-Cau-Past-Dec
 4.1 4.1 # kam wash
 4.2 4.2 # -ki -Cau
 4.3 4.3 # -ess -Past
 4.4 4.4 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Nom Mary-Gen hair-Acc wash-Cau-Past-Dec .
John washed Mary 's hair .

1 1 # John-Nom John
 1.1 1 # John John
 1.2 0 # -Nom NULL
2 3 # Mary-Gen Mary
 2.1 3 # Mary Mary
 2.2 0 # -Gen NULL
3 5 # hair-Acc hair
 3.1 5 # hair hair
 3.2 0 # -Acc NULL
4 2 # wash-Cau-Past-Dec washed
 4.1 2 # wash washed
 4.2 0 # -Cau NULL
 4.3 0 # -Past NULL
 4.4 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-i Mary-uy meli-lul kam-ki-ess-ta .
John-Nom Mary-Gen hair-Acc wash-Cau-Past-Dec .
John washed Mary 's hair .

1 4 # John-i kam-ki-ess-ta
2 3 # Mary-uy meli-lul
3 4 # meli-lul kam-ki-ess-ta
4 -1 # kam-ki-ess-ta *TOP*
5 4 # . kam-ki-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=7880 Url_id=386 flag=0 cleaned=3 src_leng=3 trans_leng=5
pang-i palk-ta .
room-Nom bright-Dec .
The room is bright .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN room)) (VP (VBZ is) (ADJP (JJ bright))) (. .))

(S+bright (NP+room (DT The)
                   (NN room))
          (VP+bright (VBZ is)
                     (ADJP-PRD+bright (JJ bright)))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The room is bright .
1 2 # The room
2 4 # room bright
3 4 # is bright
4 -1 # bright *TOP*
5 4 # . bright


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
pang-i palk-ta .
room-Nom bright-Dec .

1 1 # pang-i room-Nom
 1.1 1.1 # pang room
 1.2 1.2 # -i -Nom
2 2 # palk-ta bright-Dec
 2.1 2.1 # palk bright
 2.2 2.2 # -ta -Dec
3 3 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
room-Nom bright-Dec .
The room is bright .

1 2 # room-Nom room
 1.1 2 # room room
 1.2 0 # -Nom NULL
2 4 # bright-Dec bright
 2.1 4 # bright bright
 2.2 0 # -Dec NULL
3 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
pang-i palk-ta .
room-Nom bright-Dec .
The room is bright .

1 2 # pang-i palk-ta
2 -1 # palk-ta *TOP*
3 2 # . palk-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=7881 Url_id=386 flag=0 cleaned=3 src_leng=4 trans_leng=5
Swuni-ka sinpwun-ul palk-hi-n-ta .
Swuni-Nom identity-Acc bright-Cau-Pre-Dec .
Suni discloses her identity .

######## Q1: IGT is clean? Answer: x
#dj "disclose" vs "cause to be bright"


############################## Q2: English parse tree 
(S (NP (NNP Suni)) (VP (VBZ discloses) (NP (PRP$ her) (NN identity))) (. .))

(S+discloses (NP+Suni (NNP Suni))
             (VP+discloses (VBZ discloses)
                           (NP+identity (PRP$ her)
                                        (NN identity)))
             (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Suni discloses her identity .
1 2 # Suni discloses
2 -1 # discloses *TOP*
3 4 # her identity
4 2 # identity discloses
5 2 # . discloses


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Swuni-ka sinpwun-ul palk-hi-n-ta .
Swuni-Nom identity-Acc bright-Cau-Pre-Dec .

1 1 # Swuni-ka Swuni-Nom
 1.1 1.1 # Swuni Swuni
 1.2 1.2 # -ka -Nom
2 2 # sinpwun-ul identity-Acc
 2.1 2.1 # sinpwun identity
 2.2 2.2 # -ul -Acc
3 3 # palk-hi-n-ta bright-Cau-Pre-Dec
 3.1 3.1 # palk bright
 3.2 3.2 # -hi -Cau
 3.3 3.3 # -n -Pre
 3.4 3.4 # -ta -Dec
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Swuni-Nom identity-Acc bright-Cau-Pre-Dec .
Suni discloses her identity .

1 0 # Swuni-Nom NULL
 1.1 0 # Swuni NULL
 1.2 0 # -Nom NULL
2 4 # identity-Acc identity
 2.1 4 # identity identity
 2.2 0 # -Acc NULL
3 0 # bright-Cau-Pre-Dec NULL
 3.1 0 # bright NULL
 3.2 0 # -Cau NULL
 3.3 0 # -Pre NULL
 3.4 0 # -Dec NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Swuni-ka sinpwun-ul palk-hi-n-ta .
Swuni-Nom identity-Acc bright-Cau-Pre-Dec .
Suni discloses her identity .

1 3 # Swuni-ka palk-hi-n-ta
2 3 # sinpwun-ul palk-hi-n-ta
3 -2 # palk-hi-n-ta NULL
4 3 # . palk-hi-n-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=7884 Url_id=386 flag=0 cleaned=3 src_leng=4 trans_leng=5
Swuni-ka kuk-lul kkulh-i-n-ta .
Swuni-Nom soup-Acc boil-Cau(prepare)-Pre-Dec .
Suni prepares the soup .

######## Q1: IGT is clean? Answer: x
#dj "cause to boil" vs "prepare"
#dj "Swuni" vs "Suni"


############################## Q2: English parse tree 
(S (NP (NNP Suni)) (VP (VBZ prepares) (NP (DT the) (NN soup))) (. .))

(S+prepares (NP+Suni (NNP Suni))
            (VP+prepares (VBZ prepares)
                         (NP+soup (DT the)
                                  (NN soup)))
            (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Suni prepares the soup .
1 2 # Suni prepares
2 -1 # prepares *TOP*
3 4 # the soup
4 2 # soup prepares
5 2 # . prepares


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Swuni-ka kuk-lul kkulh-i-n-ta .
Swuni-Nom soup-Acc boil-Cau(prepare)-Pre-Dec .

1 1 # Swuni-ka Swuni-Nom
 1.1 1.1 # Swuni Swuni
 1.2 1.2 # -ka -Nom
2 2 # kuk-lul soup-Acc
 2.1 2.1 # kuk soup
 2.2 2.2 # -lul -Acc
3 3 # kkulh-i-n-ta boil-Cau(prepare)-Pre-Dec
 3.1 3.1 # kkulh boil
 3.2 3.2 # -i -Cau(prepare)
 3.3 3.3 # -n -Pre
 3.4 3.4 # -ta -Dec
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Swuni-Nom soup-Acc boil-Cau(prepare)-Pre-Dec .
Suni prepares the soup .

1 1 # Swuni-Nom NULL x
 1.1 0 # Swuni NULL
 1.2 0 # -Nom NULL
2 4 # soup-Acc soup
 2.1 4 # soup soup
 2.2 0 # -Acc NULL
3 2 # boil-Cau(prepare)-Pre-Dec NULL x
 3.1 0 # boil NULL
 3.2 0 # -Cau(prepare) NULL
 3.3 0 # -Pre NULL
 3.4 0 # -Dec NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Swuni-ka kuk-lul kkulh-i-n-ta .
Swuni-Nom soup-Acc boil-Cau(prepare)-Pre-Dec .
Suni prepares the soup .

1 3 # Swuni-ka kkulh-i-n-ta
2 3 # kuk-lul kkulh-i-n-ta
3 -2 # kkulh-i-n-ta NULL
4 3 # . kkulh-i-n-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=7886 Url_id=386 flag=0 cleaned=3 src_leng=4 trans_leng=6
ku-ka mwul-ul elli-nuncwung-i-ta .
he-Nom water-Acc freeze-Prog-Pre-Dec .
He is freezing the water .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP He)) (VP (VBZ is) (VP (NN freezing) (NP (DT the) (NN water)))) (. .))

(S+water (NP+He (PRP He))
         (VP+water (VBZ is)
                   (VP+water (NN freezing)
                             (NP+water (DT the)
                                       (NN water))))
         (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
He is freezing the water .
1 3 # He water x
2 3 # is water x
3 -1 # freezing water x
4 5 # the water
5 3 # water *TOP* x
6 3 # . water x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
ku-ka mwul-ul elli-nuncwung-i-ta .
he-Nom water-Acc freeze-Prog-Pre-Dec .

1 1 # ku-ka he-Nom
 1.1 1.1 # ku he
 1.2 1.2 # -ka -Nom
2 2 # mwul-ul water-Acc
 2.1 2.1 # mwul water
 2.2 2.2 # -ul -Acc
3 3 # elli-nuncwung-i-ta freeze-Prog-Pre-Dec
 3.1 3.1 # elli freeze
 3.2 3.2 # -nuncwung -Prog
 3.3 3.3 # -i -Pre
 3.4 3.4 # -ta -Dec
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
he-Nom water-Acc freeze-Prog-Pre-Dec .
He is freezing the water .

1 1 # he-Nom He
 1.1 1 # he He
 1.2 0 # -Nom NULL
2 5 # water-Acc water
 2.1 5 # water water
 2.2 0 # -Acc NULL
3 3 # freeze-Prog-Pre-Dec NULL x
 3.1 0 # freeze NULL
 3.2 0 # -Prog NULL
 3.3 0 # -Pre NULL
 3.4 0 # -Dec NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
ku-ka mwul-ul elli-nuncwung-i-ta .
he-Nom water-Acc freeze-Prog-Pre-Dec .
He is freezing the water .

1 3 # ku-ka mwul-ul x
2 3 # mwul-ul *TOP* x
3 -1 # elli-nuncwung-i-ta mwul-ul x
4 3 # . mwul-ul x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=7887 Url_id=386 flag=0 cleaned=3 src_leng=5 trans_leng=6
ku-ka yelsimhi mwul-ul elli-ess-ta .
he-Nom vigorously water-Acc freeze-Past-Dec .
He froze the water vigorously .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP He)) (VP (VBD froze) (NP (DT the) (NN water)) (ADVP (RB vigorously))) (. .))

(S+froze (NP+He (PRP He))
         (VP+froze (VBD froze)
                   (NP+water (DT the)
                             (NN water))
                   (ADVP+vigorously (RB vigorously)))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
He froze the water vigorously .
1 2 # He froze
2 -1 # froze *TOP*
3 4 # the water
4 2 # water froze
5 2 # vigorously froze
6 2 # . froze


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
ku-ka yelsimhi mwul-ul elli-ess-ta .
he-Nom vigorously water-Acc freeze-Past-Dec .

1 1 # ku-ka he-Nom
 1.1 1.1 # ku he
 1.2 1.2 # -ka -Nom
2 2 # yelsimhi vigorously
3 3 # mwul-ul water-Acc
 3.1 3.1 # mwul water
 3.2 3.2 # -ul -Acc
4 4 # elli-ess-ta freeze-Past-Dec
 4.1 4.1 # elli freeze
 4.2 4.2 # -ess -Past
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
he-Nom vigorously water-Acc freeze-Past-Dec .
He froze the water vigorously .

1 1 # he-Nom He
 1.1 1 # he He
 1.2 0 # -Nom NULL
2 5 # vigorously vigorously
3 4 # water-Acc water
 3.1 4 # water water
 3.2 0 # -Acc NULL
4 2 # freeze-Past-Dec froze
 4.1 2 # freeze froze
 4.2 0 # -Past NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
ku-ka yelsimhi mwul-ul elli-ess-ta .
he-Nom vigorously water-Acc freeze-Past-Dec .
He froze the water vigorously .

1 4 # ku-ka elli-ess-ta
2 4 # yelsimhi elli-ess-ta
3 4 # mwul-ul elli-ess-ta
4 -1 # elli-ess-ta *TOP*
5 4 # . elli-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=7888 Url_id=386 flag=0 cleaned=3 src_leng=5 trans_leng=8
ku-ka han-sikan-tongan mwul-ul elli-ess-ta .
he-Nom 1-hour-for water-Acc freeze-Past-Dec .
He froze the water for an hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP He)) (VP (VBD froze) (NP (DT the) (NN water)) (PP (IN for) (NP (DT an) (NN hour)))) (. .))

(S+froze (NP+He (PRP He))
         (VP+froze (VBD froze)
                   (NP+water (DT the)
                             (NN water))
                   (PP+for (IN for)
                           (NP+hour (DT an)
                                    (NN hour))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
He froze the water for an hour .
1 2 # He froze
2 -1 # froze *TOP*
3 4 # the water
4 2 # water froze
5 2 # for froze
6 7 # an hour
7 5 # hour for
8 2 # . froze


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
ku-ka han-sikan-tongan mwul-ul elli-ess-ta .
he-Nom 1-hour-for water-Acc freeze-Past-Dec .

1 1 # ku-ka he-Nom
 1.1 1.1 # ku he
 1.2 1.2 # -ka -Nom
2 2 # han-sikan-tongan 1-hour-for
 2.1 2.1 # han 1
 2.2 2.2 # -sikan -hour
 2.3 2.3 # -tongan -for
3 3 # mwul-ul water-Acc
 3.1 3.1 # mwul water
 3.2 3.2 # -ul -Acc
4 4 # elli-ess-ta freeze-Past-Dec
 4.1 4.1 # elli freeze
 4.2 4.2 # -ess -Past
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
he-Nom 1-hour-for water-Acc freeze-Past-Dec .
He froze the water for an hour .

1 1 # he-Nom He
 1.1 1 # he He
 1.2 0 # -Nom NULL
2 5,7 # 1-hour-for for,hour
 2.1 0 # 1 NULL
 2.2 7 # -hour hour
 2.3 5 # -for for
3 4 # water-Acc water
 3.1 4 # water water
 3.2 0 # -Acc NULL
4 2 # freeze-Past-Dec froze
 4.1 2 # freeze froze
 4.2 0 # -Past NULL
 4.3 0 # -Dec NULL
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
ku-ka han-sikan-tongan mwul-ul elli-ess-ta .
he-Nom 1-hour-for water-Acc freeze-Past-Dec .
He froze the water for an hour .

1 4 # ku-ka elli-ess-ta
2 4 # han-sikan-tongan elli-ess-ta
3 4 # mwul-ul elli-ess-ta
4 -1 # elli-ess-ta *TOP*
5 4 # . elli-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=7889 Url_id=386 flag=0 cleaned=3 src_leng=5 trans_leng=8
ku-ka han-sikan-nayey mwul-ul elli-ess-ta .
he-Nom 1-hour-in water-Acc freeze-Past-Dec .
He froze the water in an hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP He)) (VP (VBD froze) (NP (DT the) (NN water)) (PP (IN in) (NP (DT an) (NN hour)))) (. .))

(S+froze (NP+He (PRP He))
         (VP+froze (VBD froze)
                   (NP+water (DT the)
                             (NN water))
                   (PP+in (IN in)
                          (NP+hour (DT an)
                                   (NN hour))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
He froze the water in an hour .
1 2 # He froze
2 -1 # froze *TOP*
3 4 # the water
4 2 # water froze
5 2 # in froze
6 7 # an hour
7 5 # hour in
8 2 # . froze


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
ku-ka han-sikan-nayey mwul-ul elli-ess-ta .
he-Nom 1-hour-in water-Acc freeze-Past-Dec .

1 1 # ku-ka he-Nom
 1.1 1.1 # ku he
 1.2 1.2 # -ka -Nom
2 2 # han-sikan-nayey 1-hour-in
 2.1 2.1 # han 1
 2.2 2.2 # -sikan -hour
 2.3 2.3 # -nayey -in
3 3 # mwul-ul water-Acc
 3.1 3.1 # mwul water
 3.2 3.2 # -ul -Acc
4 4 # elli-ess-ta freeze-Past-Dec
 4.1 4.1 # elli freeze
 4.2 4.2 # -ess -Past
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
he-Nom 1-hour-in water-Acc freeze-Past-Dec .
He froze the water in an hour .

1 1 # he-Nom He
 1.1 1 # he He
 1.2 0 # -Nom NULL
2 5,7 # 1-hour-in in,hour
 2.1 0 # 1 NULL
 2.2 7 # -hour hour
 2.3 5 # -in in
3 4 # water-Acc water
 3.1 4 # water water
 3.2 0 # -Acc NULL
4 2 # freeze-Past-Dec froze
 4.1 2 # freeze froze
 4.2 0 # -Past NULL
 4.3 0 # -Dec NULL
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
ku-ka han-sikan-nayey mwul-ul elli-ess-ta .
he-Nom 1-hour-in water-Acc freeze-Past-Dec .
He froze the water in an hour .

1 4 # ku-ka elli-ess-ta
2 4 # han-sikan-nayey elli-ess-ta
3 4 # mwul-ul elli-ess-ta
4 -1 # elli-ess-ta *TOP*
5 4 # . elli-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8206 Url_id=397 flag=0 cleaned=4 src_leng=5 trans_leng=7
John-i Mary-eykey ka-lako amsi.hay-ss-ta .
John-Nom Mary-Dat go-Cmp suggest-Pst-Dec .
John suggested going , to Mary .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD suggested) (VP (VBG going) (, ,) (PP (TO to) (NP (NNP Mary))))) (. .))

(S+going (NP+John (NNP John))
         (VP+going (VBD suggested)
                   (VP+going (VBG going)
                             (, ,)
                             (PP+to (TO to)
                                    (NP+Mary (NNP Mary)))))
         (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
John suggested going , to Mary .
1 2 # John going x
2 -1 # suggested going x
3 2 # going *TOP* x
4 3 # , going
5 2 # to going x
6 5 # Mary to
7 2 # . going x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
John-i Mary-eykey ka-lako amsi.hay-ss-ta .
John-Nom Mary-Dat go-Cmp suggest-Pst-Dec .

1 1 # John-i John-Nom
 1.1 1.1 # John John
 1.2 1.2 # -i -Nom
2 2 # Mary-eykey Mary-Dat
 2.1 2.1 # Mary Mary
 2.2 2.2 # -eykey -Dat
3 3 # ka-lako go-Cmp
 3.1 3.1 # ka go
 3.2 3.2 # -lako -Cmp
4 4 # amsi.hay-ss-ta suggest-Pst-Dec
 4.1 4.1 # amsi.hay suggest
 4.2 4.2 # -ss -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Nom Mary-Dat go-Cmp suggest-Pst-Dec .
John suggested going , to Mary .

1 1 # John-Nom John
 1.1 1 # John John
 1.2 0 # -Nom NULL
2 6 # Mary-Dat Mary
 2.1 6 # Mary Mary
 2.2 0 # -Dat NULL
3 3 # go-Cmp going
 3.1 3 # go going
 3.2 0 # -Cmp NULL
4 2 # suggest-Pst-Dec suggested
 4.1 2 # suggest suggested
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-i Mary-eykey ka-lako amsi.hay-ss-ta .
John-Nom Mary-Dat go-Cmp suggest-Pst-Dec .
John suggested going , to Mary .

1 4 # John-i ka-lako x
2 4 # Mary-eykey ka-lako x
3 4 # ka-lako *TOP* x
4 -1 # amsi.hay-ss-ta ka-lako x
5 4 # . ka-lako x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8207 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=9
John-i Mary-eykey Bill-i o-l-kes-ilako amsi.hay-ss-ta .
John-Nom Mary-Dat Bill-Nom come-Fut-thing-Cmp suggest-Pst-Dec .
John suggested to Mary that Bill would come .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD suggested) (PP (TO to) (NP (NNP Mary))) (SBAR (IN that) (S (NP (NN Bill)) (VP (MD would) (VP (VB come)))))) (. .))

(S+suggested (NP+John (NNP John))
             (VP+suggested (VBD suggested)
                           (PP+to (TO to)
                                  (NP+Mary (NNP Mary)))
                           (SBAR+come (IN that)
                                      (S+come (NP+Bill (NN Bill))
                                              (VP+come (MD would)
                                                       (VP+come (VB come))))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John suggested to Mary that Bill would come .
1 2 # John suggested
2 -1 # suggested *TOP*
3 2 # to suggested
4 3 # Mary to
5 8 # that come
6 8 # Bill come
7 8 # would come
8 2 # come suggested
9 2 # . suggested


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-i Mary-eykey Bill-i o-l-kes-ilako amsi.hay-ss-ta .
John-Nom Mary-Dat Bill-Nom come-Fut-thing-Cmp suggest-Pst-Dec .

1 1 # John-i John-Nom
 1.1 1.1 # John John
 1.2 1.2 # -i -Nom
2 2 # Mary-eykey Mary-Dat
 2.1 2.1 # Mary Mary
 2.2 2.2 # -eykey -Dat
3 3 # Bill-i Bill-Nom
 3.1 3.1 # Bill Bill
 3.2 3.2 # -i -Nom
4 4 # o-l-kes-ilako come-Fut-thing-Cmp
 4.1 4.1 # o come
 4.2 4.2 # -l -Fut
 4.3 4.3 # -kes -thing
 4.4 4.4 # -ilako -Cmp
5 5 # amsi.hay-ss-ta suggest-Pst-Dec
 5.1 5.1 # amsi.hay suggest
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Nom Mary-Dat Bill-Nom come-Fut-thing-Cmp suggest-Pst-Dec .
John suggested to Mary that Bill would come .

1 1 # John-Nom John
 1.1 1 # John John
 1.2 0 # -Nom NULL
2 4 # Mary-Dat Mary
 2.1 4 # Mary Mary
 2.2 0 # -Dat NULL
3 6 # Bill-Nom Bill
 3.1 6 # Bill Bill
 3.2 0 # -Nom NULL
4 8 # come-Fut-thing-Cmp come
 4.1 8 # come come
 4.2 0 # -Fut NULL
 4.3 0 # -thing NULL
 4.4 0 # -Cmp NULL
5 2 # suggest-Pst-Dec suggested
 5.1 2 # suggest suggested
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-i Mary-eykey Bill-i o-l-kes-ilako amsi.hay-ss-ta .
John-Nom Mary-Dat Bill-Nom come-Fut-thing-Cmp suggest-Pst-Dec .
John suggested to Mary that Bill would come .

1 5 # John-i amsi.hay-ss-ta
2 5 # Mary-eykey amsi.hay-ss-ta
3 4 # Bill-i o-l-kes-ilako
4 5 # o-l-kes-ilako amsi.hay-ss-ta
5 -1 # amsi.hay-ss-ta *TOP*
6 5 # . amsi.hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8208 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=8
John-i salam-tul-eykey cencayng-ul amsi.hay-ss-ta .
John-Nom person-Plur-Dat war-Acc suggest-Pst-Dec .
John suggested a war to the people .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD suggested) (NP (DT a) (NN war)) (PP (TO to) (NP (DT the) (NNS people)))) (. .))

(S+suggested (NP+John (NNP John))
             (VP+suggested (VBD suggested)
                           (NP+war (DT a)
                                   (NN war))
                           (PP+to (TO to)
                                  (NP+people (DT the)
                                             (NNS people))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John suggested a war to the people .
1 2 # John suggested
2 -1 # suggested *TOP*
3 4 # a war
4 2 # war suggested
5 2 # to suggested
6 7 # the people
7 5 # people to
8 2 # . suggested


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-i salam-tul-eykey cencayng-ul amsi.hay-ss-ta .
John-Nom person-Plur-Dat war-Acc suggest-Pst-Dec .

1 1 # John-i John-Nom
 1.1 1.1 # John John
 1.2 1.2 # -i -Nom
2 2 # salam-tul-eykey person-Plur-Dat
 2.1 2.1 # salam person
 2.2 2.2 # -tul -Plur
 2.3 2.3 # -eykey -Dat
3 3 # cencayng-ul war-Acc
 3.1 3.1 # cencayng war
 3.2 3.2 # -ul -Acc
4 4 # amsi.hay-ss-ta suggest-Pst-Dec
 4.1 4.1 # amsi.hay suggest
 4.2 4.2 # -ss -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Nom person-Plur-Dat war-Acc suggest-Pst-Dec .
John suggested a war to the people .

1 1 # John-Nom John
 1.1 1 # John John
 1.2 0 # -Nom NULL 
2 7 # person-Plur-Dat NULL x
 2.1 0 # person NULL
 2.2 0 # -Plur NULL
 2.3 0 # -Dat NULL
3 4 # war-Acc war
 3.1 4 # war war
 3.2 0 # -Acc NULL
4 2 # suggest-Pst-Dec suggested
 4.1 2 # suggest suggested
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
John-i salam-tul-eykey cencayng-ul amsi.hay-ss-ta .
John-Nom person-Plur-Dat war-Acc suggest-Pst-Dec .
John suggested a war to the people .

1 4 # John-i amsi.hay-ss-ta
2 4 # salam-tul-eykey amsi.hay-ss-ta
3 4 # cencayng-ul amsi.hay-ss-ta
4 -1 # amsi.hay-ss-ta *TOP*
5 4 # . amsi.hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8209 Url_id=397 flag=0 cleaned=3 src_leng=7 trans_leng=10
Ku-ka wuli-tul-eykey ku sasil-ul yu.uy.ha-lako yochong.hay-ss-ta .
he-Nom us-Plur-Dat that fact-Acc pay.attention-Cmp request-Pst-Dec .
He requested us to pay attention to the fact .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP He)) (VP (VBD requested) (NP (PRP us)) (S (VP (TO to) (VP (VB pay) (NP (NN attention)) (PP (TO to) (NP (DT the) (NN fact))))))) (. .))

(S+requested (NP+He (PRP He))
             (VP+requested (VBD requested)
                           (NP+us (PRP us))
                           (S+pay (VP+pay (TO to)
                                          (VP+pay (VB pay)
                                                  (NP+attention (NN attention))
                                                  (PP+to (TO to)
                                                         (NP+fact (DT the)
                                                                  (NN fact)))))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
He requested us to pay attention to the fact .
1 2 # He requested
2 -1 # requested *TOP*
3 2 # us requested
4 5 # to pay
5 2 # pay requested
6 5 # attention pay
7 5 # to pay
8 9 # the fact
9 7 # fact to
10 2 # . requested


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Ku-ka wuli-tul-eykey ku sasil-ul yu.uy.ha-lako yochong.hay-ss-ta .
he-Nom us-Plur-Dat that fact-Acc pay.attention-Cmp request-Pst-Dec .

1 1 # Ku-ka he-Nom
 1.1 1.1 # Ku he
 1.2 1.2 # -ka -Nom
2 2 # wuli-tul-eykey us-Plur-Dat
 2.1 2.1 # wuli us
 2.2 2.2 # -tul -Plur
 2.3 2.3 # -eykey -Dat
3 3 # ku that
4 4 # sasil-ul fact-Acc
 4.1 4.1 # sasil fact
 4.2 4.2 # -ul -Acc
5 5 # yu.uy.ha-lako pay.attention-Cmp
 5.1 5.1 # yu.uy.ha pay.attention
 5.2 5.2 # -lako -Cmp
6 6 # yochong.hay-ss-ta request-Pst-Dec
 6.1 6.1 # yochong.hay request
 6.2 6.2 # -ss -Pst
 6.3 6.3 # -ta -Dec
7 7 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
he-Nom us-Plur-Dat that fact-Acc pay.attention-Cmp request-Pst-Dec .
He requested us to pay attention to the fact .

1 1 # he-Nom He
 1.1 1 # he He
 1.2 0 # -Nom NULL
2 3 # us-Plur-Dat us
 2.1 3 # us us
 2.2 0 # -Plur NULL
 2.3 0 # -Dat NULL
3 0 # that NULL
4 9 # fact-Acc fact
 4.1 9 # fact fact
 4.2 0 # -Acc NULL
5 5,6 # pay.attention-Cmp pay,attention
 5.1 5,6 # pay.attention pay,attention
 5.2 0 # -Cmp NULL
6 2 # request-Pst-Dec requested
 6.1 2 # request requested
 6.2 0 # -Pst NULL
 6.3 0 # -Dec NULL
7 10 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Ku-ka wuli-tul-eykey ku sasil-ul yu.uy.ha-lako yochong.hay-ss-ta .
he-Nom us-Plur-Dat that fact-Acc pay.attention-Cmp request-Pst-Dec .
He requested us to pay attention to the fact .

1 6 # Ku-ka yochong.hay-ss-ta
2 6 # wuli-tul-eykey yochong.hay-ss-ta
3 4 # ku yochong.hay-ss-ta x
4 5 # sasil-ul yu.uy.ha-lako
5 6 # yu.uy.ha-lako yochong.hay-ss-ta
6 -1 # yochong.hay-ss-ta *TOP*
7 6 # . yochong.hay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8211 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
Swuni-ka tases-kay kwuk-e-lul ha-n-ta .
Swuni-Nom ve-Clasf nation-language-Acc do-Pres-Dec .
Swuni can speak ve languages .

######## Q1: IGT is clean? Answer: x
#dj "ve" for "five" but the parse works
#dj "do" vs "can speak"


############################## Q2: English parse tree 
(S (NP (NNP Swuni)) (VP (MD can) (VP (VB speak) (NP (JJ ve) (NNS languages)))) (. .))

(S+speak (NP+Swuni (NNP Swuni))
         (VP+speak (MD can)
                   (VP+speak (VB speak)
                             (NP+languages (JJ ve)
                                           (NNS languages))))
         (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Swuni can speak ve languages .
1 3 # Swuni speak
2 3 # can speak
3 -1 # speak *TOP*
4 5 # ve languages
5 3 # languages speak
6 3 # . speak


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Swuni-ka tases-kay kwuk-e-lul ha-n-ta .
Swuni-Nom ve-Clasf nation-language-Acc do-Pres-Dec .

1 1 # Swuni-ka Swuni-Nom
 1.1 1.1 # Swuni Swuni
 1.2 1.2 # -ka -Nom
2 2 # tases-kay ve-Clasf
 2.1 2.1 # tases ve
 2.2 2.2 # -kay -Clasf
3 3 # kwuk-e-lul nation-language-Acc
 3.1 3.1 # kwuk nation
 3.2 3.2 # -e -language
 3.3 3.3 # -lul -Acc
4 4 # ha-n-ta do-Pres-Dec
 4.1 4.1 # ha do
 4.2 4.2 # -n -Pres
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Swuni-Nom ve-Clasf nation-language-Acc do-Pres-Dec .
Swuni can speak ve languages .

1 1 # Swuni-Nom Swuni
 1.1 1 # Swuni Swuni
 1.2 0 # -Nom NULL
2 4 # ve-Clasf ve
 2.1 4 # ve ve
 2.2 0 # -Clasf NULL
3 5 # nation-language-Acc languages
 3.1 0 # nation NULL
 3.2 5 # -language languages
 3.3 0 # -Acc NULL
4 0 # do-Pres-Dec NULL
 4.1 0 # do NULL
 4.2 0 # -Pres NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Swuni-ka tases-kay kwuk-e-lul ha-n-ta .
Swuni-Nom ve-Clasf nation-language-Acc do-Pres-Dec .
Swuni can speak ve languages .

1 4 # Swuni-ka ha-n-ta
2 3 # tases-kay kwuk-e-lul
3 4 # kwuk-e-lul ha-n-ta
4 -2 # ha-n-ta NULL
5 4 # . ha-n-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8212 Url_id=397 flag=0 cleaned=4 src_leng=4 trans_leng=5
Kunye-ka acwu chicek-i-ta .
she-Nom very intelligent-be-Pres .
She 's very intelligent .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP She)) (VP (VBZ 's) (ADJP (RB very) (JJ intelligent))) (. .))

(S+intelligent (NP+She (PRP She))
               (VP+intelligent (VBZ 's)
                               (ADJP-PRD+intelligent (RB very)
                                                     (JJ intelligent)))
               (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
She 's very intelligent .
1 4 # She intelligent
2 4 # 's intelligent
3 4 # very intelligent
4 -1 # intelligent *TOP*
5 4 # . intelligent


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Kunye-ka acwu chicek-i-ta .
she-Nom very intelligent-be-Pres .

1 1 # Kunye-ka she-Nom
 1.1 1.1 # Kunye she
 1.2 1.2 # -ka -Nom
2 2 # acwu very
3 3 # chicek-i-ta intelligent-be-Pres
 3.1 3.1 # chicek intelligent
 3.2 3.2 # -i -be
 3.3 3.3 # -ta -Pres
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
she-Nom very intelligent-be-Pres .
She 's very intelligent .

1 1 # she-Nom She
 1.1 1 # she She
 1.2 0 # -Nom NULL
2 3 # very very
3 4 # intelligent-be-Pres intelligent
 3.1 4 # intelligent intelligent
 3.2 0 # -be NULL
 3.3 0 # -Pres NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Kunye-ka acwu chicek-i-ta .
she-Nom very intelligent-be-Pres .
She 's very intelligent .

1 3 # Kunye-ka chicek-i-ta
2 3 # acwu chicek-i-ta
3 -1 # chicek-i-ta *TOP*
4 3 # . chicek-i-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8213 Url_id=397 flag=0 cleaned=4 src_leng=3 trans_leng=5
Acwu chicek-i-ta .
very intelligent-be-Pres .
She 's very intelligent .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP She)) (VP (VBZ 's) (ADJP (RB very) (JJ intelligent))) (. .))

(S+intelligent (NP+She (PRP She))
               (VP+intelligent (VBZ 's)
                               (ADJP-PRD+intelligent (RB very)
                                                     (JJ intelligent)))
               (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
She 's very intelligent .
1 4 # She intelligent
2 4 # 's intelligent
3 4 # very intelligent
4 -1 # intelligent *TOP*
5 4 # . intelligent


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Acwu chicek-i-ta .
very intelligent-be-Pres .

1 1 # Acwu very
2 2 # chicek-i-ta intelligent-be-Pres
 2.1 2.1 # chicek intelligent
 2.2 2.2 # -i -be
 2.3 2.3 # -ta -Pres
3 3 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
very intelligent-be-Pres .
She 's very intelligent .

1 3 # very very
2 4 # intelligent-be-Pres intelligent
 2.1 4 # intelligent intelligent
 2.2 0 # -be NULL
 2.3 0 # -Pres NULL
3 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Acwu chicek-i-ta .
very intelligent-be-Pres .
She 's very intelligent .

1 2 # Acwu chicek-i-ta
2 -1 # chicek-i-ta *TOP*
3 2 # . chicek-i-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8214 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
Na-nun kwaca-lul iceymak kwuw-ess-ta .
I-Top cookie-Acc just.now bake-Pst-Dec .
I just made some cookies .

######## Q1: IGT is clean? Answer: x
#dj "bake" vs "made"


############################## Q2: English parse tree 
(S (NP (PRP I)) (ADVP (RB just)) (VP (VBD made) (NP (DT some) (NNS cookies))) (. .))

(S+made (NP+I (PRP I))
        (ADVP+just (RB just))
        (VP+made (VBD made)
                 (NP+cookies (DT some)
                             (NNS cookies)))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
I just made some cookies .
1 3 # I made
2 3 # just made
3 -1 # made *TOP*
4 5 # some cookies
5 3 # cookies made
6 3 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Na-nun kwaca-lul iceymak kwuw-ess-ta .
I-Top cookie-Acc just.now bake-Pst-Dec .

1 1 # Na-nun I-Top
 1.1 1.1 # Na I
 1.2 1.2 # -nun -Top
2 2 # kwaca-lul cookie-Acc
 2.1 2.1 # kwaca cookie
 2.2 2.2 # -lul -Acc
3 3 # iceymak just.now
4 4 # kwuw-ess-ta bake-Pst-Dec
 4.1 4.1 # kwuw bake
 4.2 4.2 # -ess -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
I-Top cookie-Acc just.now bake-Pst-Dec .
I just made some cookies .

1 1 # I-Top I
 1.1 1 # I I
 1.2 0 # -Top NULL
2 0 # cookie-Acc NULL
 2.1 0 # cookie NULL
 2.2 0 # -Acc NULL
3 2 # just.now just
4 0 # bake-Pst-Dec NULL
 4.1 0 # bake NULL
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Na-nun kwaca-lul iceymak kwuw-ess-ta .
I-Top cookie-Acc just.now bake-Pst-Dec .
I just made some cookies .

1 4 # Na-nun kwuw-ess-ta
2 4 # kwaca-lul kwuw-ess-ta
3 4 # iceymak kwuw-ess-ta
4 -2 # kwuw-ess-ta NULL
5 4 # . kwuw-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8218 Url_id=397 flag=0 cleaned=3 src_leng=4 trans_leng=6
Nay-ka tongsayng-i pyenhosa-i-ta .
I-Nom sister-Nom lawyer-be-Dec .
My sister is a lawyer .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (PRP$ My) (NN sister)) (VP (VBZ is) (NP (DT a) (NN lawyer))) (. .))

(S+lawyer (NP+sister (PRP$ My)
                     (NN sister))
          (VP+lawyer (VBZ is)
                     (NP-PRD+lawyer (DT a)
                                    (NN lawyer)))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
My sister is a lawyer .
1 2 # My sister
2 5 # sister lawyer
3 5 # is lawyer
4 5 # a lawyer
5 -1 # lawyer *TOP*
6 5 # . lawyer


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Nay-ka tongsayng-i pyenhosa-i-ta .
I-Nom sister-Nom lawyer-be-Dec .

1 1 # Nay-ka I-Nom
 1.1 1.1 # Nay I
 1.2 1.2 # -ka -Nom
2 2 # tongsayng-i sister-Nom
 2.1 2.1 # tongsayng sister
 2.2 2.2 # -i -Nom
3 3 # pyenhosa-i-ta lawyer-be-Dec
 3.1 3.1 # pyenhosa lawyer
 3.2 3.2 # -i -be
 3.3 3.3 # -ta -Dec
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Nom sister-Nom lawyer-be-Dec .
My sister is a lawyer .

1 1 # I-Nom NULL x
 1.1 0 # I NULL
 1.2 0 # -Nom NULL
2 2 # sister-Nom sister
 2.1 2 # sister sister
 2.2 0 # -Nom NULL
3 3,5 # lawyer-be-Dec is,lawyer
 3.1 5 # lawyer lawyer
 3.2 3 # -be is
 3.3 0 # -Dec NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Nay-ka tongsayng-i pyenhosa-i-ta .
I-Nom sister-Nom lawyer-be-Dec .
My sister is a lawyer .

1 3 # Nay-ka pyenhosa-i-ta
2 3 # tongsayng-i pyenhosa-i-ta
3 -1 # pyenhosa-i-ta *TOP*
4 3 # . pyenhosa-i-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8219 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
Haksayng-i chayk-i sey-kwan-i philyo.ha-ta .
student-Nom book-Nom three-volumes-Nom need-Dec .
The student needs three books .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN student)) (VP (VBZ needs) (NP (CD three) (NNS books))) (. .))

(S+needs (NP+student (DT The)
                     (NN student))
         (VP+needs (VBZ needs)
                   (NP+books (CD three)
                             (NNS books)))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The student needs three books .
1 2 # The student
2 3 # student needs
3 -1 # needs *TOP*
4 5 # three books
5 3 # books needs
6 3 # . needs


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Haksayng-i chayk-i sey-kwan-i philyo.ha-ta .
student-Nom book-Nom three-volumes-Nom need-Dec .

1 1 # Haksayng-i student-Nom
 1.1 1.1 # Haksayng student
 1.2 1.2 # -i -Nom
2 2 # chayk-i book-Nom
 2.1 2.1 # chayk book
 2.2 2.2 # -i -Nom
3 3 # sey-kwan-i three-volumes-Nom
 3.1 3.1 # sey three
 3.2 3.2 # -kwan -volumes
 3.3 3.3 # -i -Nom
4 4 # philyo.ha-ta need-Dec
 4.1 4.1 # philyo.ha need
 4.2 4.2 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
student-Nom book-Nom three-volumes-Nom need-Dec .
The student needs three books .

1 2 # student-Nom student
 1.1 2 # student student
 1.2 0 # -Nom NULL
2 5 # book-Nom books
 2.1 5 # book books
 2.2 0 # -Nom NULL
3 4 # three-volumes-Nom three
 3.1 4 # three three
 3.2 0 # -volumes NULL
 3.3 0 # -Nom NULL
4 3 # need-Dec needs
 4.1 3 # need needs
 4.2 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Haksayng-i chayk-i sey-kwan-i philyo.ha-ta .
student-Nom book-Nom three-volumes-Nom need-Dec .
The student needs three books .

1 4 # Haksayng-i philyo.ha-ta
2 4 # chayk-i philyo.ha-ta
3 2 # sey-kwan-i chayk-i
4 -1 # philyo.ha-ta *TOP*
5 4 # . philyo.ha-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8220 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=9
Emeni-kkeyse ai-lul pap-ul mek-key hay-ss-ta .
mother-HNom child-Acc rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (DT The) (NN mother)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB eat) (NP (DT the) (NN rice))))) (. .))

(S+made (NP+mother (DT The)
                   (NN mother))
        (VP+made (VBD made)
                 (S+eat (NP+child (DT the)
                                  (NN child))
                        (VP+eat (VB eat)
                                (NP+rice (DT the)
                                         (NN rice)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The mother made the child eat the rice .
1 2 # The mother
2 3 # mother made
3 -1 # made *TOP*
4 5 # the child
5 6 # child eat
6 3 # eat made
7 8 # the rice
8 6 # rice eat
9 3 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-lul pap-ul mek-key hay-ss-ta .
mother-HNom child-Acc rice-Acc eat-Adv do-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-lul child-Acc
 2.1 2.1 # ai child
 2.2 2.2 # -lul -Acc
3 3 # pap-ul rice-Acc
 3.1 3.1 # pap rice
 3.2 3.2 # -ul -Acc
4 4 # mek-key eat-Adv
 4.1 4.1 # mek eat
 4.2 4.2 # -key -Adv
5 5 # hay-ss-ta do-Pst-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom child-Acc rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

1 2 # mother-HNom mother
 1.1 2 # mother mother
 1.2 0 # -HNom NULL
2 5 # child-Acc child
 2.1 5 # child child
 2.2 0 # -Acc NULL
3 8 # rice-Acc rice
 3.1 8 # rice rice
 3.2 0 # -Acc NULL
4 6 # eat-Adv eat
 4.1 6 # eat eat
 4.2 0 # -Adv NULL
5 0 # do-Pst-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse ai-lul pap-ul mek-key hay-ss-ta .
mother-HNom child-Acc rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

1 5 # Emeni-kkeyse hay-ss-ta
2 4 # ai-lul mek-key
3 4 # pap-ul mek-key
4 5 # mek-key hay-ss-ta
5 -2 # hay-ss-ta NULL
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8221 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=9
Emeni-kkeyse ai-eykey pap-ul mek-key hay-ss-ta .
mother-HNom child-Dat rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (DT The) (NN mother)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB eat) (NP (DT the) (NN rice))))) (. .))

(S+made (NP+mother (DT The)
                   (NN mother))
        (VP+made (VBD made)
                 (S+eat (NP+child (DT the)
                                  (NN child))
                        (VP+eat (VB eat)
                                (NP+rice (DT the)
                                         (NN rice)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The mother made the child eat the rice .
1 2 # The mother
2 3 # mother made
3 -1 # made *TOP*
4 5 # the child
5 6 # child eat
6 3 # eat made
7 8 # the rice
8 6 # rice eat
9 3 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-eykey pap-ul mek-key hay-ss-ta .
mother-HNom child-Dat rice-Acc eat-Adv do-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-eykey child-Dat
 2.1 2.1 # ai child
 2.2 2.2 # -eykey -Dat
3 3 # pap-ul rice-Acc
 3.1 3.1 # pap rice
 3.2 3.2 # -ul -Acc
4 4 # mek-key eat-Adv
 4.1 4.1 # mek eat
 4.2 4.2 # -key -Adv
5 5 # hay-ss-ta do-Pst-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom child-Dat rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

1 2 # mother-HNom mother
 1.1 2 # mother mother
 1.2 0 # -HNom NULL
2 5 # child-Dat child
 2.1 5 # child child
 2.2 0 # -Dat NULL
3 8 # rice-Acc rice
 3.1 8 # rice rice
 3.2 0 # -Acc NULL
4 6 # eat-Adv eat
 4.1 6 # eat eat
 4.2 0 # -Adv NULL
5 0 # do-Pst-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse ai-eykey pap-ul mek-key hay-ss-ta .
mother-HNom child-Dat rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

1 5 # Emeni-kkeyse hay-ss-ta
2 4 # ai-eykey mek-key
3 4 # pap-ul mek-key
4 5 # mek-key hay-ss-ta
5 -2 # hay-ss-ta NULL
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8222 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=9
Emeni-kkeyse ai-ka pap-ul mek-key hay-ss-ta .
mother-HNom child-Nom rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (DT The) (NN mother)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB eat) (NP (DT the) (NN rice))))) (. .))

(S+made (NP+mother (DT The)
                   (NN mother))
        (VP+made (VBD made)
                 (S+eat (NP+child (DT the)
                                  (NN child))
                        (VP+eat (VB eat)
                                (NP+rice (DT the)
                                         (NN rice)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The mother made the child eat the rice .
1 2 # The mother
2 3 # mother made
3 -1 # made *TOP*
4 5 # the child
5 6 # child eat
6 3 # eat made
7 8 # the rice
8 6 # rice eat
9 3 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-ka pap-ul mek-key hay-ss-ta .
mother-HNom child-Nom rice-Acc eat-Adv do-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-ka child-Nom
 2.1 2.1 # ai child
 2.2 2.2 # -ka -Nom
3 3 # pap-ul rice-Acc
 3.1 3.1 # pap rice
 3.2 3.2 # -ul -Acc
4 4 # mek-key eat-Adv
 4.1 4.1 # mek eat
 4.2 4.2 # -key -Adv
5 5 # hay-ss-ta do-Pst-Dec
 5.1 5.1 # hay do
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom child-Nom rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

1 2 # mother-HNom mother
 1.1 2 # mother mother
 1.2 0 # -HNom NULL
2 5 # child-Nom child
 2.1 5 # child child
 2.2 0 # -Nom NULL
3 8 # rice-Acc rice
 3.1 8 # rice rice
 3.2 0 # -Acc NULL
4 6 # eat-Adv eat
 4.1 6 # eat eat
 4.2 0 # -Adv NULL
5 0 # do-Pst-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse ai-ka pap-ul mek-key hay-ss-ta .
mother-HNom child-Nom rice-Acc eat-Adv do-Pst-Dec .
The mother made the child eat the rice .

1 5 # Emeni-kkeyse hay-ss-ta
2 4 # ai-ka mek-key
3 4 # pap-ul mek-key
4 5 # mek-key hay-ss-ta
5 -2 # hay-ss-ta NULL
6 5 # . hay-ss-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8229 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Emeni-kkeyse ai-eykey chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Dat book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mother)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB read) (NP (DT the) (NN book))))) (. .))

(S+made (NP+Mother (NNP Mother))
        (VP+made (VBD made)
                 (S+read (NP+child (DT the)
                                   (NN child))
                         (VP+read (VB read)
                                  (NP+book (DT the)
                                           (NN book)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mother made the child read the book .
1 2 # Mother made
2 -1 # made *TOP*
3 4 # the child
4 5 # child read
5 2 # read made
6 7 # the book
7 5 # book read
8 2 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-eykey chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Dat book-Acc read-Adv do-Hon-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-eykey child-Dat
 2.1 2.1 # ai child
 2.2 2.2 # -eykey -Dat
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-key read-Adv
 4.1 4.1 # ilk read
 4.2 4.2 # -key -Adv
5 5 # ha-si-ess-ta do-Hon-Pst-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -si -Hon
 5.3 5.3 # -ess -Pst
 5.4 5.4 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom child-Dat book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

1 1 # mother-HNom Mother
 1.1 1 # mother Mother
 1.2 0 # -HNom NULL
2 4 # child-Dat child
 2.1 4 # child child
 2.2 0 # -Dat NULL
3 7 # book-Acc book
 3.1 7 # book book
 3.2 0 # -Acc NULL
4 5 # read-Adv read
 4.1 5 # read read
 4.2 0 # -Adv NULL
5 0 # do-Hon-Pst-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Hon NULL
 5.3 0 # -Pst NULL
 5.4 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse ai-eykey chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Dat book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

1 5 # Emeni-kkeyse ha-si-ess-ta
2 4 # ai-eykey ilk-key
3 4 # chayk-ul ilk-key
4 5 # ilk-key ha-si-ess-ta
5 -2 # ha-si-ess-ta NULL
6 5 # . ha-si-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8230 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Emeni-kkeyse ai-lul chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Acc book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mother)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB read) (NP (DT the) (NN book))))) (. .))

(S+made (NP+Mother (NNP Mother))
        (VP+made (VBD made)
                 (S+read (NP+child (DT the)
                                   (NN child))
                         (VP+read (VB read)
                                  (NP+book (DT the)
                                           (NN book)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mother made the child read the book .
1 2 # Mother made
2 -1 # made *TOP*
3 4 # the child
4 5 # child read
5 2 # read made
6 7 # the book
7 5 # book read
8 2 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-lul chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Acc book-Acc read-Adv do-Hon-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-lul child-Acc
 2.1 2.1 # ai child
 2.2 2.2 # -lul -Acc
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-key read-Adv
 4.1 4.1 # ilk read
 4.2 4.2 # -key -Adv
5 5 # ha-si-ess-ta do-Hon-Pst-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -si -Hon
 5.3 5.3 # -ess -Pst
 5.4 5.4 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom child-Acc book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

1 1 # mother-HNom Mother
 1.1 1 # mother Mother
 1.2 0 # -HNom NULL
2 4 # child-Acc child
 2.1 4 # child child
 2.2 0 # -Acc NULL
3 7 # book-Acc book
 3.1 7 # book book
 3.2 0 # -Acc NULL
4 5 # read-Adv read
 4.1 5 # read read
 4.2 0 # -Adv NULL
5 0 # do-Hon-Pst-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Hon NULL
 5.3 0 # -Pst NULL
 5.4 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse ai-lul chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Acc book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

1 5 # Emeni-kkeyse ha-si-ess-ta
2 4 # ai-lul ilk-key
3 4 # chayk-ul ilk-key
4 5 # ilk-key ha-si-ess-ta
5 -2 # ha-si-ess-ta NULL
6 5 # . ha-si-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8231 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Emeni-kkeyse ai-ka chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Nom book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mother)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB read) (NP (DT the) (NN book))))) (. .))

(S+made (NP+Mother (NNP Mother))
        (VP+made (VBD made)
                 (S+read (NP+child (DT the)
                                   (NN child))
                         (VP+read (VB read)
                                  (NP+book (DT the)
                                           (NN book)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mother made the child read the book .
1 2 # Mother made
2 -1 # made *TOP*
3 4 # the child
4 5 # child read
5 2 # read made
6 7 # the book
7 5 # book read
8 2 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-ka chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Nom book-Acc read-Adv do-Hon-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-ka child-Nom
 2.1 2.1 # ai child
 2.2 2.2 # -ka -Nom
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-key read-Adv
 4.1 4.1 # ilk read
 4.2 4.2 # -key -Adv
5 5 # ha-si-ess-ta do-Hon-Pst-Dec
 5.1 5.1 # ha do
 5.2 5.2 # -si -Hon
 5.3 5.3 # -ess -Pst
 5.4 5.4 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom child-Nom book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

1 1 # mother-HNom Mother
 1.1 1 # mother Mother
 1.2 0 # -HNom NULL
2 4 # child-Nom child
 2.1 4 # child child
 2.2 0 # -Nom NULL
3 7 # book-Acc book
 3.1 7 # book book
 3.2 0 # -Acc NULL
4 5 # read-Adv read
 4.1 5 # read read
 4.2 0 # -Adv NULL
5 0 # do-Hon-Pst-Dec NULL
 5.1 0 # do NULL
 5.2 0 # -Hon NULL
 5.3 0 # -Pst NULL
 5.4 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse ai-ka chayk-ul ilk-key ha-si-ess-ta .
mother-HNom child-Nom book-Acc read-Adv do-Hon-Pst-Dec .
Mother made the child read the book .

1 5 # Emeni-kkeyse ha-si-ess-ta
2 4 # ai-ka ilk-key
3 4 # chayk-ul ilk-key
4 5 # ilk-key ha-si-ess-ta
5 -2 # ha-si-ess-ta NULL
6 5 # . ha-si-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8235 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=9
Emeni-kkeyse ai-eykey chayk-ul ilk-tolok seltuk.ha-si-ess-ta .
Mother-HNom child-Dat book-Acc read-Cmp persuade-Hon-Pst-Dec .
Mother persuaded the child to read the book .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NN Mother)) (VP (VBD persuaded) (NP (DT the) (NN child)) (S (VP (TO to) (VP (VB read) (NP (DT the) (NN book)))))) (. .))

(S+persuaded (NP+Mother (NN Mother))
             (VP+persuaded (VBD persuaded)
                           (NP+child (DT the)
                                     (NN child))
                           (S+read (VP+read (TO to)
                                            (VP+read (VB read)
                                                     (NP+book (DT the)
                                                              (NN book))))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Mother persuaded the child to read the book .
1 2 # Mother persuaded
2 -1 # persuaded *TOP*
3 4 # the child
4 2 # child persuaded
5 6 # to read
6 2 # read persuaded
7 8 # the book
8 6 # book read
9 2 # . persuaded


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Emeni-kkeyse ai-eykey chayk-ul ilk-tolok seltuk.ha-si-ess-ta .
Mother-HNom child-Dat book-Acc read-Cmp persuade-Hon-Pst-Dec .

1 1 # Emeni-kkeyse Mother-HNom
 1.1 1.1 # Emeni Mother
 1.2 1.2 # -kkeyse -HNom
2 2 # ai-eykey child-Dat
 2.1 2.1 # ai child
 2.2 2.2 # -eykey -Dat
3 3 # chayk-ul book-Acc
 3.1 3.1 # chayk book
 3.2 3.2 # -ul -Acc
4 4 # ilk-tolok read-Cmp
 4.1 4.1 # ilk read
 4.2 4.2 # -tolok -Cmp
5 5 # seltuk.ha-si-ess-ta persuade-Hon-Pst-Dec
 5.1 5.1 # seltuk.ha persuade
 5.2 5.2 # -si -Hon
 5.3 5.3 # -ess -Pst
 5.4 5.4 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Mother-HNom child-Dat book-Acc read-Cmp persuade-Hon-Pst-Dec .
Mother persuaded the child to read the book .

1 1 # Mother-HNom Mother
 1.1 1 # Mother Mother
 1.2 0 # -HNom NULL
2 4 # child-Dat child
 2.1 4 # child child
 2.2 0 # -Dat NULL
3 8 # book-Acc book
 3.1 8 # book book
 3.2 0 # -Acc NULL
4 6 # read-Cmp read
 4.1 6 # read read
 4.2 0 # -Cmp NULL
5 2 # persuade-Hon-Pst-Dec NULL x
 5.1 0 # persuade NULL
 5.2 0 # -Hon NULL
 5.3 0 # -Pst NULL
 5.4 0 # -Dec NULL
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Emeni-kkeyse ai-eykey chayk-ul ilk-tolok seltuk.ha-si-ess-ta .
Mother-HNom child-Dat book-Acc read-Cmp persuade-Hon-Pst-Dec .
Mother persuaded the child to read the book .

1 5 # Emeni-kkeyse seltuk.ha-si-ess-ta
2 5 # ai-eykey seltuk.ha-si-ess-ta
3 4 # chayk-ul ilk-tolok
4 5 # ilk-tolok seltuk.ha-si-ess-ta
5 -1 # seltuk.ha-si-ess-ta NULL
6 5 # . seltuk.ha-si-ess-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8241 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
John-un Mary-ka cip-ey ka-ki-lul palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp-Acc hope-Pst-Dec .
John hoped that Mary would go home .

######## Q1: IGT is clean? Answer: y



############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD hoped) (SBAR (IN that) (S (NP (NNP Mary)) (VP (MD would) (VP (VB go) (ADVP (NN home))))))) (. .))

(S+hoped (NP+John (NNP John))
         (VP+hoped (VBD hoped)
                   (SBAR+go (IN that)
                            (S+go (NP+Mary (NNP Mary))
                                  (VP+go (MD would)
                                         (VP+go (VB go)
                                                (ADVP+home (NN home)))))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John hoped that Mary would go home .
1 2 # John hoped
2 -1 # hoped *TOP*
3 6 # that go
4 6 # Mary go
5 6 # would go
6 2 # go hoped
7 6 # home go
8 2 # . hoped


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un Mary-ka cip-ey ka-ki-lul palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp-Acc hope-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # Mary-ka Mary-Nom
 2.1 2.1 # Mary Mary
 2.2 2.2 # -ka -Nom
3 3 # cip-ey home-Dir
 3.1 3.1 # cip home
 3.2 3.2 # -ey -Dir
4 4 # ka-ki-lul go-Cmp-Acc
 4.1 4.1 # ka go
 4.2 4.2 # -ki -Cmp
 4.3 4.3 # -lul -Acc
5 5 # palay-ss-ta hope-Pst-Dec
 5.1 5.1 # palay hope
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top Mary-Nom home-Dir go-Cmp-Acc hope-Pst-Dec .
John hoped that Mary would go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 4 # Mary-Nom Mary
 2.1 4 # Mary Mary
 2.2 0 # -Nom NULL
3 7 # home-Dir home
 3.1 7 # home home
 3.2 0 # -Dir NULL
4 6 # go-Cmp-Acc go
 4.1 6 # go go
 4.2 0 # -Cmp NULL
 4.3 0 # -Acc NULL
5 2 # hope-Pst-Dec NULL x
 5.1 0 # hope NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
John-un Mary-ka cip-ey ka-ki-lul palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp-Acc hope-Pst-Dec .
John hoped that Mary would go home .

1 5 # John-un palay-ss-ta
2 4 # Mary-ka ka-ki-lul
3 4 # cip-ey ka-ki-lul
4 5 # ka-ki-lul palay-ss-ta
5 -1 # palay-ss-ta NULL x
6 5 # . palay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8242 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=7
Mary-ka cip-ey ka-ki-lul John-un palay-ss-ta .
Mary-Nom home-Dir go-Cmp-Acc John-Top hope-Pst-Dec .
John hoped Mary would go home .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD hoped) (SBAR (S (NP (NNP Mary)) (VP (MD would) (VP (VB go) (ADVP (NN home))))))) (. .))

(S+hoped (NP+John (NNP John))
         (VP+hoped (VBD hoped)
                   (SBAR+go (S+go (NP+Mary (NNP Mary))
                                  (VP+go (MD would)
                                         (VP+go (VB go)
                                                (ADVP+home (NN home)))))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John hoped Mary would go home .
1 2 # John hoped
2 -1 # hoped *TOP*
3 5 # Mary go
4 5 # would go
5 2 # go hoped
6 5 # home go
7 2 # . hoped


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Mary-ka cip-ey ka-ki-lul John-un palay-ss-ta .
Mary-Nom home-Dir go-Cmp-Acc John-Top hope-Pst-Dec .

1 1 # Mary-ka Mary-Nom
 1.1 1.1 # Mary Mary
 1.2 1.2 # -ka -Nom
2 2 # cip-ey home-Dir
 2.1 2.1 # cip home
 2.2 2.2 # -ey -Dir
3 3 # ka-ki-lul go-Cmp-Acc
 3.1 3.1 # ka go
 3.2 3.2 # -ki -Cmp
 3.3 3.3 # -lul -Acc
4 4 # John-un John-Top
 4.1 4.1 # John John
 4.2 4.2 # -un -Top
5 5 # palay-ss-ta hope-Pst-Dec
 5.1 5.1 # palay hope
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Mary-Nom home-Dir go-Cmp-Acc John-Top hope-Pst-Dec .
John hoped Mary would go home .

1 3 # Mary-Nom Mary
 1.1 3 # Mary Mary
 1.2 0 # -Nom NULL
2 6 # home-Dir home
 2.1 6 # home home
 2.2 0 # -Dir NULL
3 5 # go-Cmp-Acc go
 3.1 5 # go go
 3.2 0 # -Cmp NULL
 3.3 0 # -Acc NULL
4 1 # John-Top John
 4.1 1 # John John
 4.2 0 # -Top NULL
5 2 # hope-Pst-Dec NULL x
 5.1 0 # hope NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
Mary-ka cip-ey ka-ki-lul John-un palay-ss-ta .
Mary-Nom home-Dir go-Cmp-Acc John-Top hope-Pst-Dec .
John hoped Mary would go home .

1 3 # Mary-ka ka-ki-lul
2 3 # cip-ey ka-ki-lul
3 5 # ka-ki-lul palay-ss-ta
4 5 # John-un palay-ss-ta
5 -1 # palay-ss-ta NULL x
6 5 # . palay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8243 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
John-un cip-ey ka-ki wen.hay-ss-ta .
John-Top home-Dir go-Cmp want-Pst-Dec .
John wanted to go home .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD wanted) (S (VP (TO to) (VP (VB go) (ADVP (NN home)))))) (. .))

(S+wanted (NP+John (NNP John))
          (VP+wanted (VBD wanted)
                     (S+go (VP+go (TO to)
                                  (VP+go (VB go)
                                         (ADVP+home (NN home))))))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John wanted to go home .
1 2 # John wanted
2 -1 # wanted *TOP*
3 4 # to go
4 2 # go wanted
5 4 # home go
6 2 # . wanted


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un cip-ey ka-ki wen.hay-ss-ta .
John-Top home-Dir go-Cmp want-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # cip-ey home-Dir
 2.1 2.1 # cip home
 2.2 2.2 # -ey -Dir
3 3 # ka-ki go-Cmp
 3.1 3.1 # ka go
 3.2 3.2 # -ki -Cmp
4 4 # wen.hay-ss-ta want-Pst-Dec
 4.1 4.1 # wen.hay want
 4.2 4.2 # -ss -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top home-Dir go-Cmp want-Pst-Dec .
John wanted to go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 5 # home-Dir home
 2.1 5 # home home
 2.2 0 # -Dir NULL
3 4 # go-Cmp go
 3.1 4 # go go
 3.2 0 # -Cmp NULL
4 2 # want-Pst-Dec wanted
 4.1 2 # want wanted
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-un cip-ey ka-ki wen.hay-ss-ta .
John-Top home-Dir go-Cmp want-Pst-Dec .
John wanted to go home .

1 4 # John-un wen.hay-ss-ta
2 3 # cip-ey ka-ki
3 4 # ka-ki wen.hay-ss-ta
4 -1 # wen.hay-ss-ta *TOP*
5 4 # . wen.hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8246 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
John-un cip-ey ka-ki-lul wen.hay-ss-ta .
John-Top home-Dir go-Cmp-Acc want-Pst-Dec .
John wanted to go home .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD wanted) (S (VP (TO to) (VP (VB go) (ADVP (NN home)))))) (. .))

(S+wanted (NP+John (NNP John))
          (VP+wanted (VBD wanted)
                     (S+go (VP+go (TO to)
                                  (VP+go (VB go)
                                         (ADVP+home (NN home))))))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John wanted to go home .
1 2 # John wanted
2 -1 # wanted *TOP*
3 4 # to go
4 2 # go wanted
5 4 # home go
6 2 # . wanted


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un cip-ey ka-ki-lul wen.hay-ss-ta .
John-Top home-Dir go-Cmp-Acc want-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # cip-ey home-Dir
 2.1 2.1 # cip home
 2.2 2.2 # -ey -Dir
3 3 # ka-ki-lul go-Cmp-Acc
 3.1 3.1 # ka go
 3.2 3.2 # -ki -Cmp
 3.3 3.3 # -lul -Acc
4 4 # wen.hay-ss-ta want-Pst-Dec
 4.1 4.1 # wen.hay want
 4.2 4.2 # -ss -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top home-Dir go-Cmp-Acc want-Pst-Dec .
John wanted to go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 5 # home-Dir home
 2.1 5 # home home
 2.2 0 # -Dir NULL
3 4 # go-Cmp-Acc go
 3.1 4 # go go
 3.2 0 # -Cmp NULL
 3.3 0 # -Acc NULL
4 2 # want-Pst-Dec wanted
 4.1 2 # want wanted
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-un cip-ey ka-ki-lul wen.hay-ss-ta .
John-Top home-Dir go-Cmp-Acc want-Pst-Dec .
John wanted to go home .

1 4 # John-un wen.hay-ss-ta
2 3 # cip-ey ka-ki-lul
3 4 # ka-ki-lul wen.hay-ss-ta
4 -1 # wen.hay-ss-ta *TOP*
5 4 # . wen.hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8248 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=7
John-un cip-ey ka-ki-lul taytanhi wen.hay-ss-ta .
John-Top home-Dir go-Cmp-Acc very muchwant-Pst-Dec .
John very muchwanted to go home .

######## Q1: IGT is clean? Answer: y
#dj there is a consistent typo. we wouldn't mark this as "x"


############################## Q2: English parse tree 
(S (NP (NNP John)) (ADVP (RB very)) (VP (VBD muchwanted) (S (VP (TO to) (VP (VB go) (ADVP (NN home)))))) (. .))

(S+muchwanted (NP+John (NNP John))
              (ADVP+very (RB very))
              (VP+muchwanted (VBD muchwanted)
                             (S+go (VP+go (TO to)
                                          (VP+go (VB go)
                                                 (ADVP+home (NN home))))))
              (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John very muchwanted to go home .
1 3 # John muchwanted
2 3 # very muchwanted
3 -1 # muchwanted *TOP*
4 5 # to go
5 3 # go muchwanted
6 5 # home go
7 3 # . muchwanted


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un cip-ey ka-ki-lul taytanhi wen.hay-ss-ta .
John-Top home-Dir go-Cmp-Acc very muchwant-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # cip-ey home-Dir
 2.1 2.1 # cip home
 2.2 2.2 # -ey -Dir
3 3 # ka-ki-lul go-Cmp-Acc
 3.1 3.1 # ka go
 3.2 3.2 # -ki -Cmp
 3.3 3.3 # -lul -Acc
4 4 # taytanhi very
5 5 # wen.hay-ss-ta muchwant-Pst-Dec
 5.1 5.1 # wen.hay muchwant
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top home-Dir go-Cmp-Acc very muchwant-Pst-Dec .
John very muchwanted to go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 6 # home-Dir home
 2.1 6 # home home
 2.2 0 # -Dir NULL
3 5 # go-Cmp-Acc go
 3.1 5 # go go
 3.2 0 # -Cmp NULL
 3.3 0 # -Acc NULL
4 2 # very very
5 3 # muchwant-Pst-Dec muchwanted
 5.1 3 # muchwant muchwanted
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
John-un cip-ey ka-ki-lul taytanhi wen.hay-ss-ta .
John-Top home-Dir go-Cmp-Acc very muchwant-Pst-Dec .
John very muchwanted to go home .

1 5 # John-un wen.hay-ss-ta
2 3 # cip-ey ka-ki-lul
3 5 # ka-ki-lul wen.hay-ss-ta
4 5 # taytanhi wen.hay-ss-ta
5 -1 # wen.hay-ss-ta *TOP*
6 5 # . wen.hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8249 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
John-un Mary-ka cip-ey ka-ki palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp hope-Pst-Dec .
John hoped that Mary would go home .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (VP (VBD hoped) (SBAR (IN that) (S (NP (NNP Mary)) (VP (MD would) (VP (VB go) (ADVP (NN home))))))) (. .))

(S+hoped (NP+John (NNP John))
         (VP+hoped (VBD hoped)
                   (SBAR+go (IN that)
                            (S+go (NP+Mary (NNP Mary))
                                  (VP+go (MD would)
                                         (VP+go (VB go)
                                                (ADVP+home (NN home)))))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John hoped that Mary would go home .
1 2 # John hoped
2 -1 # hoped *TOP*
3 6 # that go
4 6 # Mary go
5 6 # would go
6 2 # go hoped
7 6 # home go
8 2 # . hoped


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un Mary-ka cip-ey ka-ki palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp hope-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # Mary-ka Mary-Nom
 2.1 2.1 # Mary Mary
 2.2 2.2 # -ka -Nom
3 3 # cip-ey home-Dir
 3.1 3.1 # cip home
 3.2 3.2 # -ey -Dir
4 4 # ka-ki go-Cmp
 4.1 4.1 # ka go
 4.2 4.2 # -ki -Cmp
5 5 # palay-ss-ta hope-Pst-Dec
 5.1 5.1 # palay hope
 5.2 5.2 # -ss -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top Mary-Nom home-Dir go-Cmp hope-Pst-Dec .
John hoped that Mary would go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 4 # Mary-Nom Mary
 2.1 4 # Mary Mary
 2.2 0 # -Nom NULL
3 7 # home-Dir home
 3.1 7 # home home
 3.2 0 # -Dir NULL
4 6 # go-Cmp go
 4.1 6 # go go
 4.2 0 # -Cmp NULL
5 2 # hope-Pst-Dec NULL x
 5.1 0 # hope NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
John-un Mary-ka cip-ey ka-ki palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp hope-Pst-Dec .
John hoped that Mary would go home .

1 5 # John-un palay-ss-ta
2 4 # Mary-ka ka-ki
3 4 # cip-ey ka-ki
4 5 # ka-ki palay-ss-ta
5 -1 # palay-ss-ta NULL x
6 5 # . palay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8251 Url_id=397 flag=0 cleaned=3 src_leng=7 trans_leng=9
John-un Mary-ka cip-ey ka-ki taytanhi palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp very.much hope-Pst-Dec .
John very much hoped Mary would go home .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (ADVP (RB very) (RB much)) (VP (VBD hoped) (SBAR (S (NP (NNP Mary)) (VP (MD would) (VP (VB go) (ADVP (NN home))))))) (. .))

(S+hoped (NP+John (NNP John))
         (ADVP+much (RB very)
                    (RB much))
         (VP+hoped (VBD hoped)
                   (SBAR+go (S+go (NP+Mary (NNP Mary))
                                  (VP+go (MD would)
                                         (VP+go (VB go)
                                                (ADVP+home (NN home)))))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John very much hoped Mary would go home .
1 4 # John hoped
2 3 # very much
3 4 # much hoped
4 -1 # hoped *TOP*
5 7 # Mary go
6 7 # would go
7 4 # go hoped
8 7 # home go
9 4 # . hoped


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un Mary-ka cip-ey ka-ki taytanhi palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp very.much hope-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # Mary-ka Mary-Nom
 2.1 2.1 # Mary Mary
 2.2 2.2 # -ka -Nom
3 3 # cip-ey home-Dir
 3.1 3.1 # cip home
 3.2 3.2 # -ey -Dir
4 4 # ka-ki go-Cmp
 4.1 4.1 # ka go
 4.2 4.2 # -ki -Cmp
5 5 # taytanhi very.much
6 6 # palay-ss-ta hope-Pst-Dec
 6.1 6.1 # palay hope
 6.2 6.2 # -ss -Pst
 6.3 6.3 # -ta -Dec
7 7 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top Mary-Nom home-Dir go-Cmp very.much hope-Pst-Dec .
John very much hoped Mary would go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 5 # Mary-Nom Mary
 2.1 5 # Mary Mary
 2.2 0 # -Nom NULL
3 8 # home-Dir home
 3.1 8 # home home
 3.2 0 # -Dir NULL
4 7 # go-Cmp go
 4.1 7 # go go
 4.2 0 # -Cmp NULL
5 2,3 # very.much very,much
6 2 # hope-Pst-Dec NULL x
 6.1 0 # hope NULL
 6.2 0 # -Pst NULL
 6.3 0 # -Dec NULL
7 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
John-un Mary-ka cip-ey ka-ki taytanhi palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp very.much hope-Pst-Dec .
John very much hoped Mary would go home .

1 6 # John-un palay-ss-ta
2 4 # Mary-ka ka-ki
3 4 # cip-ey ka-ki
4 6 # ka-ki palay-ss-ta
5 6 # taytanhi palay-ss-ta
6 -2 # palay-ss-ta NULL
7 6 # . palay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8252 Url_id=397 flag=0 cleaned=3 src_leng=7 trans_leng=9
John-un Mary-ka cip-ey ka-ki-lul taytanhi palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp-Acc very.much hope-Pst-Dec .
John very much hoped Mary would go home .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP John)) (ADVP (RB very) (RB much)) (VP (VBD hoped) (SBAR (S (NP (NNP Mary)) (VP (MD would) (VP (VB go) (ADVP (NN home))))))) (. .))

(S+hoped (NP+John (NNP John))
         (ADVP+much (RB very)
                    (RB much))
         (VP+hoped (VBD hoped)
                   (SBAR+go (S+go (NP+Mary (NNP Mary))
                                  (VP+go (MD would)
                                         (VP+go (VB go)
                                                (ADVP+home (NN home)))))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
John very much hoped Mary would go home .
1 4 # John hoped
2 3 # very much
3 4 # much hoped
4 -1 # hoped *TOP*
5 7 # Mary go
6 7 # would go
7 4 # go hoped
8 7 # home go
9 4 # . hoped


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
John-un Mary-ka cip-ey ka-ki-lul taytanhi palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp-Acc very.much hope-Pst-Dec .

1 1 # John-un John-Top
 1.1 1.1 # John John
 1.2 1.2 # -un -Top
2 2 # Mary-ka Mary-Nom
 2.1 2.1 # Mary Mary
 2.2 2.2 # -ka -Nom
3 3 # cip-ey home-Dir
 3.1 3.1 # cip home
 3.2 3.2 # -ey -Dir
4 4 # ka-ki-lul go-Cmp-Acc
 4.1 4.1 # ka go
 4.2 4.2 # -ki -Cmp
 4.3 4.3 # -lul -Acc
5 5 # taytanhi very.much
6 6 # palay-ss-ta hope-Pst-Dec
 6.1 6.1 # palay hope
 6.2 6.2 # -ss -Pst
 6.3 6.3 # -ta -Dec
7 7 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
John-Top Mary-Nom home-Dir go-Cmp-Acc very.much hope-Pst-Dec .
John very much hoped Mary would go home .

1 1 # John-Top John
 1.1 1 # John John
 1.2 0 # -Top NULL
2 5 # Mary-Nom Mary
 2.1 5 # Mary Mary
 2.2 0 # -Nom NULL
3 8 # home-Dir home
 3.1 8 # home home
 3.2 0 # -Dir NULL
4 7 # go-Cmp-Acc go
 4.1 7 # go go
 4.2 0 # -Cmp NULL
 4.3 0 # -Acc NULL
5 2,3 # very.much very,much
6 4 # hope-Pst-Dec NULL x
 6.1 0 # hope NULL
 6.2 0 # -Pst NULL
 6.3 0 # -Dec NULL
7 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
John-un Mary-ka cip-ey ka-ki-lul taytanhi palay-ss-ta .
John-Top Mary-Nom home-Dir go-Cmp-Acc very.much hope-Pst-Dec .
John very much hoped Mary would go home .

1 6 # John-un palay-ss-ta
2 4 # Mary-ka ka-ki-lul
3 4 # cip-ey ka-ki-lul
4 6 # ka-ki-lul palay-ss-ta
5 6 # taytanhi palay-ss-ta
6 -1 # palay-ss-ta NULL x
7 6 # . palay-ss-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8258 Url_id=397 flag=0 cleaned=0 src_leng=4 trans_leng=7
Nay-ka kulim-ul kuli-e-lul po-myen
I-Nom picture-Acc draw-Cmp-Acc try-if
If I try to draw a picture

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(FRAG (SBAR (IN If) (S (NP (PRP I)) (VP (VBP try) (S (VP (TO to) (VP (VB draw) (NP (DT a) (NN picture)))))))))

(FRAG+try (SBAR+try (IN If)
                    (S+try (NP+I (PRP I))
                           (VP+try (VBP try)
                                   (S+draw (VP+draw (TO to)
                                                    (VP+draw (VB draw)
                                                             (NP+picture (DT a)
                                                                         (NN picture)))))))))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
If I try to draw a picture
1 3 # If try
2 3 # I try
3 -1 # try *TOP*
4 5 # to draw
5 3 # draw try
6 7 # a picture
7 5 # picture draw


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Nay-ka kulim-ul kuli-e-lul po-myen
I-Nom picture-Acc draw-Cmp-Acc try-if

1 1 # Nay-ka I-Nom
 1.1 1.1 # Nay I
 1.2 1.2 # -ka -Nom
2 2 # kulim-ul picture-Acc
 2.1 2.1 # kulim picture
 2.2 2.2 # -ul -Acc
3 3 # kuli-e-lul draw-Cmp-Acc
 3.1 3.1 # kuli draw
 3.2 3.2 # -e -Cmp
 3.3 3.3 # -lul -Acc
4 4 # po-myen try-if
 4.1 4.1 # po try
 4.2 4.2 # -myen -if
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
I-Nom picture-Acc draw-Cmp-Acc try-if
If I try to draw a picture

1 2 # I-Nom I
 1.1 2 # I I
 1.2 0 # -Nom NULL
2 7 # picture-Acc picture
 2.1 7 # picture picture
 2.2 0 # -Acc NULL
3 5 # draw-Cmp-Acc draw
 3.1 5 # draw draw
 3.2 0 # -Cmp NULL
 3.3 0 # -Acc NULL
4 1,3 # try-if If,try
 4.1 3 # try try
 4.2 1 # -if If


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Nay-ka kulim-ul kuli-e-lul po-myen
I-Nom picture-Acc draw-Cmp-Acc try-if
If I try to draw a picture

1 4 # Nay-ka po-myen
2 3 # kulim-ul kuli-e-lul
3 4 # kuli-e-lul po-myen
4 -1 # po-myen *TOP*


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8259 Url_id=397 flag=0 cleaned=3 src_leng=7 trans_leng=7
Emeni-kkeyse John-eykey amwukes-to an ilk-key ha-si-ess-ta .
mother-HNom John-Dat anything-even not read-Adv do-Hon-Pst-Dec .
Mother made John not read anything .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mother)) (VP (VBD made) (S (NP (NNP John)) (RB not) (VP (VB read) (NP (NN anything))))) (. .))

(S+made (NP+Mother (NNP Mother))
        (VP+made (VBD made)
                 (S+read (NP+John (NNP John))
                         (RB not)
                         (VP+read (VB read)
                                  (NP+anything (NN anything)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mother made John not read anything .
1 2 # Mother made
2 -1 # made *TOP*
3 5 # John read
4 5 # not read
5 2 # read made
6 5 # anything read
7 2 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Emeni-kkeyse John-eykey amwukes-to an ilk-key ha-si-ess-ta .
mother-HNom John-Dat anything-even not read-Adv do-Hon-Pst-Dec .

1 1 # Emeni-kkeyse mother-HNom
 1.1 1.1 # Emeni mother
 1.2 1.2 # -kkeyse -HNom
2 2 # John-eykey John-Dat
 2.1 2.1 # John John
 2.2 2.2 # -eykey -Dat
3 3 # amwukes-to anything-even
 3.1 3.1 # amwukes anything
 3.2 3.2 # -to -even
4 4 # an not
5 5 # ilk-key read-Adv
 5.1 5.1 # ilk read
 5.2 5.2 # -key -Adv
6 6 # ha-si-ess-ta do-Hon-Pst-Dec
 6.1 6.1 # ha do
 6.2 6.2 # -si -Hon
 6.3 6.3 # -ess -Pst
 6.4 6.4 # -ta -Dec
7 7 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
mother-HNom John-Dat anything-even not read-Adv do-Hon-Pst-Dec .
Mother made John not read anything .

1 1 # mother-HNom Mother
 1.1 1 # mother Mother
 1.2 0 # -HNom NULL
2 3 # John-Dat John
 2.1 3 # John John
 2.2 0 # -Dat NULL
3 6 # anything-even anything
 3.1 6 # anything anything
 3.2 0 # -even NULL
4 4 # not not
5 5 # read-Adv read
 5.1 5 # read read
 5.2 0 # -Adv NULL
6 0 # do-Hon-Pst-Dec NULL
 6.1 0 # do NULL
 6.2 0 # -Hon NULL
 6.3 0 # -Pst NULL
 6.4 0 # -Dec NULL
7 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Emeni-kkeyse John-eykey amwukes-to an ilk-key ha-si-ess-ta .
mother-HNom John-Dat anything-even not read-Adv do-Hon-Pst-Dec .
Mother made John not read anything .

1 6 # Emeni-kkeyse ha-si-ess-ta
2 5 # John-eykey ilk-key
3 5 # amwukes-to ilk-key
4 5 # an ilk-key
5 6 # ilk-key ha-si-ess-ta
6 -2 # ha-si-ess-ta NULL
7 6 # . ha-si-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8260 Url_id=397 flag=0 cleaned=3 src_leng=7 trans_leng=7
Amwukes-to emeni-kkeyse John-eykey an ilk-key ha-si-ess-ta .
anything-even mother-HNom John-Dat not read-Adv do-Pst-Dec .
Mother made John not read anything .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mother)) (VP (VBD made) (S (NP (NNP John)) (RB not) (VP (VB read) (NP (NN anything))))) (. .))

(S+made (NP+Mother (NNP Mother))
        (VP+made (VBD made)
                 (S+read (NP+John (NNP John))
                         (RB not)
                         (VP+read (VB read)
                                  (NP+anything (NN anything)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mother made John not read anything .
1 2 # Mother made
2 -1 # made *TOP*
3 5 # John read
4 5 # not read
5 2 # read made
6 5 # anything read
7 2 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Amwukes-to emeni-kkeyse John-eykey an ilk-key ha-si-ess-ta .
anything-even mother-HNom John-Dat not read-Adv do-Pst-Dec .

1 1 # Amwukes-to anything-even
 1.1 1.1 # Amwukes anything
 1.2 1.2 # -to -even
2 2 # emeni-kkeyse mother-HNom
 2.1 2.1 # emeni mother
 2.2 2.2 # -kkeyse -HNom
3 3 # John-eykey John-Dat
 3.1 3.1 # John John
 3.2 3.2 # -eykey -Dat
4 4 # an not
5 5 # ilk-key read-Adv
 5.1 5.1 # ilk read
 5.2 5.2 # -key -Adv
6 6 # ha-si-ess-ta do-Pst-Dec
 6.1 0 # ha NULL
 6.2 0 # -si NULL
 6.3 0 # -ess NULL
 6.4 0 # -ta NULL
7 7 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
anything-even mother-HNom John-Dat not read-Adv do-Pst-Dec .
Mother made John not read anything .

1 6 # anything-even anything
 1.1 6 # anything anything
 1.2 0 # -even NULL
2 1 # mother-HNom Mother
 2.1 1 # mother Mother
 2.2 0 # -HNom NULL
3 3 # John-Dat John
 3.1 3 # John John
 3.2 0 # -Dat NULL
4 4 # not not
5 5 # read-Adv read
 5.1 5 # read read
 5.2 0 # -Adv NULL
6 0 # do-Pst-Dec NULL
 6.1 0 # do NULL
 6.2 0 # -Pst NULL
 6.3 0 # -Dec NULL
7 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Amwukes-to emeni-kkeyse John-eykey an ilk-key ha-si-ess-ta .
anything-even mother-HNom John-Dat not read-Adv do-Pst-Dec .
Mother made John not read anything .

1 5 # Amwukes-to ilk-key
2 6 # emeni-kkeyse ha-si-ess-ta
3 5 # John-eykey ilk-key
4 5 # an ilk-key
5 6 # ilk-key ha-si-ess-ta
6 -2 # ha-si-ess-ta NULL
7 6 # . ha-si-ess-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8261 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
Tom-un mikwuk-ul twu-pen-ul pangmwun.hay-ss-ta .
Tom-Top America-Acc two-time-Acc visit-Pst-Dec .
Tom visited America two times .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Tom)) (VP (VBD visited) (NP (NNP America)) (NP (CD two) (NNS times))) (. .))

(S+visited (NP+Tom (NNP Tom))
           (VP+visited (VBD visited)
                       (NP+America (NNP America))
                       (NP+times (CD two)
                                 (NNS times)))
           (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Tom visited America two times .
1 2 # Tom visited
2 -1 # visited *TOP*
3 2 # America visited
4 5 # two times
5 2 # times visited
6 2 # . visited


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Tom-un mikwuk-ul twu-pen-ul pangmwun.hay-ss-ta .
Tom-Top America-Acc two-time-Acc visit-Pst-Dec .

1 1 # Tom-un Tom-Top
 1.1 1.1 # Tom Tom
 1.2 1.2 # -un -Top
2 2 # mikwuk-ul America-Acc
 2.1 2.1 # mikwuk America
 2.2 2.2 # -ul -Acc
3 3 # twu-pen-ul two-time-Acc
 3.1 3.1 # twu two
 3.2 3.2 # -pen -time
 3.3 3.3 # -ul -Acc
4 4 # pangmwun.hay-ss-ta visit-Pst-Dec
 4.1 4.1 # pangmwun.hay visit
 4.2 4.2 # -ss -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Tom-Top America-Acc two-time-Acc visit-Pst-Dec .
Tom visited America two times .

1 1 # Tom-Top Tom
 1.1 1 # Tom Tom
 1.2 0 # -Top NULL
2 3 # America-Acc America
 2.1 3 # America America
 2.2 0 # -Acc NULL
3 4,5 # two-time-Acc two,times
 3.1 4 # two two
 3.2 5 # -time times
 3.3 0 # -Acc NULL
4 2 # visit-Pst-Dec visited
 4.1 2 # visit visited
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Tom-un mikwuk-ul twu-pen-ul pangmwun.hay-ss-ta .
Tom-Top America-Acc two-time-Acc visit-Pst-Dec .
Tom visited America two times .

1 4 # Tom-un pangmwun.hay-ss-ta
2 4 # mikwuk-ul pangmwun.hay-ss-ta
3 4 # twu-pen-ul pangmwun.hay-ss-ta
4 -1 # pangmwun.hay-ss-ta *TOP*
5 4 # . pangmwun.hay-ss-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8262 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=8
Mwun-i han-sikan-tongan-i yel-ie iss-ta .
door-Nom one-hour-during-Nom open-Pass be-Dec .
The door remained open for an hour .

######## Q1: IGT is clean? Answer: x
#dj "remain" vs "be"


############################## Q2: English parse tree 
(S (NP (DT The) (NN door)) (VP (VBD remained) (ADJP (JJ open) (PP (IN for) (NP (DT an) (NN hour))))) (. .))

(S+remained (NP+door (DT The)
                     (NN door))
            (VP+remained (VBD remained)
                         (ADJP+open (JJ open)
                                    (PP+for (IN for)
                                            (NP+hour (DT an)
                                                     (NN hour)))))
            (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The door remained open for an hour .
1 2 # The door
2 3 # door remained
3 -1 # remained *TOP*
4 3 # open remained
5 4 # for open
6 7 # an hour
7 5 # hour for
8 3 # . remained


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Mwun-i han-sikan-tongan-i yel-ie iss-ta .
door-Nom one-hour-during-Nom open-Pass be-Dec .

1 1 # Mwun-i door-Nom
 1.1 1.1 # Mwun door
 1.2 1.2 # -i -Nom
2 2 # han-sikan-tongan-i one-hour-during-Nom
 2.1 2.1 # han one
 2.2 2.2 # -sikan -hour
 2.3 2.3 # -tongan -during
 2.4 2.4 # -i -Nom
3 3 # yel-ie open-Pass
 3.1 3.1 # yel open
 3.2 3.2 # -ie -Pass
4 4 # iss-ta be-Dec
 4.1 4.1 # iss be
 4.2 4.2 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
door-Nom one-hour-during-Nom open-Pass be-Dec .
The door remained open for an hour .

1 2 # door-Nom door
 1.1 2 # door door
 1.2 0 # -Nom NULL
2 7 # one-hour-during-Nom hour
 2.1 0 # one NULL
 2.2 7 # -hour hour
 2.3 0 # -during NULL
 2.4 0 # -Nom NULL
3 4 # open-Pass open
 3.1 4 # open open
 3.2 0 # -Pass NULL
4 0 # be-Dec NULL
 4.1 0 # be NULL
 4.2 0 # -Dec NULL
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Mwun-i han-sikan-tongan-i yel-ie iss-ta .
door-Nom one-hour-during-Nom open-Pass be-Dec .
The door remained open for an hour .

1 4 # Mwun-i iss-ta
2 3 # han-sikan-tongan-i yel-ie
3 4 # yel-ie iss-ta
4 -2 # iss-ta NULL
5 4 # . iss-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8263 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=6
Swuni-ka han sikan-tongan-ul talli-ess-ta .
Swuni-Nom one hour-for-Acc run-Pst-Dec .
Swuni ran for an hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Swuni)) (VP (VBD ran) (PP (IN for) (NP (DT an) (NN hour)))) (. .))

(S+ran (NP+Swuni (NNP Swuni))
       (VP+ran (VBD ran)
               (PP+for (IN for)
                       (NP+hour (DT an)
                                (NN hour))))
       (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Swuni ran for an hour .
1 2 # Swuni ran
2 -1 # ran *TOP*
3 2 # for ran
4 5 # an hour
5 3 # hour for
6 2 # . ran


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Swuni-ka han sikan-tongan-ul talli-ess-ta .
Swuni-Nom one hour-for-Acc run-Pst-Dec .

1 1 # Swuni-ka Swuni-Nom
 1.1 1.1 # Swuni Swuni
 1.2 1.2 # -ka -Nom
2 2 # han one
3 3 # sikan-tongan-ul hour-for-Acc
 3.1 3.1 # sikan hour
 3.2 3.2 # -tongan -for
 3.3 3.3 # -ul -Acc
4 4 # talli-ess-ta run-Pst-Dec
 4.1 4.1 # talli run
 4.2 4.2 # -ess -Pst
 4.3 4.3 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Swuni-Nom one hour-for-Acc run-Pst-Dec .
Swuni ran for an hour .

1 1 # Swuni-Nom Swuni
 1.1 1 # Swuni Swuni
 1.2 0 # -Nom NULL
2 0 # one NULL
3 3,5 # hour-for-Acc for,hour
 3.1 5 # hour hour
 3.2 3 # -for for
 3.3 0 # -Acc NULL
4 2 # run-Pst-Dec ran
 4.1 2 # run ran
 4.2 0 # -Pst NULL
 4.3 0 # -Dec NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Swuni-ka han sikan-tongan-ul talli-ess-ta .
Swuni-Nom one hour-for-Acc run-Pst-Dec .
Swuni ran for an hour .

1 4 # Swuni-ka talli-ess-ta
2 3 # han talli-ess-ta x
3 4 # sikan-tongan-ul talli-ess-ta
4 -1 # talli-ess-ta *TOP*
5 4 # . talli-ess-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8267 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=8
Chayk-i han sikan-tongan-ul ilk-hi-ess-ta .
book-Nom one hour-for-Acc read-Pass-Pst-Dec .
The book was read for one hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN book)) (VP (VBD was) (VP (VBN read) (PP (IN for) (NP (CD one) (NN hour))))) (. .))

(S+read (NP+book (DT The)
                 (NN book))
        (VP+read (VBD was)
                 (VP+read (VBN read)
                          (PP+for (IN for)
                                  (NP+hour (CD one)
                                           (NN hour)))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The book was read for one hour .
1 2 # The book
2 4 # book read
3 4 # was read
4 -1 # read *TOP*
5 4 # for read
6 7 # one hour
7 5 # hour for
8 4 # . read


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chayk-i han sikan-tongan-ul ilk-hi-ess-ta .
book-Nom one hour-for-Acc read-Pass-Pst-Dec .

1 1 # Chayk-i book-Nom
 1.1 1.1 # Chayk book
 1.2 1.2 # -i -Nom
2 2 # han one
3 3 # sikan-tongan-ul hour-for-Acc
 3.1 3.1 # sikan hour
 3.2 3.2 # -tongan -for
 3.3 3.3 # -ul -Acc
4 4 # ilk-hi-ess-ta read-Pass-Pst-Dec
 4.1 4.1 # ilk read
 4.2 4.2 # -hi -Pass
 4.3 4.3 # -ess -Pst
 4.4 4.4 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
book-Nom one hour-for-Acc read-Pass-Pst-Dec .
The book was read for one hour .

1 2 # book-Nom book
 1.1 2 # book book
 1.2 0 # -Nom NULL
2 6 # one one
3 5,7 # hour-for-Acc for,hour
 3.1 7 # hour hour
 3.2 5 # -for for
 3.3 0 # -Acc NULL
4 4 # read-Pass-Pst-Dec read
 4.1 4 # read read
 4.2 0 # -Pass NULL
 4.3 0 # -Pst NULL
 4.4 0 # -Dec NULL
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chayk-i han sikan-tongan-ul ilk-hi-ess-ta .
book-Nom one hour-for-Acc read-Pass-Pst-Dec .
The book was read for one hour .

1 4 # Chayk-i ilk-hi-ess-ta
2 3 # han sikan-tongan-ul
3 4 # sikan-tongan-ul ilk-hi-ess-ta
4 -1 # ilk-hi-ess-ta *TOP*
5 4 # . ilk-hi-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8268 Url_id=397 flag=0 cleaned=3 src_leng=5 trans_leng=8
Chayk-i han sikan-tongan-i ilk-hi-ess-ta .
book-Nom one hour-for-Nom read-Pass-Pst-Dec .
The book was read for one hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN book)) (VP (VBD was) (VP (VBN read) (PP (IN for) (NP (CD one) (NN hour))))) (. .))

(S+read (NP+book (DT The)
                 (NN book))
        (VP+read (VBD was)
                 (VP+read (VBN read)
                          (PP+for (IN for)
                                  (NP+hour (CD one)
                                           (NN hour)))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The book was read for one hour .
1 2 # The book
2 4 # book read
3 4 # was read
4 -1 # read *TOP*
5 4 # for read
6 7 # one hour
7 5 # hour for
8 4 # . read


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chayk-i han sikan-tongan-i ilk-hi-ess-ta .
book-Nom one hour-for-Nom read-Pass-Pst-Dec .

1 1 # Chayk-i book-Nom
 1.1 1.1 # Chayk book
 1.2 1.2 # -i -Nom
2 2 # han one
3 3 # sikan-tongan-i hour-for-Nom
 3.1 3.1 # sikan hour
 3.2 3.2 # -tongan -for
 3.3 3.3 # -i -Nom
4 4 # ilk-hi-ess-ta read-Pass-Pst-Dec
 4.1 4.1 # ilk read
 4.2 4.2 # -hi -Pass
 4.3 4.3 # -ess -Pst
 4.4 4.4 # -ta -Dec
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
book-Nom one hour-for-Nom read-Pass-Pst-Dec .
The book was read for one hour .

1 2 # book-Nom book
 1.1 2 # book book
 1.2 0 # -Nom NULL
2 6 # one one
3 5,7 # hour-for-Nom for,hour
 3.1 7 # hour hour
 3.2 5 # -for for
 3.3 0 # -Nom NULL
4 4 # read-Pass-Pst-Dec read
 4.1 4 # read read
 4.2 0 # -Pass NULL
 4.3 0 # -Pst NULL
 4.4 0 # -Dec NULL
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chayk-i han sikan-tongan-i ilk-hi-ess-ta .
book-Nom one hour-for-Nom read-Pass-Pst-Dec .
The book was read for one hour .

1 4 # Chayk-i ilk-hi-ess-ta
2 3 # han sikan-tongan-i
3 4 # sikan-tongan-i ilk-hi-ess-ta
4 -1 # ilk-hi-ess-ta *TOP*
5 4 # . ilk-hi-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8269 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Chayk-i han sikan-tongan-ul ilk-e ci-ess-ta .
book-Nom one hour-for-Acc read-Cmp PasAux-Pst-Dec .
The book was read for one hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN book)) (VP (VBD was) (VP (VBN read) (PP (IN for) (NP (CD one) (NN hour))))) (. .))

(S+read (NP+book (DT The)
                 (NN book))
        (VP+read (VBD was)
                 (VP+read (VBN read)
                          (PP+for (IN for)
                                  (NP+hour (CD one)
                                           (NN hour)))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The book was read for one hour .
1 2 # The book
2 4 # book read
3 4 # was read
4 -1 # read *TOP*
5 4 # for read
6 7 # one hour
7 5 # hour for
8 4 # . read


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chayk-i han sikan-tongan-ul ilk-e ci-ess-ta .
book-Nom one hour-for-Acc read-Cmp PasAux-Pst-Dec .

1 1 # Chayk-i book-Nom
 1.1 1.1 # Chayk book
 1.2 1.2 # -i -Nom
2 2 # han one
3 3 # sikan-tongan-ul hour-for-Acc
 3.1 3.1 # sikan hour
 3.2 3.2 # -tongan -for
 3.3 3.3 # -ul -Acc
4 4 # ilk-e read-Cmp
 4.1 4.1 # ilk read
 4.2 4.2 # -e -Cmp
5 5 # ci-ess-ta PasAux-Pst-Dec
 5.1 5.1 # ci PasAux
 5.2 5.2 # -ess -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
book-Nom one hour-for-Acc read-Cmp PasAux-Pst-Dec .
The book was read for one hour .

1 2 # book-Nom book
 1.1 2 # book book
 1.2 0 # -Nom NULL
2 6 # one one
3 5,7 # hour-for-Acc for,hour
 3.1 7 # hour hour
 3.2 5 # -for for
 3.3 0 # -Acc NULL
4 4 # read-Cmp read
 4.1 4 # read read
 4.2 0 # -Cmp NULL
5 0 # PasAux-Pst-Dec NULL
 5.1 0 # PasAux NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chayk-i han sikan-tongan-ul ilk-e ci-ess-ta .
book-Nom one hour-for-Acc read-Cmp PasAux-Pst-Dec .
The book was read for one hour .

1 4 # Chayk-i ilk-e
2 3 # han sikan-tongan-ul
3 4 # sikan-tongan-ul ilk-e
4 -1 # ilk-e *TOP*
5 4 # ci-ess-ta ilk-e
6 4 # . ilk-e


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8270 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Chayk-i han sikan-tongan-i ilk-e ci-ess-ta .
book-Nom one hour-for-Nom read-Cmp PasAux-Pst-Dec .
The book was read for one hour .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN book)) (VP (VBD was) (VP (VBN read) (PP (IN for) (NP (CD one) (NN hour))))) (. .))

(S+read (NP+book (DT The)
                 (NN book))
        (VP+read (VBD was)
                 (VP+read (VBN read)
                          (PP+for (IN for)
                                  (NP+hour (CD one)
                                           (NN hour)))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The book was read for one hour .
1 2 # The book
2 4 # book read
3 4 # was read
4 -1 # read *TOP*
5 4 # for read
6 7 # one hour
7 5 # hour for
8 4 # . read


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chayk-i han sikan-tongan-i ilk-e ci-ess-ta .
book-Nom one hour-for-Nom read-Cmp PasAux-Pst-Dec .

1 1 # Chayk-i book-Nom
 1.1 1.1 # Chayk book
 1.2 1.2 # -i -Nom
2 2 # han one
3 3 # sikan-tongan-i hour-for-Nom
 3.1 3.1 # sikan hour
 3.2 3.2 # -tongan -for
 3.3 3.3 # -i -Nom
4 4 # ilk-e read-Cmp
 4.1 4.1 # ilk read
 4.2 4.2 # -e -Cmp
5 5 # ci-ess-ta PasAux-Pst-Dec
 5.1 5.1 # ci PasAux
 5.2 5.2 # -ess -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
book-Nom one hour-for-Nom read-Cmp PasAux-Pst-Dec .
The book was read for one hour .

1 2 # book-Nom book
 1.1 2 # book book
 1.2 0 # -Nom NULL
2 6 # one one
3 5,7 # hour-for-Nom for,hour
 3.1 7 # hour hour
 3.2 5 # -for for
 3.3 0 # -Nom NULL
4 4 # read-Cmp read
 4.1 4 # read read
 4.2 0 # -Cmp NULL
5 0 # PasAux-Pst-Dec NULL
 5.1 0 # PasAux NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chayk-i han sikan-tongan-i ilk-e ci-ess-ta .
book-Nom one hour-for-Nom read-Cmp PasAux-Pst-Dec .
The book was read for one hour .

1 4 # Chayk-i ilk-e
2 3 # han sikan-tongan-i
3 4 # sikan-tongan-i ilk-e
4 -1 # ilk-e *TOP*
5 4 # ci-ess-ta ilk-e
6 4 # . ilk-e


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8271 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=7
Chelswu-ka chayk-ul sey sikan-tongan-ul ilk-ess-ta .
Chelswu-Nom book-Acc three hour-during-Acc read-Pst-Dec .
Chelswu read books for three hours .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNS Chelswu)) (VP (VBP read) (NP (NNS books)) (PP (IN for) (NP (CD three) (NNS hours)))) (. .))

(S+read (NP+Chelswu (NNS Chelswu))
        (VP+read (VBP read)
                 (NP+books (NNS books))
                 (PP+for (IN for)
                         (NP+hours (CD three)
                                   (NNS hours))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu read books for three hours .
1 2 # Chelswu read
2 -1 # read *TOP*
3 2 # books read
4 2 # for read
5 6 # three hours
6 4 # hours for
7 2 # . read


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-ka chayk-ul sey sikan-tongan-ul ilk-ess-ta .
Chelswu-Nom book-Acc three hour-during-Acc read-Pst-Dec .

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # chayk-ul book-Acc
 2.1 2.1 # chayk book
 2.2 2.2 # -ul -Acc
3 3 # sey three
4 4 # sikan-tongan-ul hour-during-Acc
 4.1 4.1 # sikan hour
 4.2 4.2 # -tongan -during
 4.3 4.3 # -ul -Acc
5 5 # ilk-ess-ta read-Pst-Dec
 5.1 5.1 # ilk read
 5.2 5.2 # -ess -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom book-Acc three hour-during-Acc read-Pst-Dec .
Chelswu read books for three hours .

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 3 # book-Acc books
 2.1 3 # book books
 2.2 0 # -Acc NULL
3 5 # three three
4 6 # hour-during-Acc hours
 4.1 6 # hour hours
 4.2 0 # -during NULL
 4.3 0 # -Acc NULL
5 2 # read-Pst-Dec read
 5.1 2 # read read
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chelswu-ka chayk-ul sey sikan-tongan-ul ilk-ess-ta .
Chelswu-Nom book-Acc three hour-during-Acc read-Pst-Dec .
Chelswu read books for three hours .

1 5 # Chelswu-ka ilk-ess-ta
2 5 # chayk-ul ilk-ess-ta
3 4 # sey sikan-tongan-ul
4 5 # sikan-tongan-ul ilk-ess-ta
5 -1 # ilk-ess-ta *TOP*
6 5 # . ilk-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8274 Url_id=397 flag=0 cleaned=3 src_leng=4 trans_leng=8
Haksayng-tul-i myech-sikan-i kipp-ess-ta .
Student-Plur-Nom several-hour-Nom be.happy-Pst-Dec .
The students were happy for several hours .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NNS students)) (VP (VBD were) (ADJP (JJ happy) (PP (IN for) (NP (JJ several) (NNS hours))))) (. .))

(S+happy (NP+students (DT The)
                      (NNS students))
         (VP+happy (VBD were)
                   (ADJP-PRD+happy (JJ happy)
                                   (PP+for (IN for)
                                           (NP+hours (JJ several)
                                                     (NNS hours)))))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The students were happy for several hours .
1 2 # The students
2 4 # students happy
3 4 # were happy
4 -1 # happy *TOP*
5 4 # for happy
6 7 # several hours
7 5 # hours for
8 4 # . happy


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Haksayng-tul-i myech-sikan-i kipp-ess-ta .
Student-Plur-Nom several-hour-Nom be.happy-Pst-Dec .

1 1 # Haksayng-tul-i Student-Plur-Nom
 1.1 1.1 # Haksayng Student
 1.2 1.2 # -tul -Plur
 1.3 1.3 # -i -Nom
2 2 # myech-sikan-i several-hour-Nom
 2.1 2.1 # myech several
 2.2 2.2 # -sikan -hour
 2.3 2.3 # -i -Nom
3 3 # kipp-ess-ta be.happy-Pst-Dec
 3.1 3.1 # kipp be.happy
 3.2 3.2 # -ess -Pst
 3.3 3.3 # -ta -Dec
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Student-Plur-Nom several-hour-Nom be.happy-Pst-Dec .
The students were happy for several hours .

1 2 # Student-Plur-Nom students
 1.1 2 # Student students
 1.2 0 # -Plur NULL
 1.3 0 # -Nom NULL
2 6,7 # several-hour-Nom several,hours
 2.1 6 # several several
 2.2 7 # -hour hours
 2.3 0 # -Nom NULL
3 3,4 # be.happy-Pst-Dec were,happy
 3.1 3,4 # be.happy were,happy
 3.2 0 # -Pst NULL
 3.3 0 # -Dec NULL
4 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Haksayng-tul-i myech-sikan-i kipp-ess-ta .
Student-Plur-Nom several-hour-Nom be.happy-Pst-Dec .
The students were happy for several hours .

1 3 # Haksayng-tul-i kipp-ess-ta
2 3 # myech-sikan-i kipp-ess-ta
3 -1 # kipp-ess-ta *TOP*
4 3 # . kipp-ess-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8275 Url_id=397 flag=0 cleaned=3 src_leng=6 trans_leng=8
Chayk-i han sikan-tongan-ul ilk-e ci-ess-ta .
book-Nom one hour-during-Acc read-Cmp PasAux-Pst-Dec .
The book was read for an hour .

######## Q1: IGT is clean? Answer: n
#dj duplicate


############################## Q2: English parse tree 
(S (NP (DT The) (NN book)) (VP (VBD was) (VP (VBN read) (PP (IN for) (NP (DT an) (NN hour))))) (. .))

(S+read (NP+book (DT The)
                 (NN book))
        (VP+read (VBD was)
                 (VP+read (VBN read)
                          (PP+for (IN for)
                                  (NP+hour (DT an)
                                           (NN hour)))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The book was read for an hour .
1 2 # The book
2 4 # book read
3 4 # was read
4 -1 # read *TOP*
5 4 # for read
6 7 # an hour
7 5 # hour for
8 4 # . read


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Chayk-i han sikan-tongan-ul ilk-e ci-ess-ta .
book-Nom one hour-during-Acc read-Cmp PasAux-Pst-Dec .

1 1 # Chayk-i book-Nom
 1.1 1.1 # Chayk book
 1.2 1.2 # -i -Nom
2 2 # han one
3 3 # sikan-tongan-ul hour-during-Acc
 3.1 3.1 # sikan hour
 3.2 3.2 # -tongan -during
 3.3 3.3 # -ul -Acc
4 4 # ilk-e read-Cmp
 4.1 4.1 # ilk read
 4.2 4.2 # -e -Cmp
5 5 # ci-ess-ta PasAux-Pst-Dec
 5.1 5.1 # ci PasAux
 5.2 5.2 # -ess -Pst
 5.3 5.3 # -ta -Dec
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
book-Nom one hour-during-Acc read-Cmp PasAux-Pst-Dec .
The book was read for an hour .

1 2 # book-Nom book
 1.1 2 # book book
 1.2 0 # -Nom NULL
2 0 # one NULL
3 7 # hour-during-Acc hour
 3.1 7 # hour hour
 3.2 0 # -during NULL
 3.3 0 # -Acc NULL
4 4 # read-Cmp read
 4.1 4 # read read
 4.2 0 # -Cmp NULL
5 0 # PasAux-Pst-Dec NULL
 5.1 0 # PasAux NULL
 5.2 0 # -Pst NULL
 5.3 0 # -Dec NULL
6 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Chayk-i han sikan-tongan-ul ilk-e ci-ess-ta .
book-Nom one hour-during-Acc read-Cmp PasAux-Pst-Dec .
The book was read for an hour .

1 4 # Chayk-i ilk-e
2 4 # han ilk-e
3 4 # sikan-tongan-ul ilk-e
4 -1 # ilk-e *TOP*
5 4 # ci-ess-ta ilk-e
6 4 # . ilk-e


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8277 Url_id=397 flag=0 cleaned=4 src_leng=7 trans_leng=14
Pak-ssi-nun ai-eykey namwu-ey twu-son-ulo olu-key hay-ss-ta .
Park-Mr.-Top child-Dat tree-Dir two-hand-Inst go.up-Adv do-Pst-Dec .
Mr . Park made the child go up the tree with both hands .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NNP Mr) (. .) (NNP Park)) (VP (VBD made) (S (NP (DT the) (NN child)) (VP (VB go) (PRT (RP up)) (NP (DT the) (NN tree)) (PP (IN with) (NP (DT both) (NNS hands)))))) (. .))

(S+made (NP+Park (NNP Mr)
                 (. .)
                 (NNP Park))
        (VP+made (VBD made)
                 (S+go (NP+child (DT the)
                                 (NN child))
                       (VP+go (VB go)
                              (PRT+up (RP up))
                              (NP+tree (DT the)
                                       (NN tree))
                              (PP+with (IN with)
                                       (NP+hands (DT both)
                                                 (NNS hands))))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Mr . Park made the child go up the tree with both hands .
1 3 # Mr Park
2 3 # . Park
3 4 # Park made
4 -1 # made *TOP*
5 6 # the child
6 7 # child go
7 4 # go made
8 7 # up go
9 10 # the tree
10 7 # tree go
11 7 # with go
12 13 # both hands
13 11 # hands with
14 4 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Pak-ssi-nun ai-eykey namwu-ey twu-son-ulo olu-key hay-ss-ta .
Park-Mr.-Top child-Dat tree-Dir two-hand-Inst go.up-Adv do-Pst-Dec .

1 1 # Pak-ssi-nun Park-Mr.-Top
 1.1 1.1 # Pak Park
 1.2 1.2 # -ssi -Mr.
 1.3 1.3 # -nun -Top
2 2 # ai-eykey child-Dat
 2.1 2.1 # ai child
 2.2 2.2 # -eykey -Dat
3 3 # namwu-ey tree-Dir
 3.1 3.1 # namwu tree
 3.2 3.2 # -ey -Dir
4 4 # twu-son-ulo two-hand-Inst
 4.1 4.1 # twu two
 4.2 4.2 # -son -hand
 4.3 4.3 # -ulo -Inst
5 5 # olu-key go.up-Adv
 5.1 5.1 # olu go.up
 5.2 5.2 # -key -Adv
6 6 # hay-ss-ta do-Pst-Dec
 6.1 6.1 # hay do
 6.2 6.2 # -ss -Pst
 6.3 6.3 # -ta -Dec
7 7 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Park-Mr.-Top child-Dat tree-Dir two-hand-Inst go.up-Adv do-Pst-Dec .
Mr . Park made the child go up the tree with both hands .

1 3 # Park-Mr.-Top Park
 1.1 3 # Park Park
 1.2 0 # -Mr. NULL
 1.3 0 # -Top NULL
2 6 # child-Dat child
 2.1 6 # child child
 2.2 0 # -Dat NULL
3 10 # tree-Dir tree
 3.1 10 # tree tree
 3.2 0 # -Dir NULL
4 13 # two-hand-Inst hands
 4.1 0 # two NULL
 4.2 13 # -hand hands
 4.3 0 # -Inst NULL
5 7,8 # go.up-Adv go,up
 5.1 7,8 # go.up go,up
 5.2 0 # -Adv NULL
6 0 # do-Pst-Dec NULL
 6.1 0 # do NULL
 6.2 0 # -Pst NULL
 6.3 0 # -Dec NULL
7 2 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Pak-ssi-nun ai-eykey namwu-ey twu-son-ulo olu-key hay-ss-ta .
Park-Mr.-Top child-Dat tree-Dir two-hand-Inst go.up-Adv do-Pst-Dec .
Mr . Park made the child go up the tree with both hands .

1 6 # Pak-ssi-nun hay-ss-ta
2 5 # ai-eykey olu-key
3 5 # namwu-ey olu-key
4 5 # twu-son-ulo olu-key
5 6 # olu-key hay-ss-ta
6 -2 # hay-ss-ta NULL
7 1 # . Pak-ssi-nun


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8278 Url_id=397 flag=0 cleaned=3 src_leng=8 trans_leng=9
Ecey na-nun Inho-lul onul hankwuk-ulo ttena-key hay-ss-ta .
yesterday I-Top Inho-Acc today Korea-to leave-Adv do-Pst-Dec .
Yesterday I made Inho leave for Korea today .

######## Q1: IGT is clean? Answer: x
#dj "make" vs "do"


############################## Q2: English parse tree 
(S (NP (NN Yesterday)) (NP (PRP I)) (VP (VBD made) (S (NP (NNP Inho)) (VP (VB leave) (PP (IN for) (NP (NNP Korea) (NNP today)))))) (. .))

(S+made (NP+Yesterday (NN Yesterday))
        (NP+I (PRP I))
        (VP+made (VBD made)
                 (S+leave (NP+Inho (NNP Inho))
                          (VP+leave (VB leave)
                                    (PP+for (IN for)
                                            (NP+today (NNP Korea)
                                                      (NNP today))))))
        (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
Yesterday I made Inho leave for Korea today .
1 3 # Yesterday made
2 3 # I made
3 -1 # made *TOP*
4 5 # Inho leave
5 3 # leave made
6 5 # for leave
7 8 # Korea today
8 6 # today for
9 3 # . made


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Ecey na-nun Inho-lul onul hankwuk-ulo ttena-key hay-ss-ta .
yesterday I-Top Inho-Acc today Korea-to leave-Adv do-Pst-Dec .

1 1 # Ecey yesterday
2 2 # na-nun I-Top
 2.1 2.1 # na I
 2.2 2.2 # -nun -Top
3 3 # Inho-lul Inho-Acc
 3.1 3.1 # Inho Inho
 3.2 3.2 # -lul -Acc
4 4 # onul today
5 5 # hankwuk-ulo Korea-to
 5.1 5.1 # hankwuk Korea
 5.2 5.2 # -ulo -to
6 6 # ttena-key leave-Adv
 6.1 6.1 # ttena leave
 6.2 6.2 # -key -Adv
7 7 # hay-ss-ta do-Pst-Dec
 7.1 7.1 # hay do
 7.2 7.2 # -ss -Pst
 7.3 7.3 # -ta -Dec
8 8 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
yesterday I-Top Inho-Acc today Korea-to leave-Adv do-Pst-Dec .
Yesterday I made Inho leave for Korea today .

1 1 # yesterday Yesterday
2 2 # I-Top I
 2.1 2 # I I
 2.2 0 # -Top NULL
3 4 # Inho-Acc Inho
 3.1 4 # Inho Inho
 3.2 0 # -Acc NULL
4 8 # today today
5 7 # Korea-to Korea
 5.1 7 # Korea Korea
 5.2 0 # -to NULL
6 5 # leave-Adv leave
 6.1 5 # leave leave
 6.2 0 # -Adv NULL
7 0 # do-Pst-Dec NULL
 7.1 0 # do NULL
 7.2 0 # -Pst NULL
 7.3 0 # -Dec NULL
8 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Ecey na-nun Inho-lul onul hankwuk-ulo ttena-key hay-ss-ta .
yesterday I-Top Inho-Acc today Korea-to leave-Adv do-Pst-Dec .
Yesterday I made Inho leave for Korea today .

1 7 # Ecey hay-ss-ta
2 7 # na-nun hay-ss-ta
3 6 # Inho-lul ttena-key
4 6 # onul ttena-key
5 4 # hankwuk-ulo onul
6 7 # ttena-key hay-ss-ta
7 -2 # hay-ss-ta NULL
8 7 # . hay-ss-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8460 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=6
ku namca-ka salyengkwan i-ta .
that man-Nom commander Cop-Decl .
That man is the commander .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT That) (NN man)) (VP (VBZ is) (NP (DT the) (NN commander))) (. .))

(S+commander (NP+man (DT That)
                     (NN man))
             (VP+commander (VBZ is)
                           (NP-PRD+commander (DT the)
                                             (NN commander)))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
That man is the commander .
1 2 # That man
2 5 # man commander
3 5 # is commander
4 5 # the commander
5 -1 # commander *TOP*
6 5 # . commander


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
ku namca-ka salyengkwan i-ta .
that man-Nom commander Cop-Decl .

1 1 # ku that
2 2 # namca-ka man-Nom
 2.1 2.1 # namca man
 2.2 2.2 # -ka -Nom
3 3 # salyengkwan commander
4 4 # i-ta Cop-Decl
 4.1 4.1 # i Cop
 4.2 4.2 # -ta -Decl
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
that man-Nom commander Cop-Decl .
That man is the commander .

1 1 # that That
2 2 # man-Nom man
 2.1 2 # man man
 2.2 0 # -Nom NULL
3 5 # commander commander
4 3 # Cop-Decl NULL x
 4.1 0 # Cop NULL
 4.2 0 # -Decl NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
ku namca-ka salyengkwan i-ta .
that man-Nom commander Cop-Decl .
That man is the commander .

1 2 # ku namca-ka
2 3 # namca-ka salyengkwan
3 -1 # salyengkwan *TOP*
4 3 # i-ta salyengkwan
5 3 # . salyengkwan


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8461 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=6
ce sangca-nun acwu kuta .
that box-Top very big .
That box is very big .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT That) (NN box)) (VP (VBZ is) (ADJP (RB very) (JJ big))) (. .))

(S+big (NP+box (DT That)
               (NN box))
       (VP+big (VBZ is)
               (ADJP-PRD+big (RB very)
                             (JJ big)))
       (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
That box is very big .
1 2 # That box
2 5 # box big
3 5 # is big
4 5 # very big
5 -1 # big *TOP*
6 5 # . big


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
ce sangca-nun acwu kuta .
that box-Top very big .

1 1 # ce that
2 2 # sangca-nun box-Top
 2.1 2.1 # sangca box
 2.2 2.2 # -nun -Top
3 3 # acwu very
4 4 # kuta big
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
that box-Top very big .
That box is very big .

1 1 # that That
2 2 # box-Top box
 2.1 2 # box box
 2.2 0 # -Top NULL
3 4 # very very
4 5 # big big
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
ce sangca-nun acwu kuta .
that box-Top very big .
That box is very big .

1 2 # ce sangca-nun
2 4 # sangca-nun kuta
3 4 # acwu kuta
4 -1 # kuta *TOP*
5 4 # . kuta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8462 Url_id=572 flag=0 cleaned=3 src_leng=3 trans_leng=5
kkoch-i nolah-ta .
flower-Nom yellow-Decl .
The flower is yellow .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN flower)) (VP (VBZ is) (ADJP (JJ yellow))) (. .))

(S+yellow (NP+flower (DT The)
                     (NN flower))
          (VP+yellow (VBZ is)
                     (ADJP-PRD+yellow (JJ yellow)))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The flower is yellow .
1 2 # The flower
2 4 # flower yellow
3 4 # is yellow
4 -1 # yellow *TOP*
5 4 # . yellow


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
kkoch-i nolah-ta .
flower-Nom yellow-Decl .

1 1 # kkoch-i flower-Nom
 1.1 1.1 # kkoch flower
 1.2 1.2 # -i -Nom
2 2 # nolah-ta yellow-Decl
 2.1 2.1 # nolah yellow
 2.2 2.2 # -ta -Decl
3 3 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
flower-Nom yellow-Decl .
The flower is yellow .

1 2 # flower-Nom flower
 1.1 2 # flower flower
 1.2 0 # -Nom NULL
2 4 # yellow-Decl yellow
 2.1 4 # yellow yellow
 2.2 0 # -Decl NULL
3 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
kkoch-i nolah-ta .
flower-Nom yellow-Decl .
The flower is yellow .

1 2 # kkoch-i nolah-ta
2 -1 # nolah-ta *TOP*
3 2 # . nolah-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8463 Url_id=572 flag=0 cleaned=3 src_leng=6 trans_leng=7
na-uy sayngkak-un ne-uy sayngkak-kwa talu-ta .
my idea-Top your idea-from different-Decl .
My idea is different from yours .

######## Q1: IGT is clean? Answer: y
#dj little problem


############################## Q2: English parse tree 
(S (NP (PRP$ My) (NN idea)) (VP (VBZ is) (ADJP (JJ different) (PP (IN from) (NP (NNS yours))))) (. .))

(S+different (NP+idea (PRP$ My)
                      (NN idea))
             (VP+different (VBZ is)
                           (ADJP-PRD+different (JJ different)
                                               (PP+from (IN from)
                                                        (NP+yours (NNS yours)))))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
My idea is different from yours .
1 2 # My idea
2 4 # idea different
3 4 # is different
4 -1 # different *TOP*
5 4 # from different
6 5 # yours from
7 4 # . different


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
na-uy sayngkak-un ne-uy sayngkak-kwa talu-ta .
my idea-Top your idea-from different-Decl .

1 1 # na-uy my
 1.1 0 # na NULL
 1.2 0 # -uy NULL
2 2 # sayngkak-un idea-Top
 2.1 2.1 # sayngkak idea
 2.2 2.2 # -un -Top
3 3 # ne-uy your
 3.1 0 # ne NULL
 3.2 0 # -uy NULL
4 4 # sayngkak-kwa idea-from
 4.1 4.1 # sayngkak idea
 4.2 4.2 # -kwa -from
5 5 # talu-ta different-Decl
 5.1 5.1 # talu different
 5.2 5.2 # -ta -Decl
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
my idea-Top your idea-from different-Decl .
My idea is different from yours .

1 1 # my My
2 2 # idea-Top idea
 2.1 2 # idea idea
 2.2 0 # -Top NULL
3 6 # your yours
4 2,5 # idea-from idea,from
 4.1 2 # idea idea
 4.2 5 # -from from
5 4 # different-Decl different
 5.1 4 # different different
 5.2 0 # -Decl NULL
6 7 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
na-uy sayngkak-un ne-uy sayngkak-kwa talu-ta .
my idea-Top your idea-from different-Decl .
My idea is different from yours .

1 2 # na-uy sayngkak-un,sayngkak-kwa x
2 5 # sayngkak-un talu-ta
3 4 # ne-uy sayngkak-kwa
4 5 # sayngkak-kwa talu-ta
5 -1 # talu-ta *TOP*
6 5 # . talu-ta


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8464 Url_id=572 flag=0 cleaned=3 src_leng=6 trans_leng=9
i mwuncey-nun ku mwuncey-wa kath-ta .
this problem-Top that problem-as same .
This problem is the same as that problem .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT This) (NN problem)) (VP (VBZ is) (NP (NP (DT the) (JJ same)) (PP (IN as) (NP (DT that) (NN problem))))) (. .))

(S+same (NP+problem (DT This)
                    (NN problem))
        (VP+same (VBZ is)
                 (NP-PRD+same (NP+same (DT the)
                                       (JJ same))
                              (PP+as (IN as)
                                     (NP+problem (DT that)
                                                 (NN problem)))))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
This problem is the same as that problem .
1 2 # This problem
2 5 # problem same
3 5 # is same
4 5 # the same
5 -1 # same *TOP*
6 5 # as same
7 8 # that problem
8 6 # problem as
9 5 # . same


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
i mwuncey-nun ku mwuncey-wa kath-ta .
this problem-Top that problem-as same .

1 1 # i this
2 2 # mwuncey-nun problem-Top
 2.1 2.1 # mwuncey problem
 2.2 2.2 # -nun -Top
3 3 # ku that
4 4 # mwuncey-wa problem-as
 4.1 4.1 # mwuncey problem
 4.2 4.2 # -wa -as
5 5 # kath-ta same
 5.1 0 # kath NULL
 5.2 0 # -ta NULL
6 6 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
this problem-Top that problem-as same .
This problem is the same as that problem .

1 1 # this This
2 2 # problem-Top problem
 2.1 2 # problem problem
 2.2 0 # -Top NULL
3 7 # that that
4 6,8 # problem-as as,problem
 4.1 8 # problem problem
 4.2 6 # -as as
5 5 # same same
6 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
i mwuncey-nun ku mwuncey-wa kath-ta .
this problem-Top that problem-as same .
This problem is the same as that problem .

1 2 # i mwuncey-nun
2 5 # mwuncey-nun kath-ta
3 4 # ku mwuncey-wa
4 5 # mwuncey-wa kath-ta
5 -1 # kath-ta *TOP*
6 5 # . kath-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8465 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=6
salyengkwan-i pokose-ka philyoha-ta .
commander-Nom report-Nom necessary-Decl .
The commander needs the report .

######## Q1: IGT is clean? Answer: x
#dj "needs" vs "necessary"


############################## Q2: English parse tree 
(S (NP (DT The) (NN commander)) (VP (VBZ needs) (NP (DT the) (NN report))) (. .))

(S+needs (NP+commander (DT The)
                       (NN commander))
         (VP+needs (VBZ needs)
                   (NP+report (DT the)
                              (NN report)))
         (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
The commander needs the report .
1 2 # The commander
2 3 # commander needs
3 -1 # needs *TOP*
4 5 # the report
5 3 # report needs
6 3 # . needs


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
salyengkwan-i pokose-ka philyoha-ta .
commander-Nom report-Nom necessary-Decl .

1 1 # salyengkwan-i commander-Nom
 1.1 1.1 # salyengkwan commander
 1.2 1.2 # -i -Nom
2 2 # pokose-ka report-Nom
 2.1 2.1 # pokose report
 2.2 2.2 # -ka -Nom
3 3 # philyoha-ta necessary-Decl
 3.1 3.1 # philyoha necessary
 3.2 3.2 # -ta -Decl
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
commander-Nom report-Nom necessary-Decl .
The commander needs the report .

1 2 # commander-Nom commander
 1.1 2 # commander commander
 1.2 0 # -Nom NULL
2 5 # report-Nom report
 2.1 5 # report report
 2.2 0 # -Nom NULL
3 0 # necessary-Decl NULL
 3.1 0 # necessary NULL
 3.2 0 # -Decl NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
salyengkwan-i pokose-ka philyoha-ta .
commander-Nom report-Nom necessary-Decl .
The commander needs the report .

1 3 # salyengkwan-i philyoha-ta
2 3 # pokose-ka philyoha-ta
3 -2 # philyoha-ta NULL
4 3 # . philyoha-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8466 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=6
chelswu-nun papo-ka ani-ta .
chelswu-Top fool-nom not-Decl .
Chelswu is not a fool .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBZ is) (RB not) (NP (DT a) (NN fool))) (. .))

(S+is (NP+Chelswu (NNP Chelswu))
      (VP+is (VBZ is)
             (RB not)
             (NP+fool (DT a)
                      (NN fool)))
      (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
Chelswu is not a fool .
1 5 # Chelswu is x
2 5 # is *TOP* x
3 5 # not is x
4 5 # a fool 
5 -1 # fool is x
6 5 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
chelswu-nun papo-ka ani-ta .
chelswu-Top fool-nom not-Decl .

1 1 # chelswu-nun chelswu-Top
 1.1 1.1 # chelswu chelswu
 1.2 1.2 # -nun -Top
2 2 # papo-ka fool-nom
 2.1 2.1 # papo fool
 2.2 2.2 # -ka -nom
3 3 # ani-ta not-Decl
 3.1 3.1 # ani not
 3.2 3.2 # -ta -Decl
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
chelswu-Top fool-nom not-Decl .
Chelswu is not a fool .

1 1 # chelswu-Top Chelswu
 1.1 1 # chelswu Chelswu
 1.2 0 # -Top NULL
2 5 # fool-nom fool
 2.1 5 # fool fool
 2.2 0 # -nom NULL
3 3 # not-Decl not
 3.1 3 # not not
 3.2 0 # -Decl NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
chelswu-nun papo-ka ani-ta .
chelswu-Top fool-nom not-Decl .
Chelswu is not a fool .

1 3 # chelswu-nun ani-ta
2 3 # papo-ka ani-ta
3 -2 # ani-ta NULL
4 3 # . ani-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8467 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=5
cacwu Chelswu-ka sakwa-lul mek-nun-ta .
frequently Chelswu-Nom apple-Acc eat-Pres-Decl .
Chelswu eats apples frequently .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBZ eats) (NP (NNS apples)) (ADVP (RB frequently))) (. .))

(S+eats (NP+Chelswu (NNP Chelswu))
        (VP+eats (VBZ eats)
                 (NP+apples (NNS apples))
                 (ADVP+frequently (RB frequently)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu eats apples frequently .
1 2 # Chelswu eats
2 -1 # eats *TOP*
3 2 # apples eats
4 2 # frequently eats
5 2 # . eats


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
cacwu Chelswu-ka sakwa-lul mek-nun-ta .
frequently Chelswu-Nom apple-Acc eat-Pres-Decl .

1 1 # cacwu frequently
2 2 # Chelswu-ka Chelswu-Nom
 2.1 2.1 # Chelswu Chelswu
 2.2 2.2 # -ka -Nom
3 3 # sakwa-lul apple-Acc
 3.1 3.1 # sakwa apple
 3.2 3.2 # -lul -Acc
4 4 # mek-nun-ta eat-Pres-Decl
 4.1 4.1 # mek eat
 4.2 4.2 # -nun -Pres
 4.3 4.3 # -ta -Decl
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
frequently Chelswu-Nom apple-Acc eat-Pres-Decl .
Chelswu eats apples frequently .

1 4 # frequently frequently
2 1 # Chelswu-Nom Chelswu
 2.1 1 # Chelswu Chelswu
 2.2 0 # -Nom NULL
3 3 # apple-Acc apples
 3.1 3 # apple apples
 3.2 0 # -Acc NULL
4 2 # eat-Pres-Decl eats
 4.1 2 # eat eats
 4.2 0 # -Pres NULL
 4.3 0 # -Decl NULL
5 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
cacwu Chelswu-ka sakwa-lul mek-nun-ta .
frequently Chelswu-Nom apple-Acc eat-Pres-Decl .
Chelswu eats apples frequently .

1 4 # cacwu mek-nun-ta
2 4 # Chelswu-ka mek-nun-ta
3 4 # sakwa-lul mek-nun-ta
4 -1 # mek-nun-ta *TOP*
5 4 # . mek-nun-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8472 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=6
Chelswu-ka sakwa-lul mek-ko issta .
Chelswu-Nom apple-Acc eat-aux-connect be-Pres-Decl .
Chelswu is eating an apple .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBZ is) (VP (VBG eating) (NP (DT an) (NN apple)))) (. .))

(S+eating (NP+Chelswu (NNP Chelswu))
          (VP+eating (VBZ is)
                     (VP+eating (VBG eating)
                                (NP+apple (DT an)
                                          (NN apple))))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu is eating an apple .
1 3 # Chelswu eating
2 3 # is eating
3 -1 # eating *TOP*
4 5 # an apple
5 3 # apple eating
6 3 # . eating


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-ka sakwa-lul mek-ko issta .
Chelswu-Nom apple-Acc eat-aux-connect be-Pres-Decl .

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # sakwa-lul apple-Acc
 2.1 2.1 # sakwa apple
 2.2 2.2 # -lul -Acc
3 3 # mek-ko eat-aux-connect
 3.1 0 # mek NULL
 3.2 0 # -ko NULL
4 4 # issta be-Pres-Decl
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom apple-Acc eat-aux-connect be-Pres-Decl .
Chelswu is eating an apple .

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 5 # apple-Acc apple
 2.1 5 # apple apple
 2.2 0 # -Acc NULL
3 3 # eat-aux-connect eating
 3.1 3 # eat eating
 3.2 0 # -aux NULL
 3.3 0 # -connect NULL
4 2 # be-Pres-Decl is
 4.1 2 # be is
 4.2 0 # -Pres NULL
 4.3 0 # -Decl NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chelswu-ka sakwa-lul mek-ko issta .
Chelswu-Nom apple-Acc eat-aux-connect be-Pres-Decl .
Chelswu is eating an apple .

1 3 # Chelswu-ka mek-ko
2 3 # sakwa-lul mek-ko
3 -1 # mek-ko *TOP*
4 3 # issta mek-ko
5 3 # . mek-ko


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8474 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=9
Chelswu-ka ilccik o-ki-ka elyeps-ta .
Chelswu-Nom early arrive-Nominalizer-Nom difficult .
For Chelswu t o arrive early is difficult .

######## Q1: IGT is clean? Answer: y
#dj "t o" sb "to" 


############################## Q2: English parse tree 
(S (SBAR (IN For) (S (NP (NNP Chelswu) (NNP t)) (VP (VBZ o) (VP (VB arrive) (ADVP (RB early)))))) (VP (VBZ is) (ADJP (JJ difficult))) (. .))

(S+difficult (SBAR+arrive (IN For)
                          (S+arrive (NP+t (NNP Chelswu)
                                          (NNP t))
                                    (VP+arrive (VBZ o)
                                               (VP+arrive (VB arrive)
                                                          (ADVP+early (RB early))))))
             (VP+difficult (VBZ is)
                           (ADJP-PRD+difficult (JJ difficult)))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
For Chelswu t o arrive early is difficult .
1 5 # For arrive
2 3 # Chelswu t
3 5 # t arrive
4 5 # o arrive
5 8 # arrive difficult
6 5 # early arrive
7 8 # is difficult
8 -1 # difficult *TOP*
9 8 # . difficult


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-ka ilccik o-ki-ka elyeps-ta .
Chelswu-Nom early arrive-Nominalizer-Nom difficult .

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # ilccik early
3 3 # o-ki-ka arrive-Nominalizer-Nom
 3.1 3.1 # o arrive
 3.2 3.2 # -ki -Nominalizer
 3.3 3.3 # -ka -Nom
4 4 # elyeps-ta difficult
 4.1 0 # elyeps NULL
 4.2 0 # -ta NULL
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom early arrive-Nominalizer-Nom difficult .
For Chelswu t o arrive early is difficult .

1 2 # Chelswu-Nom Chelswu
 1.1 2 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 6 # early early
3 5 # arrive-Nominalizer-Nom arrive
 3.1 5 # arrive arrive
 3.2 0 # -Nominalizer NULL
 3.3 0 # -Nom NULL
4 8 # difficult difficult
5 9 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chelswu-ka ilccik o-ki-ka elyeps-ta .
Chelswu-Nom early arrive-Nominalizer-Nom difficult .
For Chelswu t o arrive early is difficult .

1 3 # Chelswu-ka o-ki-ka
2 3 # ilccik o-ki-ka
3 4 # o-ki-ka elyeps-ta
4 -1 # elyeps-ta *TOP*
5 4 # . elyeps-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8475 Url_id=572 flag=0 cleaned=4 src_leng=5 trans_leng=10
mwusenki-ka kocangna-ss-tamyen thongsin-i pwulkanungha-ta .
radio-Nom broke-Past-if communication-Nom impossible-Decl .
If the radio is broken , communication is impossible .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (SBAR (IN If) (S (NP (DT the) (NN radio)) (VP (VBZ is) (VP (VBN broken))))) (, ,) (NP (NN communication)) (VP (VBZ is) (ADJP (JJ impossible))) (. .))

(S+impossible (SBAR+broken (IN If)
                           (S+broken (NP+radio (DT the)
                                               (NN radio))
                                     (VP+broken (VBZ is)
                                                (VP+broken (VBN broken)))))
              (, ,)
              (NP+communication (NN communication))
              (VP+impossible (VBZ is)
                             (ADJP-PRD+impossible (JJ impossible)))
              (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
If the radio is broken , communication is impossible .
1 5 # If broken
2 3 # the radio
3 5 # radio broken
4 5 # is broken
5 9 # broken impossible
6 9 # , impossible
7 9 # communication impossible
8 9 # is impossible
9 -1 # impossible *TOP*
10 9 # . impossible


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
mwusenki-ka kocangna-ss-tamyen thongsin-i pwulkanungha-ta .
radio-Nom broke-Past-if communication-Nom impossible-Decl .

1 1 # mwusenki-ka radio-Nom
 1.1 1.1 # mwusenki radio
 1.2 1.2 # -ka -Nom
2 2 # kocangna-ss-tamyen broke-Past-if
 2.1 2.1 # kocangna broke
 2.2 2.2 # -ss -Past
 2.3 2.3 # -tamyen -if
3 3 # thongsin-i communication-Nom
 3.1 3.1 # thongsin communication
 3.2 3.2 # -i -Nom
4 4 # pwulkanungha-ta impossible-Decl
 4.1 4.1 # pwulkanungha impossible
 4.2 4.2 # -ta -Decl
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
radio-Nom broke-Past-if communication-Nom impossible-Decl .
If the radio is broken , communication is impossible .

1 3 # radio-Nom radio
 1.1 3 # radio radio
 1.2 0 # -Nom NULL
2 1,5 # broke-Past-if If,broken
 2.1 5 # broke broken
 2.2 0 # -Past NULL
 2.3 1 # -if If
3 7 # communication-Nom communication
 3.1 7 # communication communication
 3.2 0 # -Nom NULL
4 9 # impossible-Decl impossible
 4.1 9 # impossible impossible
 4.2 0 # -Decl NULL
5 10 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
mwusenki-ka kocangna-ss-tamyen thongsin-i pwulkanungha-ta .
radio-Nom broke-Past-if communication-Nom impossible-Decl .
If the radio is broken , communication is impossible .

1 2 # mwusenki-ka kocangna-ss-tamyen
2 4 # kocangna-ss-tamyen pwulkanungha-ta
3 4 # thongsin-i pwulkanungha-ta
4 -1 # pwulkanungha-ta *TOP*
5 4 # . pwulkanungha-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8476 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
Chelswu-ka sakwa-lul mek-nun-ta .
Chelswu-Nom apple-Acc eat-Pres-Dec .
Chelswu eats an apple .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NNP Chelswu)) (VP (VBZ eats) (NP (DT an) (NN apple))) (. .))

(S+eats (NP+Chelswu (NNP Chelswu))
        (VP+eats (VBZ eats)
                 (NP+apple (DT an)
                           (NN apple)))
        (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Chelswu eats an apple .
1 2 # Chelswu eats
2 -1 # eats *TOP*
3 4 # an apple
4 2 # apple eats
5 2 # . eats


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
Chelswu-ka sakwa-lul mek-nun-ta .
Chelswu-Nom apple-Acc eat-Pres-Dec .

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # sakwa-lul apple-Acc
 2.1 2.1 # sakwa apple
 2.2 2.2 # -lul -Acc
3 3 # mek-nun-ta eat-Pres-Dec
 3.1 3.1 # mek eat
 3.2 3.2 # -nun -Pres
 3.3 3.3 # -ta -Dec
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
Chelswu-Nom apple-Acc eat-Pres-Dec .
Chelswu eats an apple .

1 1 # Chelswu-Nom Chelswu
 1.1 1 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 4 # apple-Acc apple
 2.1 4 # apple apple
 2.2 0 # -Acc NULL
3 2 # eat-Pres-Dec eats
 3.1 2 # eat eats
 3.2 0 # -Pres NULL
 3.3 0 # -Dec NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Chelswu-ka sakwa-lul mek-nun-ta .
Chelswu-Nom apple-Acc eat-Pres-Dec .
Chelswu eats an apple .

1 3 # Chelswu-ka mek-nun-ta
2 3 # sakwa-lul mek-nun-ta
3 -1 # mek-nun-ta *TOP*
4 3 # . mek-nun-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8478 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=8
Chelswu-ka ilccik o-ki-ka elyeps-ta .
Chelswu-Nom early arrive-Nominalizer-Nom difficult .
For Chelswu to arrive early is difficult .

######## Q1: IGT is clean? Answer: n
#dj duplicate


############################## Q2: English parse tree 
(S (SBAR (IN For) (S (NP (NNP Chelswu)) (VP (TO to) (VP (VB arrive) (ADVP (RB early)))))) (VP (VBZ is) (ADJP (JJ difficult))) (. .))

(S+difficult (SBAR+arrive (IN For)
                          (S+arrive (NP+Chelswu (NNP Chelswu))
                                    (VP+arrive (TO to)
                                               (VP+arrive (VB arrive)
                                                          (ADVP+early (RB early))))))
             (VP+difficult (VBZ is)
                           (ADJP-PRD+difficult (JJ difficult)))
             (. .))


###### Q2: English parse tree is correct? Answer: 



###############################  Q3: English DS 
For Chelswu to arrive early is difficult .
1 4 # For arrive
2 4 # Chelswu arrive
3 4 # to arrive
4 7 # arrive difficult
5 4 # early arrive
6 7 # is difficult
7 -1 # difficult *TOP*
8 7 # . difficult


########  Q3: English DS is correct? Answer: 



#######################  Q4: src and gloss alignment
Chelswu-ka ilccik o-ki-ka elyeps-ta .
Chelswu-Nom early arrive-Nominalizer-Nom difficult .

1 1 # Chelswu-ka Chelswu-Nom
 1.1 1.1 # Chelswu Chelswu
 1.2 1.2 # -ka -Nom
2 2 # ilccik early
3 3 # o-ki-ka arrive-Nominalizer-Nom
 3.1 3.1 # o arrive
 3.2 3.2 # -ki -Nominalizer
 3.3 3.3 # -ka -Nom
4 4 # elyeps-ta difficult
 4.1 0 # elyeps NULL
 4.2 0 # -ta NULL
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: 



######################### Q5: gloss and translation alignment
Chelswu-Nom early arrive-Nominalizer-Nom difficult .
For Chelswu to arrive early is difficult .

1 2 # Chelswu-Nom Chelswu
 1.1 2 # Chelswu Chelswu
 1.2 0 # -Nom NULL
2 5 # early early
3 4 # arrive-Nominalizer-Nom arrive
 3.1 4 # arrive arrive
 3.2 0 # -Nominalizer NULL
 3.3 0 # -Nom NULL
4 7 # difficult difficult
5 8 # . .


######## Q5: gloss and translation alignment is correct? Answer: 


############################# Q6: src DS
Chelswu-ka ilccik o-ki-ka elyeps-ta .
Chelswu-Nom early arrive-Nominalizer-Nom difficult .
For Chelswu to arrive early is difficult .

1 3 # Chelswu-ka o-ki-ka
2 3 # ilccik o-ki-ka
3 4 # o-ki-ka elyeps-ta
4 -1 # elyeps-ta *TOP*
5 4 # . elyeps-ta


####### Q6: src DS is correct? Answer: 





###########################################################
Igt_id=8482 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=6
i kenmwul-un hakkyo i-ta .
this building-Top school Cop-Decl .
This building is a school .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT This) (NN building)) (VP (VBZ is) (NP (DT a) (NN school))) (. .))

(S+school (NP+building (DT This)
                       (NN building))
          (VP+school (VBZ is)
                     (NP-PRD+school (DT a)
                                    (NN school)))
          (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
This building is a school .
1 2 # This building
2 5 # building school
3 5 # is school
4 5 # a school
5 -1 # school *TOP*
6 5 # . school


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
i kenmwul-un hakkyo i-ta .
this building-Top school Cop-Decl .

1 1 # i this
2 2 # kenmwul-un building-Top
 2.1 2.1 # kenmwul building
 2.2 2.2 # -un -Top
3 3 # hakkyo school
4 4 # i-ta Cop-Decl
 4.1 4.1 # i Cop
 4.2 4.2 # -ta -Decl
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
this building-Top school Cop-Decl .
This building is a school .

1 1 # this This
2 2 # building-Top building
 2.1 2 # building building
 2.2 0 # -Top NULL
3 5 # school school
4 3 # Cop-Decl NULL x
 4.1 0 # Cop NULL
 4.2 0 # -Decl NULL
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
i kenmwul-un hakkyo i-ta .
this building-Top school Cop-Decl .
This building is a school .

1 2 # i kenmwul-un
2 3 # kenmwul-un hakkyo
3 -1 # hakkyo *TOP*
4 3 # i-ta hakkyo
5 3 # . hakkyo


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8483 Url_id=572 flag=0 cleaned=3 src_leng=3 trans_leng=5
sangca-ka mwukep-ta .
box-Nom heavy-Decl .
The box is heavy .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN box)) (VP (VBZ is) (ADJP (JJ heavy))) (. .))

(S+heavy (NP+box (DT The)
                 (NN box))
         (VP+heavy (VBZ is)
                   (ADJP-PRD+heavy (JJ heavy)))
         (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
The box is heavy .
1 2 # The box
2 4 # box heavy
3 4 # is heavy
4 -1 # heavy *TOP*
5 4 # . heavy


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
sangca-ka mwukep-ta .
box-Nom heavy-Decl .

1 1 # sangca-ka box-Nom
 1.1 1.1 # sangca box
 1.2 1.2 # -ka -Nom
2 2 # mwukep-ta heavy-Decl
 2.1 2.1 # mwukep heavy
 2.2 2.2 # -ta -Decl
3 3 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
box-Nom heavy-Decl .
The box is heavy .

1 2 # box-Nom box
 1.1 2 # box box
 1.2 0 # -Nom NULL
2 4 # heavy-Decl heavy
 2.1 4 # heavy heavy
 2.2 0 # -Decl NULL
3 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
sangca-ka mwukep-ta .
box-Nom heavy-Decl .
The box is heavy .

1 2 # sangca-ka mwukep-ta
2 -1 # mwukep-ta *TOP*
3 2 # . mwukep-ta


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8485 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
inkan-un sahoycek-i anita .
man-Top social-Nom not .
Man is not social .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NN Man)) (VP (VBZ is) (RB not) (ADJP (JJ social))) (. .))

(S+is (NP+Man (NN Man))
      (VP+is (VBZ is)
             (RB not)
             (ADJP+social (JJ social)))
      (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
Man is not social .
1 4 # Man is x
2 4 # is *TOP* x
3 4 # not is x
4 -1 # social is x
5 4 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
inkan-un sahoycek-i anita .
man-Top social-Nom not .

1 1 # inkan-un man-Top
 1.1 1.1 # inkan man
 1.2 1.2 # -un -Top
2 2 # sahoycek-i social-Nom
 2.1 2.1 # sahoycek social
 2.2 2.2 # -i -Nom
3 3 # anita not
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
man-Top social-Nom not .
Man is not social .

1 1 # man-Top Man
 1.1 1 # man Man
 1.2 0 # -Top NULL
2 4 # social-Nom social
 2.1 4 # social social
 2.2 0 # -Nom NULL
3 3 # not not
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
inkan-un sahoycek-i anita .
man-Top social-Nom not .
Man is not social .

1 3 # inkan-un anita
2 3 # sahoycek-i anita
3 -1 # anita NULL x
4 3 # . anita


####### Q6: src DS is correct? Answer: y





###########################################################
Igt_id=8486 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=6
i kenmwul-un hakkyo-ka anita .
this building-Top school-Nom not .
This building is not school .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT This) (NN building)) (VP (VBZ is) (RB not) (NP (NN school))) (. .))

(S+is (NP+building (DT This)
                   (NN building))
      (VP+is (VBZ is)
             (RB not)
             (NP+school (NN school)))
      (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
This building is not school .
1 2 # This building
2 5 # building is x
3 5 # is *TOP* x
4 5 # not is x
5 -1 # school is x
6 5 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
i kenmwul-un hakkyo-ka anita .
this building-Top school-Nom not .

1 1 # i this
2 2 # kenmwul-un building-Top
 2.1 2.1 # kenmwul building
 2.2 2.2 # -un -Top
3 3 # hakkyo-ka school-Nom
 3.1 3.1 # hakkyo school
 3.2 3.2 # -ka -Nom
4 4 # anita not
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: n



######################### Q5: gloss and translation alignment
this building-Top school-Nom not .
This building is not school .

1 1 # this This
2 2 # building-Top building
 2.1 2 # building building
 2.2 0 # -Top NULL
3 5 # school-Nom school
 3.1 5 # school school
 3.2 0 # -Nom NULL
4 4 # not not
5 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
i kenmwul-un hakkyo-ka anita .
this building-Top school-Nom not .
This building is not school .

1 2 # i kenmwul-un
2 3 # kenmwul-un anita x
3 -1 # hakkyo-ka anita x
4 3 # anita NULL x
5 3 # . anita x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8487 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=6
Sangca-nun mwukep-ci anhta .
box-Top heavy-CI not-Decl .
The box is not heavy .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (DT The) (NN box)) (VP (VBZ is) (RB not) (ADJP (JJ heavy))) (. .))

(S+is (NP+box (DT The)
              (NN box))
      (VP+is (VBZ is)
             (RB not)
             (ADJP+heavy (JJ heavy)))
      (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
The box is not heavy .
1 2 # The box
2 5 # box is x
3 5 # is *TOP* x
4 5 # not is x
5 -1 # heavy is x
6 5 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
Sangca-nun mwukep-ci anhta .
box-Top heavy-CI not-Decl .

1 1 # Sangca-nun box-Top
 1.1 1.1 # Sangca box
 1.2 1.2 # -nun -Top
2 2 # mwukep-ci heavy-CI
 2.1 2.1 # mwukep heavy
 2.2 2.2 # -ci -CI
3 3 # anhta not-Decl
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
box-Top heavy-CI not-Decl .
The box is not heavy .

1 2 # box-Top box
 1.1 2 # box box
 1.2 0 # -Top NULL
2 5 # heavy-CI heavy
 2.1 5 # heavy heavy
 2.2 0 # -CI NULL
3 4 # not-Decl not
 3.1 4 # not not
 3.2 0 # -Decl NULL
4 6 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
Sangca-nun mwukep-ci anhta .
box-Top heavy-CI not-Decl .
The box is not heavy .

1 2 # Sangca-nun anhta x
2 -1 # mwukep-ci anhta x
3 2 # anhta NULL x
4 2 # . anhta x


####### Q6: src DS is correct? Answer: n





###########################################################
Igt_id=8488 Url_id=572 flag=0 cleaned=3 src_leng=5 trans_leng=5
inkan-un sahoycek i-ci anhta .
man-Top social Cop-CI not .
Man is not social .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NN Man)) (VP (VBZ is) (RB not) (ADJP (JJ social))) (. .))

(S+is (NP+Man (NN Man))
      (VP+is (VBZ is)
             (RB not)
             (ADJP+social (JJ social)))
      (. .))


###### Q2: English parse tree is correct? Answer: n



###############################  Q3: English DS 
Man is not social .
1 4 # Man is x
2 4 # is *TOP* x
3 4 # not is x
4 -1 # social is x
5 4 # . is x


########  Q3: English DS is correct? Answer: n



#######################  Q4: src and gloss alignment
inkan-un sahoycek i-ci anhta .
man-Top social Cop-CI not .

1 1 # inkan-un man-Top
 1.1 1.1 # inkan man
 1.2 1.2 # -un -Top
2 2 # sahoycek social
3 3 # i-ci Cop-CI
 3.1 3.1 # i Cop
 3.2 3.2 # -ci -CI
4 4 # anhta not
5 5 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
man-Top social Cop-CI not .
Man is not social .

1 1 # man-Top Man
 1.1 1 # man Man
 1.2 0 # -Top NULL
2 4 # social social
3 2 # Cop-CI NULL x
 3.1 0 # Cop NULL
 3.2 0 # -CI NULL
4 3 # not not
5 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: n


############################# Q6: src DS
inkan-un sahoycek i-ci anhta .
man-Top social Cop-CI not .
Man is not social .

1 2 # inkan-un anhta x
2 -1 # sahoycek anhta x
3 2 # i-ci anhta x
4 2 # anhta NULL x
5 2 # . anhta x


####### Q6: src DS is correct? Answer: n




###########################################################
Igt_id=8490 Url_id=572 flag=0 cleaned=3 src_leng=4 trans_leng=5
thamci hwaltong-i palsayngha-n-ta .
detection activity-Nom occur-Pres-Decl .
Detection activity is occurring .

######## Q1: IGT is clean? Answer: y


############################## Q2: English parse tree 
(S (NP (NN Detection) (NN activity)) (VP (VBZ is) (VP (VBG occurring))) (. .))

(S+occurring (NP+activity (NN Detection)
                          (NN activity))
             (VP+occurring (VBZ is)
                           (VP+occurring (VBG occurring)))
             (. .))


###### Q2: English parse tree is correct? Answer: y



###############################  Q3: English DS 
Detection activity is occurring .
1 2 # Detection activity
2 4 # activity occurring
3 4 # is occurring
4 -1 # occurring *TOP*
5 4 # . occurring


########  Q3: English DS is correct? Answer: y



#######################  Q4: src and gloss alignment
thamci hwaltong-i palsayngha-n-ta .
detection activity-Nom occur-Pres-Decl .

1 1 # thamci detection
2 2 # hwaltong-i activity-Nom
 2.1 2.1 # hwaltong activity
 2.2 2.2 # -i -Nom
3 3 # palsayngha-n-ta occur-Pres-Decl
 3.1 3.1 # palsayngha occur
 3.2 3.2 # -n -Pres
 3.3 3.3 # -ta -Decl
4 4 # . .
######## Q4: src and gloss alignment is correct? Answer: y



######################### Q5: gloss and translation alignment
detection activity-Nom occur-Pres-Decl .
Detection activity is occurring .

1 1 # detection Detection
2 2 # activity-Nom activity
 2.1 2 # activity activity
 2.2 0 # -Nom NULL
3 4 # occur-Pres-Decl occurring
 3.1 4 # occur occurring
 3.2 0 # -Pres NULL
 3.3 0 # -Decl NULL
4 5 # . .


######## Q5: gloss and translation alignment is correct? Answer: y


############################# Q6: src DS
thamci hwaltong-i palsayngha-n-ta .
detection activity-Nom occur-Pres-Decl .
Detection activity is occurring .

1 2 # thamci hwaltong-i
2 3 # hwaltong-i palsayngha-n-ta
3 -1 # palsayngha-n-ta *TOP*
4 3 # . palsayngha-n-ta


####### Q6: src DS is correct? Answer: y




